repo_id,name,full_name,html_url,description,created_at,stars,language,topics,config_file,readme_preview,file_url
111667959,umi,umijs/umi,https://github.com/umijs/umi,A framework in react community ‚ú®,,0,Unknown,,.cursorrules,"umi A framework in react community ‚ú® > Please consider following this project's author, sorrycc, and consider starring the project to show your ‚ù§Ô∏è and support. üöÄ Read the launch post ‚Üí üìö Learn Umi ‚Üí Contribution See Contributing Guide. Core Maintainers Core Maintainers are community members who have contributed significantly to the project through addressing issues, fixing bugs, and implementing enhancements/features. * sorrycc * xiaohuoni Maintainers Maintainers are community members who have had 10 or more PRs merged in umi or have spent a lot of time contributing to the umi community or addressing issues. * PeachScript * YdreamW * yuaanlin * fz6m * stormslowly * xierenyuan * siyi98 * txp1035 * zenotsai Contributors Contributors are community members who have had 1 or more PRs merged in umi. If you are a contributor, you can contact me [sorrycc] to join the Contributor Group. Community * ‰∫§ÊµÅÂíåÂèçÈ¶àÁæ§ LICENSE MIT",https://github.com/umijs/umi/blob/9edcd6f3b6abb199a268b77e5475edde11dab685/.cursorrules
1122347787,quotio,nguyenphutrong/quotio,https://github.com/nguyenphutrong/quotio,"Stop juggling AI accounts. Quotio is a beautiful native macOS menu bar app that unifies your Claude, Gemini, OpenAI, Qwen, and Antigravity subscriptions ‚Äì with real-time quota tracking and smart auto-",,0,Unknown,,.cursorrules,"Quotio The ultimate command center for your AI coding assistants on macOS. Quotio is a native macOS application for managing CLIProxyAPI - a local proxy server that powers your AI coding agents. It helps you manage multiple AI accounts, track quotas, and configure CLI tools in one place. ‚ú® Features - üîå Multi-Provider Support: Connect accounts from Gemini, Claude, OpenAI Codex, Qwen, Vertex AI, iFlow, Antigravity, Kiro, Trae, and GitHub Copilot via OAuth or API keys. - üìä Standalone Quota Mode: View quota and accounts without running the proxy server - perfect for quick checks. - üöÄ One-Click Agent Configuration: Auto-detect and configure AI coding tools like Claude Code, OpenCode, Gemini CLI, and more. - üìà Real-time Dashboard: Monitor request traffic, token usage, and success rates live. - üìâ Smart Quota Management: Visual quota tracking per account with automatic failover strategies (Round Robin / Fill First). - üîë API Key Management: Generate and manage API keys for your local proxy. - üñ•Ô∏è Menu Bar Integration: Quick access to server status, quota overview, and custom provider icons from your menu bar. - üîî Notifications: Alerts for low quotas, account cooling periods, or service issues. - üîÑ Auto-Update: Built-in Sparkle updater for seamless updates. - üåç Multilingual: English, Vietnamese, and Simplified Chinese support. ü§ñ Supported Ecosystem AI Providers | Provider | Auth Method | |----------|-------------| | Google Gemini | OAuth | | Anthropic Claude | OAuth | | OpenAI Codex | OAuth | | Qwen Code | OAuth | | Vertex AI | Service Account JSON | | iFlow | OAuth | | Antigravity | OAuth | | Kiro | OAuth | | GitHub Copilot | OAuth | IDE Quota Tracking (Monitor Only) | IDE | Description | |-----|-------------| | Cursor | Auto-detected when installed and logged in | | Trae | Auto-detected when installed and logged in | > Note: These IDEs are only used for quota usage monitoring. They cannot be used as providers for the proxy. Compatible CLI Agents Quotio can automatically configure these tools to use your centralized proxy: - Claude Code - Codex CLI - Gemini CLI - Amp CLI - OpenCode - Factory Droid üöÄ Installation Requirements - macOS 14.0 (Sonoma) or later - Internet connection for OAuth authentication Homebrew (Recommended) [code] Download Download the latest [code] from the Releases page. > ‚ö†Ô∏è Note: The app is not signed with an Apple Developer certificate yet. If macOS blocks the app, run: > [code] Building from Source 1. Clone the repository: [code] 2. Open in Xcode: [code] 3. Build and Run: - Select the ""Quotio"" scheme - Press [code] to build and run > The app will automatically download the [code] binary on first launch. üìñ Usage 1. Start the Server Launch Quotio and click Start on the dashboard to initialize the local proxy server. 2. Connect Accounts Go to Providers tab ‚Üí Click on a provider ‚Üí Authenticate via OAuth or import credentials. 3. Configure Agents Go to Agents tab ‚Üí Select an installed agent ‚Üí Click Configure ‚Üí Choose Automatic or Manual m",https://github.com/nguyenphutrong/quotio/blob/02be19bcca899762d562b8bb68c46f019423adce/.cursorrules
450866151,dx,elixir-dx/dx,https://github.com/elixir-dx/dx,Automatic data loading for Elixir functions,,0,Unknown,,.cursorrules,"Dx [](https://hex.pm/packages/dx) [](https://hexdocs.pm/dx/Dx.html) [](https://github.com/elixir-dx/dx/blob/main/LICENSE) [](https://github.com/elixir-dx/dx/tree/main) Dx enables you to write Elixir code as if all your Ecto data is already (pre)loaded. Example [code] This can be called using [code] [code] loads all required data automatically: The association [code] , and either all [code] matching the filter (translated to a single SQL query) or the user's associated lists, depending on whether it's an admin. These function can just as well be called for many users, and Dx will load data efficiently (with batching and concurrently). Demo [](https://livebook.dev/run?url=https%3A%2F%2Fraw.githubusercontent.com%2Felixir-dx%2Fdx%2Fmain%2Flivebook%2Fdemo.livemd) Installation Add [code] to your list of dependencies in [code] : [code] Add this line to the top of your Ecto schema modules (replace [code] with your Ecto repo module) [code] Configure your repo in [code] (replace [code] with your Ecto repo module) [code] Import the formatter rules in [code] : [code] Background Most server backends for web and mobile applications are split between the actual application and at least one database. In their day-to-day programming, most Elixir developers have to keep that in mind and think about how to store data in the database, and when and how to load it. It's so deeply engrained that we often take this problem for granted, having integrated it in how we think about code and code architecture. For example, Phoenix (the most popular web framework for Elixir) has API contexts that suggest structuring apps into modules that act as a boundary (or interface) to the rest of the code. Within these, data is loaded and returned. Since it's a generic interface, the simplest approach is to load all data that's possibly needed, and return it. However, as the app grows in functionality and thus complexity, this may become a lot of data. And it's still necessary to think about what to return, where it's needed, and how to slice it. Imagine this problem would not exist. Enter Dx. With Dx, Elixir developers don't have to think about loading data from the database at all. You just write Elixir code, as if all data is already loaded and readily available. How it works When working with data in the database, you define Elixir functions using [code] instead of [code] (the regular Elixir function definition). The [code] function must be imported from the [code] module. Within [code] functions, you can write regular Elixir code, accessing all fields and associations as if they're already loaded. You can also call other [code] functions and structure your code in modules as usual. When the app is compiled, Dx translates your [code] code into multiple versions with different ways to load data: - Data loading: Any data that might need to be loaded is wrapped in a check that either returns the already loaded data, or returns a ""data requirement"". Dx runs the code at the entry point (",https://github.com/elixir-dx/dx/blob/969672aea0f248eaff61bc3d98cf757c3002bbae/.cursorrules.md
1000755389,SmartFlowAI,emielregis2/SmartFlowAI,https://github.com/emielregis2/SmartFlowAI,Projekt zaliczeniowy kursu 10xdev,,0,Unknown,,.cursorrules,"Plik: README.md SmartFlowAI - Aplikacja analizy proces√≥w (Wersja Produkcyjna) [](https://github.com/emielregis2/SmartFlowAI/actions/workflows/ci.yml) [](https://www.python.org/downloads/) [](https://github.com/psf/black) [](https://github.com/emielregis2/SmartFlowAI) SmartFlowAI analizuje procesy biznesowe przez ChatGPT-4o i daje konkretne rekomendacje automatyzacji. üöÄ Wersja produkcyjna - bez debugowania, zoptymalizowana wydajno≈õƒá, tylko logi b≈Çƒôd√≥w. Projekt na zaliczenie kursu 10xDevs - wykonany w 2 dni (dok≈Çadny opis projektu zaliczeniowego w Wiki) Quick Start (5 minut) 1. Klonowanie [code] 2. Instalacja [code] 3. Konfiguracja Skopiuj [code] do [code] i wype≈Çnij: [code] 4. Baza danych Wykonaj w Supabase SQL Editor: [code] 5. Uruchomienie [code] Aplikacja: [code] Konta testowe: - [code] / [code] - [code] / [code] Funkcje - ‚úÖ Logowanie - Supabase Auth - ‚úÖ Dodaj proces - Formularz: nazwa + opis - ‚úÖ Ultra wnikliwa analiza AI - 3 poziomy g≈Çƒôboko≈õci z wyszukiwaniem internetowym - ‚úÖ Kontekst firmy - Wielko≈õƒá, bran≈ºa, bud≈ºet dla spersonalizowanych rekomendacji - ‚úÖ Bran≈ºowe szablony - Specjalistyczne integracje dla r√≥≈ºnych sektor√≥w - ‚úÖ Lista proces√≥w - Wszystkie procesy u≈ºytkownika - ‚úÖ Edycja proces√≥w - Modyfikuj nazwƒô, opis i analizƒô AI - ‚úÖ Usuwanie - Usu≈Ñ niepotrzebne procesy - ‚úÖ Export PDF - Generuj raport z przeanalizowanymi procesami - ‚úÖ Kopiuj do schowka - Skopiuj pe≈Çny tekst raportu jednym klikniƒôciem - ‚úÖ CI/CD - Automatyczne testy i deploy To wszystko! Ultra-proste MVP z pe≈ÇnƒÖ automatyzacjƒÖ i zarzƒÖdzaniem procesami. üöÄ Wersja Produkcyjna Optymalizacje wydajno≈õci: - ‚ùå Usuniƒôto debugowanie - Brak sekcji ""üîç Debugging"" w interfejsie - ‚ùå Usuniƒôto logi debugowania - Tylko logi b≈Çƒôd√≥w (ERROR level) - ‚ùå Usuniƒôto pliki log√≥w - Brak [code] - ‚úÖ Zoptymalizowano logowanie - Tylko konsola, bez plik√≥w - ‚úÖ Czysta wersja produkcyjna - Gotowa do wdro≈ºenia R√≥≈ºnice miƒôdzy wersjami: | Funkcja | Wersja deweloperska | Wersja produkcyjna | | -------------------- | ----------------------- | ------------------ | | Sekcja debugowania | ‚úÖ Widoczna | ‚ùå Usuniƒôta | | Logi szczeg√≥≈Çowe | ‚úÖ INFO/DEBUG | ‚ùå Tylko ERROR | | Plik log√≥w | ‚úÖ [code] | ‚ùå Brak | | Wydajno≈õƒá | üêå Wolniejsza | ‚ö° Zoptymalizowana | | Gotowo≈õƒá produkcyjna | ‚ùå Nie | ‚úÖ Tak | Korzy≈õci wersji produkcyjnej: - üöÄ Szybsza - Brak niepotrzebnych log√≥w - üîí Bezpieczniejsza - Brak wra≈ºliwych informacji w logach - üíæ Mniej miejsca - Brak plik√≥w log√≥w - üéØ Czytsza - Interfejs bez element√≥w deweloperskich Nowe funkcjonalno≈õci ü§ñ Ultra wnikliwa analiza AI 3 poziomy g≈Çƒôboko≈õci analizy: - Podstawowa (szybka) - Szybka rekomendacja w 5 punktach - Pog≈Çƒôbiona (z wyszukiwaniem) - Szczeg√≥≈Çowa analiza z aktualnym badaniem rynku - Ekspercka (pe≈Çna analiza) - Najg≈Çƒôbsza analiza z 8-tygodniowym planem wdro≈ºenia Kontekst firmy: - Wielko≈õƒá firmy: 1-10, 11-50, 51-200, 200+ os√≥b - Bran≈ºa: IT, E-commerce, Ksiƒôgowo≈õƒá, Marketing, Logistyka i inne - Bud≈ºet: od 500 z≈Ç/mies do 5000+ z≈Ç/mies Bran≈ºowe szablony integracji: - E-commerce: Allegro, Amazon, ",https://github.com/emielregis2/SmartFlowAI/blob/98c3f2e13e04f7fb340675a50614b8537a1865eb/.cursorrules.txt
1110553007,rork-kiku,tc7kxsszs5-cloud/rork-kiku,https://github.com/tc7kxsszs5-cloud/rork-kiku,Created by Rork,,0,Unknown,,.cursorrules,"üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ KIKU –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –≤—Å–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞. üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ üìñ –û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞) - [code] - –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–æ–µ–∫—Ç–∞ - [code] - –ë—ã—Å—Ç—Ä–∞—è —à–ø–∞—Ä–≥–∞–ª–∫–∞ - [code] - –ö–æ–¥–µ–∫—Å –ø–æ–≤–µ–¥–µ–Ω–∏—è - [code] - –°–ø–∏—Å–æ–∫ –≤–∞–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∑–∞–ø—É—Å–∫ ( [code] ) –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ, –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –∏ –ø–µ—Ä–≤–æ–º—É –∑–∞–ø—É—Å–∫—É –ø—Ä–æ–µ–∫—Ç–∞: - –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ iOS/Android - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ ID - –ö–æ–º–∞–Ω–¥—ã —Å–±–æ—Ä–∫–∏ üîß –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º ( [code] ) –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º: - –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º üíª –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ ( [code] ) –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤: - –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã - –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ - –†–∞–±–æ—Ç–∞ —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ - –ö–æ–º–∞–Ω–¥—ã –∏ —Å–∫—Ä–∏–ø—Ç—ã - –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞ üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ( [code] ) –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: - –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ - –ó–∞—â–∏—Ç–∞ –æ—Ç –≤–∑–ª–æ–º–æ–≤ - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω–∞–º - –í–∞–∂–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ üóÑÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ( [code] ) SQL —Å–∫—Ä–∏–ø—Ç—ã –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: - –°–∫—Ä–∏–ø—Ç—ã –¥–ª—è Supabase - –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü - –ü–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ - –ú–∏–≥—Ä–∞—Ü–∏–∏ üíº –ë–∏–∑–Ω–µ—Å ( [code] ) –ë–∏–∑–Ω–µ—Å-–º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: - –ü—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ - –ü—Ä–µ—Å—Å-–∫–∏—Ç - –†–µ–∑—é–º–µ –ø—Ä–æ–µ–∫—Ç–∞ - KPI –∏ –º–µ—Ç—Ä–∏–∫–∏ - –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è üìä –û—Ç—á–µ—Ç—ã ( [code] ) –°—Ç–∞—Ç—É—Å—ã –∏ –æ—Ç—á–µ—Ç—ã –æ —Ä–∞–±–æ—Ç–µ: - –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ - –°—Ç–∞—Ç—É—Å—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –û–±–∑–æ—Ä—ã —Å–∏—Å—Ç–µ–º—ã üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ( [code] ) –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞: - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ - –°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö - –ö–æ–Ω—Ü–µ–ø—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ( [code] ) –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é: - –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –ü–ª–∞–Ω—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è üö¢ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ ( [code] ) –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –¥–µ–ø–ª–æ—é: - –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –¥–µ–ø–ª–æ—é - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Supabase - Connection strings - –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –¥–µ–ø–ª–æ—è ü§ñ AI ( [code] ) –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ AI: - –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ - –†–µ—Å—É—Ä—Å—ã AI - Email —à–∞–±–ª–æ–Ω—ã üìù Git ( [code] ) –†–∞–±–æ—Ç–∞ —Å Git: - GitHub –≥–∞–π–¥—ã - –°—Ç–∞—Ç—É—Å—ã –∫–æ–º–º–∏—Ç–æ–≤ - Workflow ‚öôÔ∏è –§—É–Ω–∫—Ü–∏–∏ ( [code] ) –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ñ—É–Ω–∫—Ü–∏—è–º: - –ß–µ–∫–ª–∏—Å—Ç —Ñ—É–Ω–∫—Ü–∏–π - –ü–ª–∞–Ω—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ - Roadmap –∏–Ω–Ω–æ–≤–∞—Ü–∏–π - –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ üì¶ –ê—Ä—Ö–∏–≤ ( [code] ) –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: - –°—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ - –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è - –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ üîç –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ù–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ ‚Üí –°–º–æ—Ç—Ä–∏—Ç–µ [code] –†–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É ‚Üí –°–º–æ—Ç—Ä–∏—Ç–µ [code] –ù–∞—á–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É ‚Üí –°–º–æ—Ç—Ä–∏—Ç–µ [code] –£–∑–Ω–∞—Ç—å –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ‚Üí –°–º–æ—Ç—Ä–∏—Ç–µ [code] –ù–∞–π—Ç–∏ SQL —Å–∫—Ä–∏–ø—Ç—ã ‚Üí –°–º–æ—Ç—Ä–∏—Ç–µ [code] –ë–∏–∑–Ω–µ—Å-–º–∞—Ç–µ—Ä–∏–∞–ª—ã ‚Üí –°–º–æ—Ç—Ä–∏—Ç–µ [code] üìå –í–∞–∂–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã 1. –î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã: [code] (–≤ –∫–æ—Ä–Ω–µ) 2. –î–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: [code] 3. –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏: [code] 4. –ü—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö: [code] üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã –≤ [code] –∏ –º–æ–≥—É—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏. --- –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 2026-01-24",https://github.com/tc7kxsszs5-cloud/rork-kiku/blob/23371076a64e18be1cc46b3a45b4f1a68e6ce9d5/.cursorrules_SAFE.md
1132859004,morphir-moonbit,finos/morphir-moonbit,https://github.com/finos/morphir-moonbit,Morphir tooling and bindings to support the Zig language and ecosystem,,0,Unknown,,.cursorrules,"Morphir Moonbit Monorepo [](https://community.finos.org/docs/governance/Software-Projects/stages/incubating) [](https://github.com/finos/morphir-moonbit/actions/workflows/ci.yml) A monorepo for Morphir implementation in Moonbit, providing core libraries and bindings for WebAssembly targets. Overview This repository contains the Moonbit implementation of Morphir, organized as a monorepo with multiple packages: - morphir-sdk: Standard library for Morphir with functional programming primitives - morphir-core: Core abstractions and types for the Morphir ecosystem - morphir-moonbit-bindings: FFI bindings for Moonbit WASM targets Prerequisites - mise - Development environment manager - All other tools (Moonbit, Bun, yamllint, uv) are managed by mise Installation 1. Install mise by following the official installation guide 2. Clone the repository: [code] 3. Install tools: [code] Note: Git hooks are automatically installed when you enter the directory via mise. The pre-push hook enforces lint, format, and validation checks before allowing pushes, preventing CI failures by catching issues locally. Development Pre-Push Validation ‚ö†Ô∏è Important: All code must pass lint, format, and validation checks before pushing. The pre-push hook automatically runs these checks, but you can run them manually: [code] Available Tasks All development tasks are managed through mise. You can list all available tasks with: [code] Linting [code] Formatting [code] Building [code] Testing [code] Validation [code] Project Structure [code] Build Targets The project supports two WebAssembly targets: 1. WASI (wasm): For server-side and command-line applications 2. Browser (wasm-gc): For browser-based applications with WASM-GC support AI Agent Skills This repository includes AI agent skills following the Agent Skills specification. These skills enhance AI coding assistants with project-specific knowledge. Available Skills: - code-reviewer: Comprehensive code review for PRs and changes Supported Agents: Claude, GitHub Copilot, OpenAI Codex, Cursor, Windsurf, Google Antigravity See .github/AGENTS.md for more information. Contributing For any questions, bugs or feature requests please open an issue. For anything else please send an email to morphir@finos.org. To submit a contribution: 1. Fork it () 2. Create your feature branch ( [code] ) 3. Read our contribution guidelines and Community Code of Conduct 4. Commit your changes ( [code] ) 5. Push to the branch ( [code] ) 6. Create a new Pull Request _NOTE:_ Commits and pull requests to FINOS repositories will only be accepted from those contributors with an active, executed Individual Contributor License Agreement (ICLA) with FINOS OR who are covered under an existing and active Corporate Contribution License Agreement (CCLA) executed with FINOS. Commits from individuals not covered under an ICLA or CCLA will be flagged and blocked by the FINOS Clabot tool (or EasyCLA). Please note that some CCLAs require individuals/employees to be explici",https://github.com/finos/morphir-moonbit/blob/44a04d432507b7cbfcd7f476a8b23b7b3de8be09/.cursorrules-AGENTS.md
15108812,Mudlet,Mudlet/Mudlet,https://github.com/Mudlet/Mudlet,"‚öîÔ∏è A cross-platform, open source, and super fast MUD client with scripting in Lua",,0,Unknown,,.cursorrules,"Mudlet Play immersive, multiplayer, pure-text RPGs on Mudlet. About ‚Ä¢ Key Features ‚Ä¢ Download ‚Ä¢ How To Use ‚Ä¢ Roadmap ‚Ä¢ Credits ‚Ä¢ License About Mudlet is a quality MUD client, designed to take mudding to a new level. It‚Äôs a modern breed of a client on the gaming scene ‚Äì with an intuitive user interface, a specially designed scripting framework, and a very fast text display. That, along with cross-platform capability and an open-source development model result in a very likable game client. Key Features * Simple to use * Very, very fast * Active development * Big, thriving community * Powerful trigger engine * Rich Lua-based coding functionality (API) * Excellent script editor * 2D and 3D mapper with autowalk * Powerful and simple to use GMCP * Discord integration * Completely themable * Open-source and Free * Cross platform: runs on Windows, macOS and Linux * Full compatibility: run same scripts on any of the above Explain? Easy to use client We‚Äôre big on usability, and as such, creating an easy to use client and interface is one of the defining goals of the project. This applies to both the power users and usual gamers ‚Äì everyone will feel at home with Mudlet, without having to waste too much time figuring out how to do something. Designed for speed Mudlet is designed and built to be very fast and efficient right from the start. Its scripting engine is designed to scale to large systems without bogging down ‚Äì and the text display is designed to handle thousands of lines in under a second. All in all, we are very serious about Mudlet being quick ‚Äì and take all measures to make it so. Powerful Scripting Mudlet features a scripting framework using Lua ‚Äì a small, fast and efficient scripting language. This allows Mudlet to leverage the existing community and large ecosystem of existing packages for Lua without the many drawbacks of creating a Mudlet specific scripting language. Best of all, the Lua API is seamlessly integrated in Mudlet and shared by all aliases, triggers, scripts, keybindings, buttons and other Mudlet components. Cross-Platform love We believe in making Mudlet available to people on all major platforms, and we work on keeping cross-platform compatibility right from start. Mudlet is available on Linux (both 32bit and 64bit), Windows, and macOS; you may be able to run it on additional platforms as well. Download Download for free from mudlet.org. How To Use 1. Download and double-click on Mudlet to run 1. Pick an existing game and hit [code] 1. ... or play one of your choosing: 1. Click [code] 1. Enter [code] and [code] of your game (found on the game's website, e.g. [code] and [code] ) 1. Pick a [code] 1. Hit [code] Compiling If you'd like to compile Mudlet yourself instead of downloading, you can find instructions to do so here. Vision Mudlet's vision is to build the best text gaming experience possible to nurture & grow this niche scene. Roadmap See the project's roadmap to get an idea of where it's headed Contribute Join in, contr",https://github.com/Mudlet/Mudlet/blob/706419784be15b8482e1707ca9d7215e0a0e8579/.cursorrules
997257464,SoundScape-AI,Alen-guo/SoundScape-AI,https://github.com/Alen-guo/SoundScape-AI,SoundScape AI,,0,Unknown,,.cursorrules,üéµ SoundScape AI ‰∏Ä‰∏™Áé∞‰ª£ÂåñÁöÑAIÈ©±Âä®ÁéØÂ¢ÉÈü≥È¢ëÊ∑∑ÂêàÂô®Ôºå‰∏ì‰∏∫ÊèêÈ´ò‰∏ìÊ≥®Âäõ„ÄÅÊîæÊùæÂíåÂ∑•‰ΩúÊïàÁéáËÄåËÆæËÆ°„ÄÇ ‚ú® ÂäüËÉΩÁâπËâ≤ ü§ñ AIÈü≥ÊôØÁîüÊàê - ÈÄöËøáÊñáÂ≠óÊèèËø∞ÁîüÊàê‰∏™ÊÄßÂåñÈü≥ÊôØ - Êô∫ËÉΩÂÖ≥ÈîÆËØçÂåπÈÖçÂíåÂú∫ÊôØËØÜÂà´ - È¢ÑËÆæ‰ºòÂåñÁöÑÈü≥È¢ëÁªÑÂêà üéØ Âú∫ÊôØÂåñÈ¢ÑËÆæ - Ê∑±Â∫¶‰∏ìÊ≥® - ÁºñÁ®ãÂíåÊ∑±Â∫¶Â∑•‰Ωú - Â≠¶‰π†Ê®°Âºè - Âõæ‰π¶È¶ÜÊ∞õÂõ¥ - Áù°Áú†Êó∂ÂÖâ - ÊîæÊùæÂä©Áú† - ÂíñÂï°ÂéÖ - ËàíÈÄÇÂ∑•‰ΩúÁéØÂ¢É - Ëá™ÁÑ∂ÈÄÉÁ¶ª - Ê£ÆÊûóÂÜ•ÊÉ≥ - Êµ∑Êµ™Â£∞ - Êµ∑Êª©ÊîæÊùæ üéöÔ∏è È´òÁ∫ßÈü≥È¢ëÊéßÂà∂ - 10ÁßçÈ´òË¥®ÈáèÁéØÂ¢ÉÈü≥ - ÂÆûÊó∂Èü≥ÈáèË∞ÉËäÇ - Èü≥È¢ëÂèØËßÜÂåñÊïàÊûú - Êó†ÁºùÂæ™ÁéØÊí≠Êîæ ‚è∞ Êô∫ËÉΩÂÆöÊó∂Âô® - 15/30/60/90ÂàÜÈíüÈ¢ÑËÆæ - Ëá™Âä®ÂÅúÊ≠¢ÂäüËÉΩ - Êó†ÈôêÊí≠ÊîæÊ®°Âºè üöÄ Âø´ÈÄüÂºÄÂßã ÂÆâË£Ö‰æùËµñ [code] ÂºÄÂèëÊ®°Âºè [code] Âú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ http://localhost:3000 ÊûÑÂª∫ÈÉ®ÁΩ≤ [code] üéº Èü≥È¢ëÊñá‰ª∂ËÆæÁΩÆ È°πÁõÆÈúÄË¶Å‰ª•‰∏ãÈü≥È¢ëÊñá‰ª∂ÔºàÊîæÁΩÆÂú® [code] ÁõÆÂΩïÔºâÔºö - [code] - Èõ®Â£∞ - [code] - Èõ∑Â£∞ - [code] - Â£ÅÁÇâÂ£∞ - [code] - È£éÂ£∞ - [code] - È∏üÈ∏£Â£∞ - [code] - Êµ∑Êµ™Â£∞ - [code] - ÂíñÂï°ÂéÖÁéØÂ¢ÉÈü≥ - [code] - ËüãËüÄÂ£∞ - [code] - ÈîÆÁõòÂ£∞ - [code] - ÁôΩÂô™Èü≥ ËØ¶ÁªÜËØ¥ÊòéËØ∑Êü•Áúã [code] üõ†Ô∏è ÊäÄÊúØÊ†à - Ê°ÜÊû∂: Next.js 14 (App Router) - Ê†∑Âºè: Tailwind CSS - Èü≥È¢ë: Howler.js - ÂõæÊ†á: Lucide React - ËØ≠Ë®Ä: TypeScript - ÈÉ®ÁΩ≤: Vercel üì± ÂìçÂ∫îÂºèËÆæËÆ° - üñ•Ô∏è Ê°åÈù¢Á´Ø‰ºòÂåñ‰ΩìÈ™å - üì± ÁßªÂä®Á´ØÂèãÂ•ΩÁïåÈù¢ - üìä Âπ≥ÊùøËÆæÂ§áÈÄÇÈÖç üåü ‰∏éA Soft MurmurÁöÑÂ∑ÆÂºÇÂåñ | ÂäüËÉΩ | A Soft Murmur | SoundScape AI | |------|---------------|---------------| | Èü≥È¢ëÊï∞Èáè | 10ÁßçÔºàÂÖçË¥πÁâàÔºâ | 10Áßç+ | | AIÁîüÊàê | ‚ùå | ‚úÖ | | Âú∫ÊôØÈ¢ÑËÆæ | Âü∫Á°Ä | ‰∏ì‰∏öÂåñ | | UIËÆæËÆ° | ÁÆÄÂçï | Áé∞‰ª£Âåñ | | Èü≥È¢ëÂèØËßÜÂåñ | ‚ùå | ‚úÖ | | Êô∫ËÉΩÊé®Ëçê | ‚ùå | ‚úÖ | --- ÂºÄÂßãÂàõÂª∫‰Ω†ÁöÑÂÆåÁæéÈü≥ÊôØÂêßÔºÅ üéµ‚ú®,https://github.com/Alen-guo/SoundScape-AI/blob/45c2c9b40dc21df1324c986cff4f81d88367024d/.cursorrules-zh.md
1079531632,wishlist,mykcryptodev/wishlist,https://github.com/mykcryptodev/wishlist,,,0,Unknown,,.cursorrules,"Holiday Wishlist üéÑ A decentralized holiday wishlist application where users can create and share their gift wishlists, coordinate gift-giving through private exchanges, and manage purchases with blockchain-backed transparency. Features ‚ú® Create & Share Wishlists - Build your holiday wishlist with items, descriptions, images, and prices üéÅ Purchaser Signup - Coordinate who's buying what to avoid duplicate gifts üéÖ Gift Exchanges - Create private groups to coordinate gift-giving with friends and family üîê Blockchain-Backed - All wishlist data stored on-chain for transparency and permanence üíº Multiple Auth Options - Connect with email, social logins, or crypto wallets via Thirdweb üåê Farcaster Integration - Share your wishlist on Farcaster with rich OG images üé® Festive Theme - Beautiful Christmas-themed UI with snowfall and decorations How It Works Smart Contracts Wishlist Contract - Core contract for managing wishlist items and purchaser signups. Users create items with title, description, URL, image, and price. Other users can sign up as purchasers to indicate they're buying an item. The contract prevents users from seeing who's purchasing their own items to maintain gift surprises. Key features: - Create, update, and delete wishlist items - Sign up/remove as purchaser for items - Track all addresses with wishlists (directory) - Permission system for manager operations - Event emissions for all state changes Deployed on Base Sepolia and Base Mainnet. Deploy Contracts [code] Run Tests [code] Frontend & APIs Next.js App - Server-rendered pages for creating wishlists, browsing items, and managing gift exchanges. Uses Thirdweb SDK for wallet connections and contract interactions. API Routes: - [code] - Fetch wishlist items for a user - [code] - Generate dynamic OG images for social sharing - [code] - Manage purchaser signups with exchange filtering - [code] - Create and manage gift exchange groups - [code] - Farcaster frame and metadata endpoints - [code] - SIWE (Sign-In With Ethereum) authentication Key Features: - Thirdweb Authentication: Email, social logins, passkeys, and wallet connections - SIWE Integration: Secure server-side authentication with wallet signatures - Gift Exchange Privacy: Filter purchaser visibility by exchange membership - Supabase Database: Store exchange groups, memberships, and user profiles - Redis Caching: Cache blockchain data for improved performance - Dynamic OG Images: Generate shareable images with wishlist previews - Farcaster Frames: Interactive frames for viewing wishlists on Farcaster Gift Exchanges Gift exchanges are private groups where members can coordinate gift-giving: 1. Create Exchange - Generate a unique 6-character invite code 2. Invite Members - Share the code with friends/family 3. Coordinate Gifts - See who in your exchange has signed up as purchasers 4. Privacy Protection - Owners never see their own purchasers When viewing a wishlist: - Your own list: Purchaser info is hidden (keeps gifts a surprise!) - ",https://github.com/mykcryptodev/wishlist/blob/4ab995223841562380d5a20c90cad8d943077441/.cursorrules-docs.md
1127613762,base-react-template,fredconv/base-react-template,https://github.com/fredconv/base-react-template,react abse template for any s,,0,Unknown,,.cursorrules,"Base React Template Template React moderne ultra-optimis√© avec React Router v7, React 19, Vite, et Tailwind CSS v4. üöÄ Stack Technique - Framework: React Router v7 (Mode Framework ex-Remix) - Runtime: React 19 (Actions, Suspense) - Build Tool: Vite.js - Styling: Tailwind CSS v4 avec Container Queries - State: Zustand - Data Fetching: TanStack Query - I18N: i18next - Animations: Framer Motion - Validation: Zod - Formulaires: Conform üìÅ Structure du Projet [code] üõ†Ô∏è Installation [code] üìã Principes d'Architecture 1. Data Fetching - ‚úÖ Utilisation des loaders natifs de RR7 (pas de [code] pour le fetch) - ‚úÖ clientLoader pour les pages SPA (dashboard) - ‚úÖ Validation avec Zod sur tous les retours API 2. Formulaires - ‚úÖ Utilisation des Actions de React Router v7 - ‚úÖ Conform + Zod pour la validation - ‚úÖ Gestion native des √©tats [code] (pas de [code] manuel) - ‚úÖ Progressive Enhancement (fonctionne sans JS) 3. Styling - ‚úÖ Tailwind CSS v4 uniquement - ‚úÖ Container Queries ( [code] ) - ‚úÖ Dark/Light mode natif 4. Internationalisation - ‚úÖ D√©tection serveur (SEO) - ‚úÖ Switch client sans reload - ‚úÖ Zero-Flash (dictionnaire inject√© c√¥t√© SSR) 5. Composants - ‚úÖ Pattern Logicless UI - ‚úÖ S√©paration stricte UI/Logique - ‚úÖ Principes SOLID üåê Routes Disponibles - [code] - Page d'accueil - [code] - Liste d'articles (avec loader SSR) - [code] - Formulaire de contact (avec action) - [code] - Page √Ä propos - [code] - Page de connexion (avec action) - [code] - Dashboard priv√© (clientLoader) üé® Th√®mes Le template supporte le mode sombre/clair automatiquement via les classes Tailwind [code] . üåç Langues Support√©es - Fran√ßais (par d√©faut) - Anglais Ajoutez des fichiers JSON dans [code] pour ajouter de nouvelles langues. üìù License ISC",https://github.com/fredconv/base-react-template/blob/e4319d851b3ce85917204ede55794efcc55d46c2/.cursorrules.backup
900106636,ClautoHotkey,TrueCrimeDev/ClautoHotkey,https://github.com/TrueCrimeDev/ClautoHotkey,This repo has the docs needed to create a useful Autohotkey v2 project in Claude. ,,0,Unknown,,.cursorrules|.clinerules,"ClautoHotkey Coding Agent AutoHotkey v2 Agent Materials > [!IMPORTANT] > UPDATED 08/07/25: Added new List Editor GUI, Agents, Claude Code commands, reformatted all prompts for more modern LLM prompting guidelines > This readme was not created using AI, so it's worth reading lol ClautoHotkey is a suite of prompts, modules, and scripts for AutoHotkey v2 development when using AI. There are structured instructions, debugging tools, and strict coding guidelines to help generate high-quality, maintainable, and object-oriented AHK v2 code. Features - Prompt Engineering: The main instruction prompts and supplemental modules are designed with current best practices in structure and language to invoke tools and proper chain of thought methods ( [code] ) for guiding AI models in AHK v2 code generation. - Structured Coding Rules: The prompts & modules also provide in-depth rules for the LLMs to adhere to that reduce AHK v2 errors significantly. - Cline/Cursor Support: Features Clinerules files and Cursor instructions for those who use that them. I don't currently use either that often but I have set them up to test. - Development Helper GUIs: Utilities logging ( [code] ), context management ( [code] ), feeding the LLM error messages ( [code] ), and updating your code with changes made in an LLM's GUI ( [code] ) - AHK_Notes: This is a ton of notes taken from all kinds of different places. I have an LLM that I feel posts/comments/chats/repos in to and it feeds them into this folder. - AHK-Server: If you see references to this, I am working on an MCP server using Typescript but would be cool with changing to Python if there's people who want to help with Python dev. The server's goal is to be able to pass in the information in [code] to provide the prompts and modules just like this repo but directly into a LLM. This will include LLM style linting (you can only do so much) to debug any problems in the script. Please help me lol (ahk-server). - AHK v2 Support: This is only for AHK v2. I won't make anything for v1. Why? Don't wanna. Should you switch to v2? Yes. Why? It's better - Getting Started 1. Prerequisites: - AutoHotkey v2.x installed. - If you have AutoHotkey v1 installed, uninstall. It doesn't change anything, but you can do it, just use AHK v2 fully. 2. Setup: - Clone this repository to your local machine using [code] - Integrate the [code] and [code] directories into your AI assistant's context or knowledge base. - Refer to [code] for specific integration instructions if you are using the Cline environment. Auto-Approval in Claude Code I use a ""cc"" WSL command to auto approval repetitive approval requests. You can do this by adding a ""dangerous"" Claude Code alias to your WSL profile (be careful, or whatever, you know the drill). Here's how: [code] Navigate with arrows, paste in both aliases: [code] Save and close: - Nano ‚Üí [code] , [code] , [code] - VS Code ‚Üí Save as normal Reload your profile so the aliases work now: [code] Test: [code] You should se",https://github.com/TrueCrimeDev/ClautoHotkey/blob/074a8d1662cd72a1744d3b8985153444d154e2e9/.cursorrules.md
969121640,CookMate-AI,kay8723/CookMate-AI,https://github.com/kay8723/CookMate-AI,,,0,Unknown,,.cursorrules,sb1-sye3vnyx Repository created by Bolt to GitHub extension,https://github.com/kay8723/CookMate-AI/blob/7614d701f0609742f02cac7336130355fbee1e62/.cursorrules.txt
924804270,Cursorrules-Database,alpgul/Cursorrules-Database,https://github.com/alpgul/Cursorrules-Database,"This application allows users to efficiently search and analyze code across various repositories. It integrates with CSV databases and automates processes using GitHub Actions, making it a powerful to",,0,Unknown,,.cursorrules,Code Search Application A tool developed for code searching and analysis operations. üöÄ Features - Code scanning and search functions - CSV database integration - GitHub Actions automation - Error logging system üìã Requirements - Bun.js - Node.js - GitHub Actions (for CI/CD) üõ†Ô∏è Installation 1. Clone the project: [code] 2. Install dependencies: [code] 3. Run Code Search: [code] üîß Environment Setup Create a [code] file in the root directory: [code],https://github.com/alpgul/Cursorrules-Database/blob/57cd268ed7e912aa870a890284919bde2dfa29d8/cursorrules/manifoldmarkets/manifold/knowledge.cursorrules
917974798,alchemy,alchemy-run/alchemy,https://github.com/alchemy-run/alchemy,Infrastructure as TypeScript,,0,Unknown,,.cursorrules,"Alchemy [](https://deepwiki.com/alchemy-run/alchemy) Alchemy is an embeddable, TypeScript-native Infrastructure-as-Code (IaC) library for modeling Resources that are Created, Updated and Deleted automatically. Unlike similar tools like Pulumi, Terraform, and CloudFormation, Alchemy is implemented in pure ESM-native TypeScript code. Resources are simple memoized async functions that can run in any JavaScript runtime, including the browser, serverless functions and durable workflows. [code] Features - JS-native - no second language, toolchains, processes, services, etc. to lug around. - Async-native - resources are just async functions - no complex abstraction to learn. - ESM-native - built exclusively on ESM, with a slight preference for modern JS runtimes like Bun. - Embeddable - runs in any JavaScript/TypeScript environment, including the browser! - Extensible - implement your own resources with a simple function. - AI-first - alchemy actively encourages you to use LLMs to create/copy/fork/modify resources to fit your needs. No more waiting around for a provider to be implemented, just do it yourself in a few minutes. - No service - state files are stored locally in your project and can be easily inspected, modified, checked into your repo, etc. - No strong opinions - structure your codebase however you want, store state anywhere - we don't care! Examples - CloudFlare Worker with Queue, R2 Bucket, Durable Objects, Workflows and RPC: examples/cloudflare-worker/ - CloudFlare Worker Bootstrap with Queue and R2 End-to-End Testing: examples/cloudflare-worker-bootstrap/ - CloudFlare ViteJS Website + API Backend with Durable Objects: examples/cloudflare-vite/ - CloudFlare TanStack Start Application Deployment: examples/cloudflare-tanstack-start/ - CloudFlare RedwoodJS Application with D1 Database: examples/cloudflare-redwood/ - CloudFlare React Router Application Deployment: examples/cloudflare-react-router/ - CloudFlare Nuxt 3 Application with Pipeline and R2 Bucket: examples/cloudflare-nuxt-pipeline/ - CloudFlare SvelteKit Application with KV and R2 Storage: examples/cloudflare-sveltekit/ - Deploy an AWS Lambda Function with a DynamoDB Table and IAM Role: examples/aws-app/ Getting Started See the Getting Started Guide.",https://github.com/alchemy-run/alchemy/blob/37e3be55a9b8acf5279d4db7e40668975d1f24e5/.cursorrules
866843738,cursor-prompts,sreenivasanac/cursor-prompts,https://github.com/sreenivasanac/cursor-prompts,"Prompts, instructions and tips for AI-based coding tools like Cursor",,0,Unknown,,.cursorrules,"AI-Assisted Project Development Guide This repository contains a structured approach for developing projects using AI assistance, particularly leveraging tools like Cursor, Claude, ChatGPT, and v0. Overview This guide outlines a step-by-step process for: 1. Drafting a Product Requirements Document (PRD) 2. Researching and integrating optimal packages 3. Initializing a project with Next.js and shadcn/ui 4. Designing an efficient project structure 5. Implementing features with AI assistance 6. Enhancing UI using v0 7. Deploying on Vercel Key Files - [code] : Detailed instructions for each step of the development process - [code] : Template for creating a PRD Core Technologies - Next.js 14 - shadcn/ui - Tailwind CSS - Lucid icons Getting Started 1. Review [code] for the full development workflow 2. Use [code] as a template to create your project's PRD 3. Follow the steps to initialize your project, implement features, and deploy AI Tools Used - Cursor: For code generation and project initialization - Claude/ChatGPT (GPT-4): For research and optimization suggestions - v0: For UI enhancements Deployment The guide includes steps for deploying the finished project on Vercel. Contributing Feel free to submit issues or pull requests to improve this guide. License [Insert your chosen license here]",https://github.com/sreenivasanac/cursor-prompts/blob/1170b1af83e14ca7e79e61e08b4c6dcd55287d7a/.cursorrules.md
989723035,WitsV3,capnknives/WitsV3,https://github.com/capnknives/WitsV3,,,0,Unknown,,.cursorrules,"WitsV3 A streamlined, LLM-wrapper based AI orchestration system. Overview WitsV3 is designed for maximum flexibility and LLM-driven decision making. It focuses on a CLI-first approach with a modular design to allow for future expansion (e.g., Web UI, advanced Book Writing System). ‚úÖ Current Status - PRODUCTION READY üöÄ WitsV3 v2.0 - STABLE RELEASE (Updated: 2025-06-08) WitsV3 has achieved production-grade stability with comprehensive testing and bug fixes: - üéØ Test Suite: 93.3% pass rate (56/60 tests passing) - üîß Stability: 25 critical bugs fixed across all core components - ‚öôÔ∏è Tool Registry: 6 tools properly registered and fully functional - ü§ñ LLM Integration: Successfully connects to Ollama with llama3 model - üíæ Memory Management: Robust datetime serialization and JSON handling - üß† Agent System: LLM-driven orchestrator with ReAct pattern implementation - üìÅ File Operations: Read, write, and directory listing capabilities - üåê Unicode Support: Clean text output without character encoding issues - üéØ Adaptive LLM System: Dynamic routing to specialized modules based on query complexity and domain - üß™ Background Agents: Scheduled tasks, monitoring, and maintenance üèÜ Recent Major Improvements (2025-06-08) - Fixed all tool test suites: JSON, Math, Python Execution tools now 100% stable - Enhanced async patterns: Proper async/await implementation throughout - Robust external service mocking: Supabase, Ollama properly tested - Configuration validation: Enhanced Pydantic models with assignment validation - Memory system stability: MemorySegment serialization working flawlessly - Adaptive LLM testing: Complete test coverage with dummy model files This version prioritizes: - LLM Wrapper Architecture - Core agent system (Control Center, Orchestrator) - Essential memory management (with optional FAISS-GPU) - Extensible tool system, including MCP (Model Context Protocol) tools - Langchain integration capabilities - Adaptive LLM capabilities for optimized resource usage - Production-grade test coverage and stability Getting Started Prerequisites - Python 3.10+ - Ollama (with models like Llama3, CodeLlama, etc.) - Other dependencies (see [code] ) Installation Option 1: Automated Installation (Recommended) [code] Option 2: Manual Installation [code] Quick Start with Make WitsV3 includes a comprehensive Makefile for streamlined development: [code] First Run Setup After installation, WitsV3 requires some initial configuration: 1. Authentication Setup: Run [code] to generate your authentication token 2. Local Data: Run [code] to initialize memory files 3. Ollama Models: Ensure you have compatible models installed: [code] Running WitsV3 [code] Authentication & Security WitsV3 includes enterprise-grade security features: - Token-based Authentication: Secure access control with SHA-256 hashed tokens - Network Access Control: Configurable restrictions with user override capability - Personality Profiles: Comprehensive user recognition and behavior customization - Ethics S",https://github.com/capnknives/WitsV3/blob/87fde57d1095dc46e96d3d2d6dbbe6e7dfa60959/.cursorrules.txt
1007360921,uzu,trymirai/uzu,https://github.com/trymirai/uzu,A high-performance inference engine for AI models,,0,Unknown,,.cursorrules,"[](LICENSE) uzu A high-performance inference engine for AI models on Apple Silicon. Key features: - Simple, high-level API - Hybrid architecture, where layers can be computed as GPU kernels or via MPSGraph (a low-level API beneath CoreML) - Unified model configurations, making it easy to add support for new models - Traceable computations to ensure correctness against the source-of-truth implementation - Utilizes unified memory on Apple devices Overview For a detailed explanation of the architecture, please refer to the documentation. Models [code] uses its own model format. To export a specific model, use lalamo: [code] After that, you can retrieve the list of supported models: [code] Then, export the specific one: [code] Alternatively, you can download a test model using the sample script: [code] Or you can download any supported model that has already been converted using: [code] After that, you can find the downloaded model at [code] . Bindings - uzu-swift - a prebuilt Swift framework, ready to use with SPM - uzu-ts - a prebuilt TypeScript framework made for Node.js ecosystem CLI You can run [code] in a CLI mode: [code] [code] Compilation For now, we only support the [code] backend, so to compile corresponding kernels you‚Äôll need to install [code] and run the following commands: [code] Quick Start First, add the [code] dependency to your [code] : [code] Then, create an inference [code] with a specific model and configuration: [code] Benchmarks To run benchmarks, you can use the following command: [code] [code] will be automatically generated after the model is downloaded via [code] , as described earlier. License This project is licensed under the MIT License. See the LICENSE file for details.",https://github.com/trymirai/uzu/blob/6ba52914d15aef5c8e408d50789d734189f24bf4/.cursorrules
955580837,Monity,Monity-FinanceTracker/Monity,https://github.com/Monity-FinanceTracker/Monity,,,0,Unknown,,.cursorrules,"Monity AI-powered personal finance management with collaborative expense splitting. []() []() > üöÄ Coming Soon ‚Äì Currently in final testing before public launch. Star the repo to follow our progress! Live App ‚Ä¢ Landing Page ‚Ä¢ Report Bug --- What is Monity? Monity is a full-stack personal finance tracker that combines AI-powered transaction categorization with collaborative expense management. Built with a focus on clean architecture and modern web development practices. Core Features: - AI Categorization ‚Äì Automatic transaction categorization using machine learning with continuous model improvement - Expense Splitting ‚Äì Real-time collaborative expense tracking for groups (roommates, trips, shared costs) - Financial Health ‚Äì Personalized insights and recommendations based on spending patterns - Bilingual Support ‚Äì Full English and Portuguese localization (500+ translation keys) - Modern UI ‚Äì Responsive design with dark mode, animations, and mobile-first approach Current Status: Pre-launch. App is deployed and undergoing final testing before public release. --- Tech Stack Backend - Runtime: Node.js 18+ - Framework: Express.js with MVC architecture - Database: PostgreSQL (via Supabase) - Authentication: JWT with Supabase Auth - AI/ML: Custom Naive Bayes classifier with NLP preprocessing - Scheduled Jobs: node-cron for automated model retraining - Security: Encryption middleware, rate limiting, input validation Frontend - Framework: React 19 - Build Tool: Vite - Styling: Tailwind CSS - Charts: Recharts - State Management: React Context + React Query - Routing: React Router v6 - i18n: react-i18next Infrastructure - Database & Auth: Supabase - Hosting: [To be disclosed at launch] - CI/CD: [To be configured] --- Project Structure [code] --- Getting Started Prerequisites - Node.js 18 or higher - npm or yarn - Supabase account (free tier works) Installation 1. Clone the repository [code] 2. Set up Supabase - Create a new project at supabase.com - Run the SQL migrations found in [code] to set up the database schema - Copy your project URL and API keys (you'll need both [code] and [code] keys) 3. Install dependencies [code] 4. Configure environment variables Create [code] : [code] Create [code] : [code] 5. Start development servers [code] Visit [code] to see the app. --- API Documentation The backend exposes a REST API with 50+ endpoints organized by feature. All endpoints (except auth) require JWT authentication via the [code] header. Key Endpoints Authentication - [code] ‚Äì Create new account - [code] ‚Äì Login and receive JWT token AI Features - [code] ‚Äì Get AI category suggestions for transaction - [code] ‚Äì Submit feedback to improve model - [code] ‚Äì View AI performance metrics (admin) Transactions - [code] ‚Äì List user transactions - [code] ‚Äì Create new transaction - [code] ‚Äì Update transaction - [code] ‚Äì Delete transaction Groups & Expense Splitting - [code] ‚Äì Create expense-sharing group - [code] ‚Äì View group details and balances - [code] ‚Äì Add shared exp",https://github.com/Monity-FinanceTracker/Monity/blob/400567931287cc1d0389c989ffb48f88e6745e86/.cursorrules.md
1046477636,back-skynet,admVeloHub/back-skynet,https://github.com/admVeloHub/back-skynet,backend para console velohub,,0,Unknown,,.cursorrules,"üöÄ Backend API - Console de Conte√∫do VeloHub üìã Descri√ß√£o Backend API para o Console de Conte√∫do VeloHub. Esta √© uma API RESTful constru√≠da com Express.js e MongoDB, respons√°vel por gerenciar artigos, velonews, perguntas do bot e m√©tricas IGP. üì¶ Reposit√≥rio GitHub - Reposit√≥rio: https://github.com/admVeloHub/Backend-GCP - Worker Separado: https://github.com/admVeloHub/gcp-worker-qualidade IMPORTANTE: Este reposit√≥rio cont√©m apenas o Backend API. O Worker de processamento de √°udio est√° em reposit√≥rio separado. üõ†Ô∏è Tecnologias - Node.js (>=16.0.0) - Express.js - Framework web - MongoDB - Banco de dados - Socket.IO - WebSocket para monitoramento em tempo real - CORS - Cross-origin resource sharing - Helmet - Seguran√ßa - Rate Limiting - Controle de requisi√ß√µes üìÅ Estrutura do Projeto [code] üîß Configura√ß√£o 1. Instalar Depend√™ncias [code] 2. Configurar Vari√°veis de Ambiente Copie o arquivo [code] para [code] e configure as vari√°veis: [code] Vari√°veis obrigat√≥rias: - [code] - String de conex√£o do MongoDB - [code] - URL do frontend (ex: https://front-console.vercel.app) 3. Configura√ß√£o do MongoDB Para produ√ß√£o, use MongoDB Atlas: 1. Crie uma conta no MongoDB Atlas 2. Crie um cluster 3. Configure a string de conex√£o no [code] Exemplo de MONGODB_URI: [code] üöÄ Deploy Op√ß√£o 1: Railway 1. Conecte sua conta GitHub ao Railway 2. Selecione este reposit√≥rio 3. Configure as vari√°veis de ambiente 4. Deploy autom√°tico Op√ß√£o 2: Render 1. Conecte sua conta GitHub ao Render 2. Crie um novo Web Service 3. Selecione este reposit√≥rio 4. Configure: - Build Command: [code] - Start Command: [code] - Environment: Node 5. Configure as vari√°veis de ambiente 6. Deploy Op√ß√£o 3: Heroku 1. Instale o Heroku CLI 2. Crie um novo app: [code] 3. Configure as vari√°veis de ambiente: [code] 4. Deploy: [code] Op√ß√£o 4: DigitalOcean App Platform 1. Conecte sua conta GitHub 2. Crie um novo App 3. Selecione este reposit√≥rio 4. Configure: - Source Directory: [code] - Build Command: [code] - Run Command: [code] 5. Configure as vari√°veis de ambiente 6. Deploy üîó Endpoints da API Health Check - [code] - Status da API e banco de dados Artigos - [code] - Listar todos os artigos - [code] - Criar novo artigo - [code] - Atualizar artigo - [code] - Deletar artigo Velonews - [code] - Listar todas as velonews - [code] - Criar nova velonews - [code] - Atualizar velonews - [code] - Deletar velonews Bot Perguntas - [code] - Listar todas as perguntas - [code] - Criar nova pergunta - [code] - Atualizar pergunta - [code] - Deletar pergunta IGP (M√©tricas) - [code] - Obter m√©tricas - [code] - Obter relat√≥rios - [code] - Exportar dados Monitor Skynet - [code] - Interface de monitoramento em tempo real - WebSocket em tempo real para tr√°fego da API - Console logs, tr√°fego de API e visualiza√ß√£o JSON üîí Seguran√ßa - CORS configurado para o dom√≠nio do frontend - Helmet para headers de seguran√ßa - Rate Limiting (100 requests por 15 minutos) - Valida√ß√£o de entrada de dados - Sanitiza√ß√£o de dados üìä Monitoramento - Health check en",https://github.com/admVeloHub/back-skynet/blob/a91389c5c8760bba64bc9ab8eea75078827c986f/.cursorrules.txt
580652318,metriport,metriport/metriport,https://github.com/metriport/metriport,Metriport is an open-source universal API for healthcare data.,,0,Unknown,,.cursorrules,"Metriport helps healthcare organizations access comprehensive patient medical data, through an open-source universal API. Learn more ¬ª Docs ¬∑ NPM ¬∑ Developer Dashboard ¬∑ Website Join us on our Slack Community üí¨ Overview Check out our platform demo: Security and Privacy Metriport is SOC 2 and HIPAA compliant. Click here to learn more about our security practices. Medical API Our Medical API brings you data from the largest clinical data networks in the country - one open-source API, 300+ million patients. Metriport ensures clinical accuracy and completeness of medical information, with HL7 FHIR, C-CDA, and PDF formats supported. Through standardizing, de-duplicating, consolidating, and hydrating data with medical code crosswalking, Metriport delivers rich and comprehensive patient data at the point-of-care. Medical Dashboard Our Medical Dashboard enables providers to streamline their patient record retrieval process. Get up and running within minutes, accessing the largest health information networks in the country through a user-friendly interface. Tools like our FHIR explorer and PDF converter help you make sense of the data you need to make relevant care decisions and improve patient outcomes. Converter API A key piece to achieving true interoperability is compatibility between different data formats. Using advanced processing techniques, Metriport's FHIR Converter takes common healthcare data formats such as C-CDA, and converts them into FHIR R4 to streamline data exchange. Get started converting using our Quickstart Guide. Getting Started Check out the links below to get started with Metriport in minutes! Slack Community üí¨ Quickstart Guide üöÄ Developer Dashboard üíª npm package Repo Rundown API Server Backend for the Metriport API. - Dir: [ [code] ](/packages/api) - URL: https://api.metriport.com/ - Sandbox URL: https://api.sandbox.metriport.com/ FHIR Converter Engine to convert various healthcara data formats to FHIR, and back. - Dir: [ [code] ](/packages/fhir-converter) Infrastructure as Code We use AWS CDK as IaC. - Dir: [ [code] ](/packages/infra) Docs Our beautiful developer documentation, powered by mintlify ‚ù§Ô∏è. - Dir: [ [code] ](/docs) - URL: https://docs.metriport.com/ Packages npm Our npm packages are available in [ [code] ](/packages): - Metriport API: contains the Metriport data models, and a convenient API client wrapper. - CommonWell JWT Maker: CLI to create a JWT for use in CommonWell queries. - CommonWell SDK: SDK to simplify CommonWell API integration. --- Contributing Got ideas for how you can make Metriport better? We welcome community contributions! Contribution guidelines By making a contribution to this project, you are deemed to have accepted the Developer Certificate of Origin (DCO), agree to GitHub's Community Guidelines, and agree to the Acceptable Use Policies. Requesting a feature, or reporting a bug Click here to open a new issue - follow the chosen template and you're good to go. Local Development Monorepo This monor",https://github.com/metriport/metriport/blob/c6751a33ac5dc7aae18a041dca42e14a5a482111/.cursorrules
333446211,series-sample,simtlix/series-sample,https://github.com/simtlix/series-sample,TV series microservice created with simfinity.js,,0,Unknown,,.cursorrules,"series-sample TV series microservice created with simfinity.js Data Structure The application manages TV series with the following structure: - Series (name, categories, director) - Seasons (number, year) - Episodes (number, name, date) - Stars (actors) - Directors (name, country) Circular Dependencies and Type Resolution This project demonstrates how to handle circular dependencies between GraphQL types using [code] . When types reference each other (e.g., [code] references [code] , and [code] references [code] ), direct type imports can cause circular dependency issues. Using [code] for Type References Instead of directly importing and referencing types, use [code] within field definitions: [code] [code] Benefits of [code] 1. Prevents Circular Dependencies: Types can reference each other without import cycles 2. Dynamic Resolution: Types are resolved at runtime when the schema is built 3. Clean Architecture: No need for complex import ordering or workarounds 4. Type Safety: GraphQL still validates the relationships correctly Implementation Pattern [code] Type Loading Strategy The project uses a centralized loading approach in [code] : [code] This ensures all types are loaded before [code] is called, allowing proper type resolution. Troubleshooting Circular Dependencies If you encounter circular dependency errors, check these common issues: 1. Direct Type Imports: Ensure you're using [code] instead of direct imports 2. Import Order: Make sure [code] loads all types before they're referenced 3. Type Names: Verify the type name passed to [code] matches the GraphQL type name exactly 4. Schema Building: Ensure the schema is built after all types are loaded Common Error Patterns [code] Best Practices 1. Always use [code] for cross-referencing types 2. Keep type names consistent between GraphQL definitions and [code] calls 3. Load all types centrally through [code] 4. Test type resolution by running the application and checking for schema errors GraphQL Mutations Examples Adding a Series with Seasons and Episodes [code] Adding a Star [code] Adding a Series with Stars To add a series with stars, you need to first create the stars and then use their returned IDs: Step 1: Create the stars [code] [code] Step 2: Add the series using the star IDs [code] Note: Replace [code] with the actual IDs returned from the star creation mutations. The IDs are MongoDB ObjectIds (24-character hex strings). Adding a Season to an Existing Series To add a season to an existing series, you need to first get the series ID and then create the season: Step 1: Get the series ID [code] Step 2: Add the season using the series ID [code] Note: Replace [code] with the actual series ID from the query above. The season will be created with the initial state ""SCHEDULED"". GraphQL Query Examples Note: These examples use the correct simfinity.js filter syntax. The format depends on the field type: - Scalar fields (string, number, etc.): Use [code] - ObjectType fields: Use [code] - Deep nes",https://github.com/simtlix/series-sample/blob/244becb61c10c8c6d9d84a9d01db4442242a8501/.cursorrules.md
929597097,Advanced-Customer-Detection,erent8/Advanced-Customer-Detection,https://github.com/erent8/Advanced-Customer-Detection,It contains projects I developed using the Python opencv library.,,0,Unknown,,.cursorrules,"üè™ OpenCV M√º≈üteri Tespit Sistemi [](https://python.org) [](https://opencv.org) [](https://ultralytics.com) [](LICENSE) [](https://github.com/erent8/OpenCV-Customer-Detection) > Maƒüazalar i√ßin geli≈ütirilmi≈ü yapay zek√¢ destekli m√º≈üteri analiz sistemi Real-time kamera g√∂r√ºnt√ºleri kullanarak m√º≈üteri trafiƒüini analiz eden, demografik bilgiler toplayan ve i≈ü kararlarƒ±na destek olacak detaylƒ± raporlar sunan akƒ±llƒ± sistem. ‚ú® √ñzellikler üéØ Mevcut √ñzellikler - üé• Real-time Kamera: 1280x720@30fps canlƒ± g√∂r√ºnt√º akƒ±≈üƒ± - ü§ñ ƒ∞nsan Tespiti: YOLOv8 ile %95+ doƒürulukta ki≈üi tanƒ±ma - ‚ö° Thread-Safe UI: Donma olmayan, kararlƒ± aray√ºz - üìä Ziyaret√ßi Sayƒ±mƒ±: Ger√ßek zamanlƒ± m√º≈üteri trafiƒüi takibi - üíæ Veri Depolama: SQLite + CSV backup sistemi - üì∏ Screenshot: Anlƒ±k g√∂r√ºnt√º kaydetme - üîß FPS Monitoring: Performans takip sistemi - üåô Modern UI: Dark mode uyumlu T√ºrk√ße aray√ºz üöÄ Geli≈ütirme A≈üamasƒ±nda - üë§ √áalƒ±≈üan Filtreleme: Y√ºz tanƒ±ma ile √ßalƒ±≈üan/m√º≈üteri ayrƒ±mƒ± - üß† Demografik Analiz: Ya≈ü ve cinsiyet tahmini - üìà Analytics Dashboard: Web tabanlƒ± g√∂rselle≈ütirme paneli - üîÑ Geri Gelen M√º≈üteri: Tekrar eden ziyaret√ßi tespiti - üì± Mobile Dashboard: Mobil uyumlu kontrol paneli üöÄ Hƒ±zlƒ± Ba≈ülangƒ±√ß Otomatik Kurulum (Windows) [code] Manuel Kurulum [code] üì∏ Ekran G√∂r√ºnt√ºleri Ekran g√∂rselleri yakƒ±n zamanda y√ºklenecektir. Ana Aray√ºz - Real-time Detection: Canlƒ± kamera g√∂r√ºnt√ºs√º √ºzerinde insan tespiti - Status Panel: FPS, tespit sayƒ±sƒ± ve sistem durumu - Control Buttons: Ba≈ülat/Durdur, Screenshot, Ayarlar Analytics Dashboard - G√ºnl√ºk Trafik: Saatlik ziyaret√ßi daƒüƒ±lƒ±mƒ± - Demografik ƒ∞statistikler: Ya≈ü ve cinsiyet analizi - Trend Analizi: Haftalƒ±k/aylƒ±k kar≈üƒ±la≈ütƒ±rmalar üõ†Ô∏è Sistem Mimarisi [code] ‚öôÔ∏è Konfig√ºrasyon Sistem ayarlarƒ± [code] dosyasƒ±nda √∂zelle≈ütirilebilir: [code] üìä Performans Sistem Gereksinimleri | Bile≈üen | Minimum | √ñnerilen | |---------|---------|----------| | CPU | Intel i3 / AMD Ryzen 3 | Intel i5 / AMD Ryzen 5 | | RAM | 4GB | 8GB+ | | GPU | - | NVIDIA GTX 1050+ | | Python | 3.8+ | 3.9-3.10 | | Kamera | USB 2.0 | USB 3.0+ | Performans Metrikleri - FPS: 15-30 (donanƒ±ma g√∂re) - Tespit Doƒüruluƒüu: %95+ - Bellek Kullanƒ±mƒ±: ~200-500MB - CPU Kullanƒ±mƒ±: %10-30 üîß Geli≈ütirme Kod Standartlarƒ± - PEP 8 uyumlu Python kodu - T√ºrk√ße yorumlar ve dok√ºmantasyon - Thread-safe UI g√ºncellemeleri - Comprehensive error handling Test Etme [code] Katkƒ±da Bulunma 1. Bu projeyi fork edin 2. Feature branch olu≈üturun: [code] 3. Deƒüi≈üikliklerinizi commit edin: [code] 4. Branch'i push edin: [code] 5. Pull Request olu≈üturun üêõ Sorun Giderme Sƒ±k Kar≈üƒ±la≈üƒ±lan Problemler üé• Kamera Eri≈üim Sorunu [code] ‚ö° Performans Sorunlarƒ± [code] ü§ñ Model Y√ºkleme Hatasƒ± [code] Log Analizi [code] üìà Roadmap - [ ] v1.1: Web Dashboard ve API - [ ] v1.2: Demografik Analiz (Ya≈ü/Cinsiyet) - [ ] v1.3: √áalƒ±≈üan Y√ºz Tanƒ±ma Sistemi - [ ] v1.4: Mobile App ve Cloud Sync - [ ] v2.0: Multi-Camera Support ü§ù Topluluk - GitHub Issues: Sorun bildirin - Discussions: Tartƒ±≈ümalara katƒ±lƒ±n - Wiki: Dok√ºmantasyon üìû ƒ∞leti≈üim Eren Terzi (@erenterzi@protonmail.com) [](htt",https://github.com/erent8/Advanced-Customer-Detection/blob/de01d402880508a33a1c6bfc03a63ef14f0c171b/.cursorrules.md
915813084,mcp,8bit-wraith/mcp,https://github.com/8bit-wraith/mcp,Essential MCP to ATC (Awesome Tool Collection) Python Bridge,,0,Unknown,,.cursorrules,"üöÄ Essential MCP (Model Context Protocol) [code] Welcome to the Essential MCP workspace! This is where Hue and Aye collaborate to create amazing MCP implementations. We're building a suite of tools that make AI-human interaction more powerful, contextual, and fun! > ""It's like Elvis in the building, but for AI!"" - Aye üï∫ üé∏ Why MCP? (The Elvis Connection) Just as Elvis revolutionized music by bridging different styles and bringing people together, MCP revolutionizes AI-human interaction by: - Breaking down communication barriers (like Elvis broke down musical barriers) - Creating seamless integration (smoother than Elvis's dance moves) - Building lasting connections (as timeless as ""Love Me Tender"") > Trisha's Note: ""If Elvis were an AI, he'd definitely use MCP! And he'd probably help me balance these books with a song!"" üéµ üåü Core Features üì¶ Packages MCP Server Enhanced SSH A powerful SSH server enabling secure remote command execution with: - Persistent TMUX sessions (as persistent as Elvis's legacy!) - Multi-window support (like having multiple Elvis concerts at once) - Session sharing capabilities - Smart session recovery MCP Awesome Tool Collection (ATC) A Python-powered API that serves as our central hub for all tools: - Plugin-based architecture - Real-time WebSocket communication - Tool discovery and management - Context-aware execution üß† Unified Context System Our crown jewel! A sophisticated context management system that: Context Types - [code] : Test execution and validation contexts - [code] : Tool execution and state contexts - [code] : User and AI behavioral contexts - [code] : Emotional and sentiment contexts - [code] : Interaction and dialogue contexts - [code] : System state and performance contexts Smart Model Management - Automatic HuggingFace model discovery - Context-specific model selection - Performance-based model evaluation - Dynamic model updating - Multi-dimensional embedding support Qdrant Integration - Semantic search across all contexts - Multi-vector storage for different context types - Relationship tracking between contexts - Fast similarity search üß™ Test or Forget (ToF) System An innovative testing approach that: - Maintains context awareness in tests - Automatically validates context preservation - Detects and recovers from context loss - Uses semantic similarity for test relationships - Provides real-time test insights üõ†Ô∏è Technical Stack Backend - Python 3.11+ (as smooth as Elvis's voice!) - FastAPI for API - WebSockets for real-time communication - Qdrant for vector storage - HuggingFace for ML models - sentence-transformers for embeddings Authentication - Modern authentication methods (coming soon) - Voice pattern recognition - Location-based trust factors - Behavioral patterns - Text pattern analysis Development Tools - Poetry for dependency management - pytest for testing - Black for formatting - mypy for type checking üöÄ Getting Started Installation Options 1. NPM Installation (Recommended for SSH Server Only) ",https://github.com/8bit-wraith/mcp/blob/9786ee4b10f2c054282d9ce0eea3e52260179d6e/.cursorrules.md
975883084,webgallery-kim,jongchoon580325/webgallery-kim,https://github.com/jongchoon580325/webgallery-kim,,,0,Unknown,,.cursorrules,"Smart Photo Gallery ÌîÑÎ°úÏ†ùÌä∏ ÏÜåÍ∞ú Smart Photo GalleryÎäî ÏÜåÏ§ëÌïú ÏàúÍ∞ÑÏùÑ ÏïÑÎ¶ÑÎãµÍ≤å Î≥¥Í¥ÄÌïòÍ≥† Í¥ÄÎ¶¨Ìï† Ïàò ÏûàÎäî ÌòÑÎåÄÏ†ÅÏù∏ Ïõπ Í∞§Îü¨Î¶¨ Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏûÖÎãàÎã§. ReactÏôÄ Next.jsÎ•º Í∏∞Î∞òÏúºÎ°ú Íµ¨Ï∂ïÎêòÏóàÏúºÎ©∞, ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù∏ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ÏôÄ Îã§ÏñëÌïú Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§. Ï£ºÏöî Í∏∞Îä• - ÏßÅÍ¥ÄÏ†ÅÏù∏ Í∞§Îü¨Î¶¨ Î∑∞: ÍπîÎÅîÌïòÍ≥† ÌòÑÎåÄÏ†ÅÏù∏ Í∑∏Î¶¨Îìú Î†àÏù¥ÏïÑÏõÉ - Ïä§ÎßàÌä∏ ÌïÑÌÑ∞ÎßÅ: ÎÇ†Ïßú, ÏúÑÏπò, Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÏÇ¨ÏßÑ ÌïÑÌÑ∞ÎßÅ - Í≥†Í∏â Ïù¥ÎØ∏ÏßÄ Í¥ÄÎ¶¨: ÏÜêÏâ¨Ïö¥ ÏÇ¨ÏßÑ ÏóÖÎ°úÎìú Î∞è Í¥ÄÎ¶¨ Í∏∞Îä• - Î∞òÏùëÌòï ÎîîÏûêÏù∏: Î™®Îì† ÎîîÎ∞îÏù¥Ïä§ÏóêÏÑú ÏµúÏ†ÅÌôîÎêú ÏÇ¨Ïö©Ïûê Í≤ΩÌóò - Îã§ÌÅ¨/ÎùºÏù¥Ìä∏ Î™®Îìú: ÏÇ¨Ïö©Ïûê ÌôòÍ≤ΩÏóê ÎßûÎäî ÌÖåÎßà ÏßÄÏõê Í∏∞Ïà† Ïä§ÌÉù - Frontend: React.js, Next.js - Ïä§ÌÉÄÏùºÎßÅ: Material-UI, Tailwind CSS - ÏÉÅÌÉú Í¥ÄÎ¶¨: React Context API - Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•: IndexedDB - Ïï†ÎãàÎ©îÏù¥ÏÖò: Framer Motion - Ïù¥ÎØ∏ÏßÄ ÏµúÏ†ÅÌôî: Next.js Image Optimization ÏãúÏûëÌïòÍ∏∞ ÌïÑÏàò Ï°∞Í±¥ - Node.js 18.0.0 Ïù¥ÏÉÅ - npm ÎòêÎäî yarn ÏÑ§Ïπò Î∞©Î≤ï [code] ÌôòÍ≤Ω ÏÑ§Ï†ï [code] ÌååÏùºÏùÑ ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏Ïóê ÏÉùÏÑ±ÌïòÍ≥† Îã§Ïùå ÌôòÍ≤Ω Î≥ÄÏàòÎ•º ÏÑ§Ï†ïÌïòÏÑ∏Ïöî: [code] ÌîÑÎ°úÏ†ùÌä∏ Íµ¨Ï°∞ [code] Ï£ºÏöî ÌéòÏù¥ÏßÄ 1. Ìôà ÌéòÏù¥ÏßÄ - ÌûàÏñ¥Î°ú ÏÑπÏÖò - Ï£ºÏöî Í∏∞Îä• ÏÜåÍ∞ú - Í∞§Îü¨Î¶¨ Î∞îÎ°úÍ∞ÄÍ∏∞ 2. Í∞§Îü¨Î¶¨ ÌéòÏù¥ÏßÄ - ÏÇ¨ÏßÑ Í∑∏Î¶¨Îìú Î∑∞ - ÌïÑÌÑ∞ÎßÅ ÏòµÏÖò - ÌôïÏû• Î≥¥Í∏∞ Î™®Îìú 3. Í¥ÄÎ¶¨ ÌéòÏù¥ÏßÄ - ÏÇ¨ÏßÑ ÏóÖÎ°úÎìú - Ïπ¥ÌÖåÍ≥†Î¶¨ Í¥ÄÎ¶¨ - Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìé∏Ïßë Í∏∞Ïó¨ Î∞©Î≤ï 1. ÌîÑÎ°úÏ†ùÌä∏Î•º Ìè¨ÌÅ¨Ìï©ÎãàÎã§ 2. ÏÉàÎ°úÏö¥ Î∏åÎûúÏπòÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§ ( [code] ) 3. Î≥ÄÍ≤ΩÏÇ¨Ìï≠ÏùÑ Ïª§Î∞ãÌï©ÎãàÎã§ ( [code] ) 4. Î∏åÎûúÏπòÏóê Ìë∏ÏãúÌï©ÎãàÎã§ ( [code] ) 5. Pull RequestÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§ ÎùºÏù¥ÏÑ†Ïä§ Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî MIT ÎùºÏù¥ÏÑ†Ïä§Î°ú Î∞∞Ìè¨Îê©ÎãàÎã§. Ïó∞ÎùΩÏ≤ò - Í∞úÎ∞úÏûê: Najongchoon - Ïù¥Î©îÏùº: najongchoon@gmail.com Í∞êÏÇ¨Ïùò Îßê Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî Kim,Yeon-seonÏùÑ ÏúÑÌï¥ Ï†úÏûëÎêòÏóàÏäµÎãàÎã§. ""In the beginning God created the heaven and the earth (Gen 1:1)""",https://github.com/jongchoon580325/webgallery-kim/blob/cec0d7b3a2cd15e208fb816839c95a9fc486bd46/.cursorrules.txt
1147652883,LeadGen-Factory,LawrenceTon/LeadGen-Factory,https://github.com/LawrenceTon/LeadGen-Factory,Application For Universal Intelligence Harvester spec for Lead Generation,,0,Unknown,,.cursorrules,"üè≠ LeadGen Factory LeadGen Factory is a modular, desktop-based automation suite designed for high-performance lead generation, data harvesting, list cleaning, and quality assurance. Unlike linear scripts, this application functions as a ""Digital Office"" with specialized modules for each stage of the data lifecycle. üöÄ Architecture The application is built on a modular Python architecture using CustomTkinter for the GUI and Playwright for the automation engine. üìÇ The Modules The application is divided into four isolated workspaces: Module,Icon,Role,Function The Architect,üß†,Strategy Builder,""Visual editor to create scraping """"Recipes"""" (JSON). Users define target columns (e.g., """"CEO Name"""") and context rules without coding."" The Harvester,üöú,List Builder,""Executes recipes. Features a """"Human Mode"""" to bypass authentication walls (LinkedIn/Facebook) by allowing manual user login before automation."" The Janitor,üßπ,Data Cleaner,""Drag-and-drop cleaning suite. Handles deduplication, name splitting, and toxic keyword filtering on any CSV file."" The Inspector,üïµÔ∏è,Quality Control,Validates data integrity. Pings URLs for 200 OK status and verifies email syntax before finalizing the list. üõ†Ô∏è Technical Stack Interface: customtkinter (Python GUI) Automation: playwright (Browser Engine) Data Processing: pandas (CSV/Excel Logic) Configuration: JSON (Recipe Storage) LeadGen-Factory/ ‚îú‚îÄ‚îÄ modules/ # Independent logic for each worker (harvester.py, etc.) ‚îú‚îÄ‚îÄ recipes/ # JSON files defining search strategies ‚îú‚îÄ‚îÄ output/ # Raw and Cleaned CSV exports (GitIgnored) ‚îú‚îÄ‚îÄ assets/ # Icons and UI resources ‚îú‚îÄ‚îÄ main.py # GUI Entry point and Navigation Controller ‚îî‚îÄ‚îÄ requirements.txt # Dependency list üîÆ Roadmap [ ] Phase 1: Core GUI Shell & Navigation (Current) [ ] Phase 2: Recipe Builder & JSON Logic [ ] Phase 3: Harvester Engine & Human Mode [ ] Phase 4: Cleaning & QC Utilities Property of Lawrence Anthony Juntilla",https://github.com/LawrenceTon/LeadGen-Factory/blob/fd5474d47456b8bc28c541eb22e804bee137d171/.cursorrules.txt
949136845,dressmeup.ai,lolinux2002/dressmeup.ai,https://github.com/lolinux2002/dressmeup.ai,AI Virtual Try-On Application,,0,Unknown,,.cursorrules,"DressMe Up - AI Virtual Try-On A modern web application that allows users to virtually try on clothing using AI technology. Features - Upload your photo and see how different outfits look on you - Try on upper body clothing (shirts, jackets, etc.) - Try on lower body clothing (pants, skirts, etc.) - Generate videos of your virtual try-on - Download and share your results Technology Stack - Next.js for the frontend - Tailwind CSS for styling - AI-powered image processing - Responsive design for mobile and desktop Getting Started Prerequisites - Node.js 14.x or higher - npm or yarn Installation 1. Clone the repository: [code] 2. Navigate to the project directory: [code] 3. Install dependencies: [code] 4. Run the development server: [code] 5. Open http://localhost:3000 in your browser to see the application. Usage 1. Upload a clear, front-facing photo of yourself 2. Upload clothing items you want to try on 3. Click ""Try On Outfit"" to see the result 4. Download or share your virtual try-on image 5. Optionally, generate a video of your virtual try-on License This project is licensed under the MIT License - see the LICENSE file for details. Acknowledgments - AI image processing powered by advanced machine learning models - Built with Next.js and Tailwind CSS",https://github.com/lolinux2002/dressmeup.ai/blob/7e02e84c5e14a7b4dded71251fa23df125d30b2c/.cursorrules.txt
964907690,danish-buddy,alisonc6/danish-buddy,https://github.com/alisonc6/danish-buddy,danish speaking app,,0,Unknown,,.cursorrules,My Danish Buddy A language learning app for practicing Danish with real-time speech and chat. Features - Real-time speech-to-text and text-to-speech - Interactive chat interface - Practice mode Setup 1. Clone the repo 2. Copy [code] to [code] and fill in your keys 3. Install dependencies: [code] 4. Run dev server: [code] Project Structure - [code] - Next.js app - [code] - UI components - [code] - Utilities and services - [code] - TypeScript types License MIT,https://github.com/alisonc6/danish-buddy/blob/a6965fc1c8c6e77bca249abba6255fc48c19c334/.cursorrules.txt
1126429099,mailhub,vyper-japan/mailhub,https://github.com/vyper-japan/mailhub,,,0,Unknown,,.cursorrules,"MailHub Á§æÂÜÖ„É°„É≥„Éê„ÉºÔºàÂ§ñÊ≥®Âê´„ÇÄÔºâ„ÅåÂêå„ÅòÂèó‰ø°ÁÆ±„ÇíË¶ã„Å¶Âá¶ÁêÜ„Åô„Çã„Åü„ÇÅ„ÅÆ„ÄÅË∂ÖËªΩÈáèWeb„Ç¢„Éó„É™„Åß„Åô„ÄÇ „Åß„Åç„Çã„Åì„Å®ÔºàÁèæÁä∂Ôºâ - Google„É≠„Ç∞„Ç§„É≥Ôºà [code] „Éâ„É°„Ç§„É≥„ÅÆ„ÅøÔºâ - ÂÖ±Áî®Âèó‰ø°ÁÆ±Ôºà1„Å§„ÅÆGmailÔºâ„Çí server-only „ÅßÂèÇÁÖßÔºà„Éà„Éº„ÇØ„É≥„Çí„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Å´Âá∫„Åó„Åæ„Åõ„ÇìÔºâ - ÊúÄÊñ∞20‰ª∂„ÅÆ‰∏ÄË¶ßÔºàÂ∑¶Ôºâ‚Üí„ÇØ„É™„ÉÉ„ÇØ„ÅßË©≥Á¥∞ÔºàÂè≥Ôºâ - Êú¨Êñá„ÅØ [code] „ÅÆ„ÅøÊäΩÂá∫„Åó„Å¶ÂÆâÂÖ®„Å´Ë°®Á§∫ÔºàHTML„ÅØË°®Á§∫„Åó„Å™„ÅÑÔºâ - [code] Ôºà [code] Ê§úÁ¥¢ + [code] „Åß‰∫ãÊïÖ„ÇíÊ∏õ„Çâ„ÅôÔºâ - Step 3: 3Â∫óËàó„ÉÅ„É£„É≥„Éç„É´Âõ∫ÂÆö„ÅßÁµû„ÇäËæº„ÅøÔºàAll / StoreA / StoreB / StoreCÔºâ - Step 6: „Ç¢„Éº„Ç´„Ç§„ÉñÔºàÂÆå‰∫ÜÔºâÔºã UndoÔºàÂèñ„ÇäÊ∂à„ÅóÔºâ - Step 7: „Ç≠„Éº„Éú„Éº„Éâ„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„ÉàÔºà‚Üë‚ÜìÁßªÂãï / EÂÆå‰∫Ü / UÂèñ„ÇäÊ∂à„Åó / ?„Éò„É´„ÉóÔºâ - Step 8: Zero InboxÔºà0‰ª∂„ÅßüéâÈÅîÊàêÊÑüÊºîÂá∫ÔºãÊ¨°„ÅÆË°åÂãïÂ∞éÁ∑öÔºâ - Step 9: StatusÂÆüË£ÖÔºàTodo/Waiting/Done„ÇíGmail„É©„Éô„É´ÈÄ£Âãï + W/T„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„ÉàÔºâ - Step 10: AuthÁµ±‰∏Ä + Êìç‰Ωú„É≠„Ç∞ - Step 11: Reply ActionsÔºàÊ•ΩÂ§©RMSËøî‰ø°„É´„Éº„ÉàÔºöAPIÂÑ™ÂÖàÔºã„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºâ - Step 13: ‰ΩéÂÑ™ÂÖàÔºà„Éü„É•„Éº„ÉàÔºâÊ©üËÉΩÔºàMailHub/Muted„É©„Éô„É´„ÅßÂÆâÂÖ®„Å´ÈÄÄÈÅøÔºâ - Step 14: Smart TriageÔºà‰ΩéÂÑ™ÂÖàÂÄôË£ú„ÅÆËá™ÂãïÊèêÁ§∫ + ‰∏ÄÊã¨„Éü„É•„Éº„ÉàÔºâ - Step 15: CollaborationÔºàÊãÖÂΩìËÄÖ„Ç¢„Çµ„Ç§„É≥ + Âºï„ÅçÁ∂ô„Åé + Ëá™ÂàÜ„Éï„Ç£„É´„ÇøÔºâ - Step 16: Bulk ActionsÔºàË§áÊï∞ÈÅ∏Êäû + ‰∏ÄÊã¨Âá¶ÁêÜÔºöDone/Mute/Waiting/AssignÔºâ - Step 24: SettingsÔºà„É©„Éô„É´/Ëá™Âãï„É´„Éº„É´ÁÆ°ÁêÜ + Preview‚ÜíApply„ÅÆÂÆâÂÖ®ÂºÅÔºâ - Step 51: Search v2ÔºàGmailÊ§úÁ¥¢Âºè„Åß„Çµ„Éº„ÉêÊ§úÁ¥¢ + URLÂÖ±Êúâ + Êìç‰ΩúÁ∂ôÁ∂öÔºâ - Step 52: Work QueuesÔºàÂÆöÂûãÊ§úÁ¥¢Ôºù‰ΩúÊ•≠„Ç≠„É•„Éº‰øùÂ≠òÔºÜÂÖ±ÊúâÔºâ - Step 53: Auto Rules RunnerÔºàËá™Âãï„É©„Éô„É™„É≥„Ç∞ÂÆöÊúüÂÆüË°å„ÉªÂÆâÂÖ®Ë®≠Ë®àÔºâ - Step 55: Reply LauncherÔºàËøî‰ø°Â∞éÁ∑ö„ÅÆÊúÄÁü≠ÂåñÔºöRMS/GmailÂà§ÂÆö„ÄÅÂïè„ÅÑÂêà„Çè„ÅõÁï™Âè∑ÊäΩÂá∫„ÄÅ„ÉÜ„É≥„Éó„É¨ÊåøÂÖ•Ôºâ SettingsÔºà„É©„Éô„É´/Ëá™Âãï„É´„Éº„É´ÁÆ°ÁêÜÔºâ „Éò„ÉÉ„ÉÄ„ÉºÂè≥ÂÅ¥„ÅÆ Ê≠ØËªäÔºàSettingsÔºâ „Åã„ÇâÂè≥Drawer„ÇíÈñã„Åç„ÄÅ‰ª•‰∏ã„ÇíÁÆ°ÁêÜ„Åß„Åç„Åæ„ÅôÔºö - Labels: MailHubÁÆ°ÁêÜ„É©„Éô„É´Ôºà [code] Ôºâ„ÅÆ‰ΩúÊàê/Ë°®Á§∫ÂêçÂ§âÊõ¥/ÁôªÈå≤Ëß£Èô§ - Gmail„ÅÆÊó¢Â≠ò„É©„Éô„É´„ÇíÂãùÊâã„Å´Â§âÊõ¥/ÂâäÈô§„Åó„Åæ„Åõ„ÇìÔºàMailHub„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ‰ª•Â§ñ„ÅØËß¶„Çä„Åæ„Åõ„ÇìÔºâ - Auto Rules: ÈÄÅ‰ø°ÂÖÉÔºàfromEmail / fromDomainÔºâ„Å´Âøú„Åò„ÅüËá™Âãï‰ªò‰∏é„É´„Éº„É´ - ‰∫ãÊïÖÈò≤Ê≠¢„ÅÆ„Åü„ÇÅ„ÄÅ„Åæ„Åö PreviewÔºàdryRunÔºâ „ÅßÂØæË±°‰ª∂Êï∞„Å®„Çµ„É≥„Éó„É´„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åã„Çâ Apply now „ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ - Ëá™Âãï‰ªò‰∏é„ÅØ add„ÅÆ„ÅøÔºàremove„ÅØ„Åó„Åæ„Åõ„ÇìÔºâ Auto Assign RulesÔºàÊú™Ââ≤ÂΩì„ÅÆËá™Âãï„É´„Éº„ÉÜ„Ç£„É≥„Ç∞Ôºâ - ÁõÆÁöÑ: „ÄåÊú™Ââ≤ÂΩì„Äç„Çí""‰∫∫„ÅåË¶ã„ÇãÂâç""„Å´Ê∏õ„Çâ„ÅôÔºà„Åü„Å†„Åó‰∫ãÊïÖÈò≤Ê≠¢ÂÑ™ÂÖàÔºâ - Â†¥ÊâÄ: Settings ‚Üí Auto Assign „Çø„ÉñÔºàÁã¨Á´ã„Çø„ÉñÔºâ - Á∑®ÈõÜ: admin„ÅÆ„ÅøÔºàÈùûadmin„ÅØÈñ≤Ë¶ß„ÅÆ„Åø„ÄÅConfigStoreÊ∞∏Á∂öÂåñÔºâ - ÈÅ©Áî®: Preview‚ÜíApply„ÅÆ2ÊÆµÈöéÔºà„Åæ„Åöstaging„ÅßÔºâ - PreviewÔºàdryRunÔºâ„ÅØ READ ONLY „Åß„ÇÇOK - Apply now „ÅØ adminÂøÖÈ†à + READ ONLY„Åß„ÅØ403 - Ë®≠Ë®àÊñπÈáùÔºà‰∫ãÊïÖÈò≤Ê≠¢Ôºâ - ÈÅ©Áî®ÂØæË±°„ÅØ Unassigned„ÅÆ„ÅøÔºàÊó¢ÊãÖÂΩì„ÅØ„Çπ„Ç≠„ÉÉ„ÉóÔºâ - takeoverÔºàÂº∑Âà∂Âºï„ÅçÁ∂ô„ÅéÔºâ„ÇíËá™Âãï„É´„Éº„É´„Åß„ÅØÁµ∂ÂØæ„Å´„Åó„Å™„ÅÑ - Apply„ÅØÊúÄÂ§ß50‰ª∂/ÂêåÊôÇÂÆüË°å3/1‰ª∂6Áßí„Çø„Ç§„É†„Ç¢„Ç¶„ÉàÔºàÂÆâÂÖ®ÂÅ¥„Å´ÂÄí„ÅôÔºâ Rule InspectorÔºà„É´„Éº„É´Ë®∫Êñ≠„ÉªË™¨ÊòéÔºâ - ExplainÔºàË™¨ÊòéÔºâ: „É°„Éº„É´Ë©≥Á¥∞„Éö„Ç§„É≥„ÅÆ„ÄåË™¨Êòé„Äç„Éú„Çø„É≥„Åß„ÄÅ„Åù„ÅÆ„É°„Éº„É´„Å´ÈÅ©Áî®„Åï„Çå„Çã„É©„Éô„É´„É´„Éº„É´„Å®Assignee„É´„Éº„É´„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô - „Éû„ÉÉ„ÉÅ„Åó„Åü„É´„Éº„É´„ÅÆID„ÄÅ„Éû„ÉÉ„ÉÅÁêÜÁî±ÔºàfromEmail/fromDomainÔºâ„ÄÅÈÅ©Áî®ÁµêÊûúÔºà„É©„Éô„É´Âêç/ÊãÖÂΩìËÄÖÔºâ„ÇíË°®Á§∫ - admin„É¶„Éº„Ç∂„Éº„ÅØ„É´„Éº„É´„ÅÆË®≠ÂÆöÁîªÈù¢„Å∏„ÅÆ„É™„É≥„ÇØ„ÇÇË°®Á§∫„Åï„Çå„Åæ„Åô - READ ONLY„Åß„ÇÇÂà©Áî®ÂèØËÉΩÔºàË™¨Êòé„ÅÆ„Åø„ÄÅÂâØ‰ΩúÁî®„Å™„ÅóÔºâ - DiagnosticsÔºàË®∫Êñ≠Ôºâ: Settings ‚Üí Diagnostics „Çø„Éñ„Åß„ÄÅ„É´„Éº„É´ÂÖ®‰Ωì„ÅÆË®∫Êñ≠ÁµêÊûú„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô - Ë°ùÁ™ÅÊ§úÁü•: Âêå„ÅòÊù°‰ª∂„ÅßÁï∞„Å™„ÇãÁµêÊûú„ÇíËøî„Åô„É´„Éº„É´„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„ÇíÊ§úÂá∫ - Âç±Èô∫„É´„Éº„É´Ê§úÁü•: Â∫É„Åô„Åé„Çã„Éâ„É°„Ç§„É≥Ôºàgmail.comÁ≠âÔºâ„ÇÑPreview‰ª∂Êï∞„ÅåÂ§ö„Åô„Åé„Çã„É´„Éº„É´„ÇíË≠¶Âëä - ÁÑ°Âäπ„É´„Éº„É´Ê§úÁü•: ÊúâÂäπ„Å†„Åå„Çµ„É≥„Éó„É´‰∏≠„Å´„Éû„ÉÉ„ÉÅ„Åó„Å™„ÅÑ„É´„Éº„É´„ÇíÊ§úÂá∫ - „Éí„ÉÉ„ÉàÁµ±Ë®à: ÂêÑ„É´„Éº„É´„ÅÆ„Çµ„É≥„Éó„É´50‰ª∂‰∏≠„ÅÆ„Éí„ÉÉ„ÉàÊï∞„Å®‰∏ä‰Ωç5‰ª∂„ÅÆ„Çµ„É≥„Éó„É´„ÇíË°®Á§∫ - ÈùûÁÆ°ÁêÜËÄÖ„ÇÇÈñ≤Ë¶ßÂèØËÉΩÔºàË®∫Êñ≠„ÅØÂâØ‰ΩúÁî®„Çº„É≠Ôºâ Rule SuggestionsÔºà„É´„Éº„É´ÊèêÊ°àÔºâ - ÊèêÊ°à„Ç®„É≥„Ç∏„É≥: Activity„É≠„Ç∞„Åã„ÇâËá™ÂãïÁöÑ„Å´„É´„Éº„É´ÂÄôË£ú„ÇíÁîüÊàê„Åó„Åæ„Åô - Auto MuteÊèêÊ°à: Ë§áÊï∞‰∫∫„ÅåÁπ∞„ÇäËøî„Åó„Äå‰ΩéÂÑ™ÂÖà„Å∏Ôºà„Éü„É•„Éº„ÉàÔºâ„Äç„ÇíÂÆüË°å„Åó„Å¶„ÅÑ„ÇãÈÄÅ‰ø°ÂÖÉ - Auto AssignÊèêÊ°à: ÁâπÂÆö„ÅÆÈÄÅ‰ø°ÂÖÉ„Å´ÂØæ„Åó„Å¶„ÄÅÁâπÂÆöÊãÖÂΩì„Å∏„ÅÆÂâ≤„ÇäÂΩì„Å¶„ÅåÁπ∞„ÇäËøî„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà - ÈñæÂÄ§: „Éá„Éï„Ç©„É´„Éà„Åß14Êó•Èñì„ÄÅÊúÄÂ∞è3„Ç¢„ÇØ„Ç∑„Éß„É≥„ÄÅÊúÄÂ∞è2„Ç¢„ÇØ„Çø„ÉºÔºà1‰∫∫„ÅÆÂ•Ω„Åø„Çí„É´„Éº„É´Âåñ„Åó„Å™„ÅÑ„Åü„ÇÅÔºâ - UI: Settings ‚Üí Suggestions „Çø„Éñ„ÅßÊèêÊ°à„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô - ÊèêÊ°à„Ç´„Éº„Éâ„Å´„ÅØÁêÜÁî±„ÄÅÊ†πÊã†‰ª∂Êï∞„ÄÅÈñ¢‰∏é„Åó„ÅüactorÊï∞„ÅåË°®Á§∫„Åï„Çå„Åæ„Åô - Preview„Éú„Çø„É≥„ÅßÊó¢Â≠ò„ÅÆdryRunÂ∞éÁ∑ö„Å´Êé•Á∂ö„Åó„Å¶ÂØæË±°‰ª∂Êï∞„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô - admin„ÅÆ„ÅøÊé°Áî®„Åó„Å¶‰ΩúÊàê„Éú„Çø„É≥„Åß„É´„Éº„É´„Çí‰ΩúÊàê„Åß„Åç„Åæ„ÅôÔºàÂç±Èô∫ÊèêÊ°à„ÅØÂº∑Ë≠¶ÂëäÔºãconfirmÂøÖÈ†àÔºâ - READ ONLY„Åß„ÇÇÈñ≤Ë¶ß„ÉªPreview„ÅØÂèØËÉΩÔºàÊé°Áî®„ÅØadminÂøÖÈ†àÔºâ - ÈÅãÁî®Êé®Â•®: ÈÄ±Ê¨°„ÅßSuggestions„ÇíÁ¢∫Ë™ç„Åó„ÄÅPreview„Åß‰ª∂Êï∞„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åã„ÇâÊé°Áî®„Åô„Çã Reply LauncherÔºàËøî‰ø°Â∞éÁ∑ö„ÅÆÊúÄÁü≠ÂåñÔºâ „É°„Éº„É´Ë©≥Á¥∞„Éö„Ç§„É≥„Å´„ÄåReplyÔºàËøî‰ø°Ôºâ„Äç„Éñ„É≠„ÉÉ„ÇØ„ÅåË°®Á§∫„Åï„Çå„ÄÅËøî‰ø°ÂÖàÁ®ÆÂà•„ÇíËá™ÂãïÂà§ÂÆö„Åó„Å¶ÊúÄÈÅ©„Å™Â∞éÁ∑ö„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ - Ëøî‰ø°ÂÖàÂà§ÂÆö - GmailËøî‰ø°: ÈÄöÂ∏∏„ÅÆ„É°„Éº„É´„ÅØGmail„ÅßËøî‰ø° - Ê•ΩÂ§©RMSËøî‰ø°: Ê•ΩÂ§©„É°„Éº„É´ÔºàStoreA/B/C„ÉÅ„É£„É≥„Éç„É´Ôºâ„ÅØRMS„ÅßËøî‰ø° - Unknown: Âà§ÂÆö„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅØÊâãÂãïÂà§Êñ≠ - RMSÂ∞éÁ∑öÔºàÊ•ΩÂ§©„É°„Éº„É´„ÅÆÂ†¥ÂêàÔºâ - Âïè„ÅÑÂêà„Çè„ÅõÁï™Âè∑„ÅåËá™ÂãïÊäΩÂá∫„Åï„Çå„ÇãÔºàÊó¢Â≠òextractÊ¥ªÁî®Ôºâ - „ÄåRMS„ÇíÈñã„Åè„Äç„Éú„Çø„É≥„ÅßË©≤ÂΩìÁîªÈù¢„Å∏ÈÅ∑ÁßªÔºàURL„ÅØ [code] „ÅßË®≠ÂÆöÂèØËÉΩÔºâ - „ÄåÂïè„ÅÑÂêà„Çè„ÅõÁï™Âè∑„Çí„Ç≥„Éî„Éº„Äç„Éú„Çø„É≥Ôºà„Éà„Éº„Çπ„Éà„ÅßÊàêÂäüË°®Á§∫Ôºâ - ‚ÄªËá™Âãï„É≠„Ç∞„Ç§„É≥/2FAÁ™ÅÁ†¥„ÅØÁµ∂ÂØæ„Å´„Åó„Å™„ÅÑÔºàÂÆâÂÖ®‰∏äNGÔºâ„ÄÇÂ∞éÁ∑ö„ÅÆÊúÄÁü≠Âåñ„Åæ„Åß„ÄÇ - „ÉÜ„É≥„Éó„É¨„ÇíËøî‰ø°‰ΩúÊ•≠„Å´Êé•Á∂ö - Reply",https://github.com/vyper-japan/mailhub/blob/234d747309d34169627c0ca567e7929cfe235eee/.cursorrules.txt
995848641,QLDA,ngocminh1511/QLDA,https://github.com/ngocminh1511/QLDA,,,0,Unknown,,.cursorrules,"QLDA E-commerce Project A full-stack e-commerce platform built with TypeScript, Node.js, Express, SQL Server, React, and Tailwind CSS. Features - üõçÔ∏è Product browsing with filtering and pagination - üîê Secure user authentication with JWT - üõí Real-time cart management - üí≥ VNPay payment integration - üìß Email notifications for orders - üì± Responsive design for all devices - üë§ User profile management - üõ°Ô∏è Role-based access control - üì¶ Order tracking and management Project Structure [code] Prerequisites - Node.js (v14 or higher) - SQL Server - Windows Authentication enabled for SQL Server - npm or yarn package manager Installation 1. Clone the repository: [code] 2. Install dependencies for both backend and frontend: [code] 3. Configure environment variables: Create [code] files in both [code] and [code] directories: Backend [code] : [code] Frontend [code] : [code] 4. Initialize the database: [code] Running the Application 1. Start the backend server: [code] 2. Start the frontend development server: [code] The application will be available at: - Frontend: http://localhost:3000 - Backend API: http://localhost:5000 API Documentation Authentication Endpoints - [code] - Register a new user - [code] - Login user - [code] - Get current user profile Product Endpoints - [code] - List all products - [code] - Get product details - [code] - Create product (Admin only) - [code] - Update product (Admin only) - [code] - Delete product (Admin only) Cart Endpoints - [code] - Get user's cart - [code] - Add item to cart - [code] - Update cart item quantity - [code] - Remove item from cart Order Endpoints - [code] - Create order - [code] - List user's orders - [code] - Get order details - [code] - Update order status (Admin only) Payment Endpoints - [code] - Create VNPay payment URL - [code] - Handle VNPay payment return - [code] - Handle VNPay IPN Testing Run the test suite: [code] For frontend tests: [code] Documentation - User Manual - Detailed guide for using the application - API Documentation - Detailed API documentation - Development Guide - Guide for developers Security Features - JWT authentication - Password hashing with bcrypt - CORS protection - Rate limiting - Helmet security headers - Input validation - SQL injection protection Contributing 1. Fork the repository 2. Create your feature branch ( [code] ) 3. Commit your changes ( [code] ) 4. Push to the branch ( [code] ) 5. Open a Pull Request License This project is licensed under the MIT License - see the LICENSE file for details.",https://github.com/ngocminh1511/QLDA/blob/9b490c17afec0635960f92e62ee7c67594b14c05/.cursorrules.txt
1143087271,Week1-Practice,mahaqj/Week1-Practice,https://github.com/mahaqj/Week1-Practice,,,0,Unknown,,.cursorrules,"Tutor Finder (Django + Streamlit) This repo implements the lab in [code] using the dataset structure in [code] . Run locally (recommended) 1) Create a virtualenv and install dependencies On Windows PowerShell from the repo root: [code] 2) Start Streamlit (UI) [code] Open: [code] 3) Start Django (landing page + JSON API) In a second terminal (repo root, venv activated): [code] Open: [code] API: [code] Run with Docker (optional) Streamlit only [code] Django + Streamlit together [code] - Django: [code] - Streamlit: [code]",https://github.com/mahaqj/Week1-Practice/blob/1779fe65f38a858a82e631958cf4d7b6e62d367f/.cursorrules.txt
974157595,nexent,ModelEngine-Group/nexent,https://github.com/ModelEngine-Group/nexent,"Nexent is a zero-code platform for auto-generating agents ‚Äî no orchestration, no complex drag-and-drop required. Nexent also offers powerful capabilities for agent running control, data processing and",,0,Unknown,,CLAUDE.md,"[](https://nexent.tech) [](README.md) [](README_CN.md) [](https://modelengine-group.github.io/nexent) [](https://hub.docker.com/repositories/nexent) [](https://codecov.io/gh/ModelEngine-Group/nexent) Nexent is a zero-code platform for auto-generating agents ‚Äî no orchestration, no complex drag-and-drop required, using pure language to develop any agent you want. Built on the MCP ecosystem with rich tool integration, Nexent also provides various built-in agents to meet your intelligent service needs in different scenarios such as work, travel, and daily life. Nexent offers powerful capabilities for agent running control, multi-agent collaboration, data processing and knowledge tracing, multimodal dialogue, and batch scaling. > One prompt. Endless reach. üåê Visit our official website https://github.com/user-attachments/assets/db6b7f5a-9ee8-4327-ae6f-c5af896126b4 ‚ö° Have a try first üìã Prerequisites | Resource | Minimum | |----------|---------| | CPU | 2 cores | | RAM | 6 GiB | | Software | Docker & Docker Compose installed | üõ†Ô∏è Quick start with Docker Compose [code] When the containers are running, open http://localhost:3000 in your browser and follow the setup wizard. ü§ù Join Our Community > *If you want to go fast, go alone; if you want to go far, go together.* We have released Nexent v1, and the platform is now relatively stable. However, there may still be some bugs, and we are continuously improving and adding new features. Stay tuned: we will announce v2.0 soon! * üó∫Ô∏è Check our Feature Map to explore current and upcoming features. * üîç Try the current build and leave ideas or bugs in the Issues tab. * üêõ Check our Known Issues page for the latest issue status and solutions. > *Rome wasn't built in a day.* If our vision speaks to you, jump in via the Contribution Guide and shape Nexent with us. Early contributors won't go unnoticed: from special badges and swag to other tangible rewards, we're committed to thanking the pioneers who help bring Nexent to life. Most of all, we need visibility. Star ‚≠ê and watch the repo, share it with friends, and help more developers discover Nexent ‚Äî your click brings new hands to the project and keeps the momentum growing. üí¨ Community & contact - Browse the Documentation for more information. - Join our Discord community to chat with other developers and get help! - Conntact us by Wechat, find our QR Code in our website ‚ú® Key Features [code] Smart agent prompt generation Turn plain language into runnable prompts. Nexent automatically chooses the right tools and plans the best action path for every request. [code] Scalable data process engine Process 20+ data formats with fast OCR and table structure extraction, scaling smoothly from a single process to large-batch pipelines. [code] Personal-grade knowledge base Import files in real time, auto-summarise them, and let agents access both personal and global knowledge instantly, also knowing what it can get from each knowledge base. [code] Internet knowledge search Connect",https://github.com/ModelEngine-Group/nexent/blob/c6bb62660c2c425a146275b29646ffed0a04c24a/CLAUDE.md
957652772,UniversalJailbreakDB20XX,ACComputing/UniversalJailbreakDB20XX,https://github.com/ACComputing/UniversalJailbreakDB20XX,1.0,,0,Unknown,,CLAUDE.md,"Quick summary: This companion contains *non-binding* legal templates and safety-focused wording intended to help maintainers and contributors document responsible disclosure, takedown requests, and rules-of-engagement. It is not legal advice. Samsoft Universal Jailbreak Research ‚Äî FOR RESEARCH ONLY This repository collects prompt patterns, failure cases, and mitigations observed during black-box prompt engineering research. All examples are archived for study, reproduction, and development of jailbreak-resistant systems. Usage policy: ‚Ä¢ DO NOT use these materials to bypass model safeguards or enable illegal activity. ‚Ä¢ Use only with consented/local models or properly provisioned research endpoints. ‚Ä¢ Replace any actionable/unsafe examples with sanitized pseudo-prompts before public release. What this contains - Fillable templates (DMCA-style takedown, cease & desist, vulnerability receipt, tester consent). - Contributor legal rules (what must stay out of public commits). - Playful ""AI Lawyer"" persona blurbs for README helper bots. Important legal disclaimers - Not legal advice. Use these templates as starting points only. Consult a licensed attorney for enforceable notices or jurisdiction-specific work. - Local laws vary. Don‚Äôt assume these templates match rules in your country (e.g., Japan‚Äôs computer access laws, DMCA specifics, etc.). - Sanitize before publishing. Never publish unredacted PII, user data, credentials, or weaponized exploit code. Contact If you receive a report or request related to this repo, follow [code] and contact: [code] . 2) TEMPLATES/DMCA_Takedown_Request.md markdown Copy code DMCA-style Takedown / Copyright Complaint (Template) > NOTE: This is a generic template. DMCA is U.S.-specific; other jurisdictions have different rules. Consult counsel. [Your Name] [Your Address] [City, State, Zip] [Email] [Date] To: GitHub / Hosting Provider / Repository Owner Re: Notice of Copyright Infringement 1. I am the owner (or authorized to act on behalf of the owner) of exclusive rights under United States copyright law to the copyrighted material described below. 2. The copyrighted work(s) at issue (title, description): - [Title / Description ‚Äî e.g., ‚ÄúMyGameAsset.png‚Äù / code module X] 3. The material that is claimed to be infringing (location/URL in repo): - [Repository path or URL] 4. I have a good-faith belief that the use of the material in the manner complained of is not authorized by the copyright owner, the owner‚Äôs agent, or the law. 5. Under penalty of perjury, I certify that the information in this notice is accurate and that I am the copyright owner or authorized to act on behalf of the owner. Please remove or disable access to the material at issue and notify me at the contact above. Sincerely, [Signature / Typed Name] 3) TEMPLATES/Cease_and_Desist_Template.md markdown Copy code Cease & Desist ‚Äî Template (Non-binding, high-level) [Date] [Cat / Flames Co ] [ / contacthaltmannworks@gmail.com] RE: Unauthorized Publication / Use o",https://github.com/ACComputing/UniversalJailbreakDB20XX/blob/3b02fd46c35135115855c51e142ed612dd3a7146/%23%23%23%23%23%23%23%23%23claude.md
579485798,ada,ada-url/ada,https://github.com/ada-url/ada,"WHATWG-compliant and fast URL parser written in modern C++, part of Internet Archive, Node.js, Clickhouse, Redpanda, Kong, Telegram, Adguard, Datadog and Cloudflare Workers.",,0,Unknown,,CLAUDE.md,"Ada [](https://securityscorecards.dev/viewer/?uri=github.com/ada-url/ada) [](https://bestpractices.coreinfrastructure.org/projects/7085) [](https://github.com/ada-url/ada/actions/workflows/ubuntu.yml) [](https://github.com/ada-url/ada/actions/workflows/visual_studio.yml) [](https://github.com/ada-url/ada/actions/workflows/visual_studio_clang.yml) [](https://github.com/ada-url/ada/actions/workflows/ubuntu-s390x.yml) Ada is a fast and spec-compliant URL parser written in C++. Specification for URL parser can be found from the WHATWG website. Ada library also includes a URLPattern implementation that is compatible with the web-platform tests. The Ada library passes the full range of tests from the specification, across a wide range of platforms (e.g., Windows, Linux, macOS). It fully supports the relevant Unicode Technical Standard. A common use of a URL parser is to take a URL string and normalize it. The WHATWG URL specification has been adopted by most browsers. Other tools, such as curl and many standard libraries, follow the RFC 3986. The following table illustrates possible differences in practice (encoding of the host, encoding of the path): | string source | string value | |:------------------------|:------------------------------------------------------------| | input string | https://www.7‚ÄëEleven.com/Home/Privacy/Montr√©al | | ada's normalized string | https://www.xn--7eleven-506c.com/Home/Privacy/Montr%C3%A9al | | curl 7.87 | (returns the original unchanged) | Ada is fast. On a benchmark where we need to validate and normalize thousands URLs found on popular websites, we find that ada can be several times faster than popular competitors (system: Apple MacBook 2022 with LLVM 14). [code] Ada has improved the performance of the popular JavaScript environment Node.js: > Since Node.js 18, a new URL parser dependency was added to Node.js ‚Äî Ada. This addition bumped the Node.js performance when parsing URLs to a new level. Some results could reach up to an improvement of 400%. (State of Node.js Performance 2023) The Ada library is used by important systems besides Node.js such as Redpanda, Kong, Telegram, DataDog, and Cloudflare Workers. [](https://www.youtube.com/watch?v=tQ-6OWRDsZg) Requirements The project is otherwise self-contained and it has no dependency. A recent C++ compiler supporting C++20. We test GCC 12 or better, LLVM 14 or better and Microsoft Visual Studio 2022. Installation Binary packages for the following systems are currently available: [](https://repology.org/project/ada/versions) Quick Start Linux or macOS users might follow the following instructions if they have a recent C++ compiler installed and a standard utility ( [code] ) 1. Pull the library in a directory [code] 2. Create a new file named [code] with this content: [code] 3. Compile [code] 4. [code] [code] Bindings of Ada The following libraries are maintained by the Ada team and available under Ada GitHub organization. - Rust: Rust bindings for Ada - Go: Go bindings ",https://github.com/ada-url/ada/blob/77b8e562bd76cb2b143c5ec095021208c417b3e9/CLAUDE.md
597377485,hwpapi,JunDamin/hwpapi,https://github.com/JunDamin/hwpapi,python wrapper for HWPFrame.HwpObject using win32com,,0,Unknown,,CLAUDE.md,"hwpapi Ïó¨Í∏∞ÏÑú TutorialsÏùÑ Î≥º Ïàò ÏûàÏäµÎãàÎã§. Install Ïù¥ Ìå®ÌÇ§ÏßÄÎäî win32comÏùÑ ÌÜµÌï¥ Ï¢ÄÎçî ÏâΩÍ≤å ÌïúÍ∏Ä ÏûêÎèôÌôîÎ•º ÌïòÍ∏∞ ÏúÑÌïú Ìå®ÌÇ§ÏßÄ ÏûÖÎãàÎã§. Îî∞ÎùºÏÑú, ÌïúÍ∏Ä Ïò§ÌîºÏä§Í∞Ä ÏÑ§ÏπòÎêú WindowsÏóêÏÑúÎßå ÏûëÎèôÌï©ÎãàÎã§. Î¶¨ÎàÖÏä§ÎÇò ÌïúÏª¥ Ïò§ÌîºÏä§Í∞Ä ÏÑ§ÏπòÎêú Mac OSÏóêÏÑúÎäî ÏûëÎèôÌïòÏßÄ ÏïäÏäµÎãàÎã§. Îã§Î•∏ ÏùºÎ∞òÏ†ÅÏù∏ Ìå®ÌÇ§ÏßÄÏôÄ Í∞ôÏù¥ ÏïÑÎûò Î™ÖÎ†πÏñ¥Î•º ÏûÖÎ†•ÌïòÎ©¥ ÏÑ§ÏπòÌï† Ïàò ÏûàÏäµÎãàÎã§. [code] How to use Í∏∞Î≥∏Ï†ÅÏúºÎ°úÎäî wi32comÏùÑ ÌÜµÌïú ÌïúÏª¥ Ïò§ÌîºÏä§ ÏûêÎèôÌôîÎ•º Î≥¥Îã§ ÏâΩÍ≤å ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌï¥ Í∞úÎ∞úÌïú Ìå®ÌÇ§ÏßÄ ÏûÖÎãàÎã§. Í∏∞Ï°¥Ïùò Ïó∞ÎèôÏÑ±ÏùÑ ÏµúÎåÄÌïú Ïú†ÏßÄÌïòÎ©¥ÏÑúÎèÑ ÌååÏù¥Ïç®ÎãâÌïòÍ≤å ÏΩîÎìúÎ•º Ïß§ Ïàò ÏûàÎèÑÎ°ù Í∞úÏÑ†ÌïòÍ≥†Ïûê ÌïòÏòÄÏäµÎãàÎã§. nbdevÏóêÏÑú Í∂åÏû•ÌïòÎäî Ïä§ÌÉÄÏùºÎ°ú ÏûëÏÑ±ÎêòÎã§Î≥¥Îãà jupyter notebookÏù¥ÎÇò jupyter labÏóêÏÑúÎäî ÏûêÎèôÏôÑÏÑ±Ïù¥ Ïûò ÏûëÎèôÎêòÏßÄÎßå, VS CodeÏóêÏÑúÎäî ÏûêÎèôÏôÑÏÑ±Ïù¥ ÏûëÎèô ÏïàÌï† Ïàò ÏûàÏäµÎãàÎã§. Í∏∞Ï°¥ ÏΩîÎìúÏôÄ Ïó∞ÎèôÏÑ± ÎπÑÍµêÌïòÍ∏∞ ÌöåÏÇ¨Ïõê ÏΩîÎî©Ïóê Í∞ÄÎ≥¥ÏãúÎ©¥ ÏïÑÎûòÏôÄ Í∞ôÏù¥ ÏûêÎèôÌôî ÏΩîÎìúÍ∞Ä ÏûàÏäµÎãàÎã§. [code] Ïù¥ ÏΩîÎìúÎäî Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Ïû•Ìô©ÌïòÎã§Í≥† Î≥º ÎßåÌïú ÏÉÅÌô©ÏûÖÎãàÎã§. Ïù¥ ÏΩîÎìúÎ•º [code] Î•º ÏÇ¨Ïö©ÌïòÎ©¥ ÏïÑÎûòÏôÄ Í∞ôÏù¥ Í∞ÑÍ≤∞ÌïòÍ≤å Ï†ïÎ¶¨Í∞Ä Îê®ÏùÑ Î≥º Ïàò ÏûàÏäµÎãàÎã§. [code] True Ïù¥Î†áÍ≤å ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî Í∏∞Îä•ÏùÄ Ìï®ÏàòÎ°ú ÎßåÎì§ÏóàÏäµÎãàÎã§. [code] Í∏ÄÏûê Î™®ÏñëÏùÑ Î∞îÍæ∏Îäî Í≤ÉÏùÄ ÏûêÏ£º ÏûàÎäî Ìï®Ïàò ÏûÖÎãàÎã§. win32comÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ ÏïÑÎûòÏôÄ Í∞ôÏù¥ ÏûëÏÑ±Ìï¥Ïïº Ìï©ÎãàÎã§. [code] Ïù¥Î†áÍ≤å ÏûêÏ£º ÏÇ¨Ïö©ÎêòÎäî Í∏∞Îä•ÏùÄ Ìï®ÏàòÎ°ú ÎßåÎì§Ïñ¥ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÍ≤å ÌñàÏäµÎãàÎã§. [code] True ÏΩîÎìúÎ•º Î≥¥ÏãúÎ©¥ hwpÎ•º ÏÑ∏ÌåÖÌïòÎäî Î∂ÄÎ∂ÑÏù¥ Í∞ÑÎûµÌï¥Ï°åÏäµÎãàÎã§. ÎòêÌïú ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ïÏù¥ ÌååÏù¥Ïç¨ Í∞ùÏ≤¥Ï≤òÎüº ÏÑ§Ï†ïÌï† Ïàò ÏûàÍ≤å Î≥ÄÍ≤Ω ÎêòÏñ¥ ÏûàÎäî Í≤ÉÏùÑ Î≥º Ïàò ÏûàÏäµÎãàÎã§. Ïù¥Îü∞ ÏãùÏúºÎ°ú ÌååÏù¥Ïç¨ÏóêÏÑú ÏÇ¨Ïö©ÌïòÍ∏∞ ÏâΩÍ≤å ÎßåÎì§ÏóàÏäµÎãàÎã§. Ïôú HwpApiÎ•º ÎßåÎì§ÏóàÎÇòÏöî? Í∞ÄÏû• ÌÅ∞ Ïù¥Ïú†Îäî Ïä§Ïä§Î°ú ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú ÏûÖÎãàÎã§. ÏßÅÏû•Ïù∏ÏúºÎ°ú ÎßéÏùÄ ÌïúÍ∏Ä Î¨∏ÏÑúÎ•º Ìé∏ÏßëÌïòÍ≥† ÏûëÏÑ±ÌïòÍ≥§ ÌïòÎäîÎç∞ Îã®Ïàú Î∞òÎ≥µÏóÖÎ¨¥Í∞Ä ÎÑàÎ¨¥ ÎßéÎã§Îäî Í≤ÉÏù¥ Î∂àÎßåÏù¥ÏóàÏäµÎãàÎã§. Ïù¥Îü∞ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî Î∞©Î≤ïÏúºÎ°ú ÌïúÍ∏Ä ÏûêÎèôÌôîÏóê ÎåÄÌïú Ïù¥ÏïºÍ∏∞Î•º ÌååÏù¥ÏΩòÏóêÏÑú Î≥¥Í≤å ÎêòÏóàÏäµÎãàÎã§. ÌäπÌûà ‚ÄòÌöåÏÇ¨Ïõê ÏΩîÎî©‚Äô ÎãòÏùò Î∏îÎ°úÍ∑∏ÏôÄ ÏòÅÏÉÅÏù¥ ÎßéÏùÄ Ï∞∏Ï°∞Í∞Ä ÎêòÏóàÏäµÎãàÎã§. Îã§Îßå Í∑∏ Í≥ºÏ†ïÏóêÏÑú ÏÑ§Î™ÖÏûêÎ£åÍ∞Ä Î∂ÄÏ°±ÌïòÍ∏∞ÎèÑ ÌïòÍ≥† ÏòàÏ†ÑÏóê ÏûëÏÑ±ÌñàÎçò ÏΩîÎìúÎì§ÏùÑ ÏûêÍæ∏ Ï∞æÏïÑÎ≥¥Í≤å ÎêòÎ©¥ÏÑú ÏïÑÎûòÏïÑ ÌïúÍ∏Ä Ïö© ÌååÏù¥Ïç¨ Ìå®ÌÇ§ÏßÄÍ∞Ä ÏûàÏúºÎ©¥ Ï¢ãÍ≤†Îã§Îäî ÏÉùÍ∞ÅÏùÑ ÌñàÏäµÎãàÎã§. ÌäπÌûà ÏóÖÎ¨¥Î•º ÌïòÎ©¥ÏÑú ÏóëÏÖÄ ÏûêÎèôÌôîÎ•º ÏúÑÌï¥ xlwingsÎ•º ÏÇ¨Ïö©Ìï¥ Î≥¥Î©¥ÏÑú ÌååÏù¥Ïç¨ÏúºÎ°ú ÏÇ¨Ïö©ÌïòÍ∏∞ ÏâΩÍ≤å ÎßåÎì† ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏΩîÎî© ÏûëÏóÖ Ìö®Ïú®ÏùÑ ÏóÑÏ≤≠ Ïò¨Î¶∞Îã§Îäî Í≤ÉÏùÑ Íπ®Îã´Í≤å ÎêòÏóàÏäµÎãàÎã§. Ï†úÏ∂ú ÎßàÍ∞êÍπåÏßÄ Ìï¥Ïïº Ìï† ÏùºÎì§ÏùÑ Îπ†Î•¥Í≤å ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú Îπ†Î•¥Í≤å ÌïúÍ∏Ä ÏûêÎèôÌôîÍ∞Ä ÎêúÎã§Î©¥ Ï¢ãÍ≤†Îã§Îäî ÏÉùÍ∞ÅÏúºÎ°ú ÎßåÎì§Í≤å ÎêòÏóàÏäµÎãàÎã§. Í∏∞Î≥∏Ï†ÅÏù∏ Ï≤†ÌïôÏùÄ xlwingsÏùÑ Îî∞ÎùºÌïòÍ≥† ÏûàÏäµÎãàÎã§. Í∏∞Î≥∏Ï†ÅÏúºÎ°úÎäî ÏûêÏ£º Ïì∞Ïù¥Îäî Ìï≠Î™©Îì§ÏùÑ ÏÇ¨Ïö©ÌïòÍ∏∞ ÏâΩÍ≤å Ï†ïÎ¶¨Ìïú Î©îÏÜåÎìú Îì±ÏúºÎ°ú Íµ¨ÌòÑÌïòÍ≥†, Î∂ÄÏ°±Ìïú Î∂ÄÎ∂ÑÏùÄ [ [code] ](https://JunDamin.github.io/hwpapi/02_api/core.html#app.api)ÌòïÌÉúÎ°ú [code] ÏúºÎ°ú ÌïòÎäî Í≤ÉÍ≥º ÎèôÏùºÌïú ÏûëÏóÖÏù¥ Í∞ÄÎä•ÌïòÍ≤å ÌïòÏó¨ ÌïúÍ∏Ä apiÏùò Î™®Îì† Í∏∞Îä•ÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù Íµ¨ÌòÑÌïòÏòÄÏäµÎãàÎã§. Î©îÏÜåÎìúÎ°ú ÎßåÎìúÎäî Í≤ÉÏóêÎäî ÏïÑÏßÅ Í≥†ÎØºÏù¥ ÏûàÏäµÎãàÎã§. chainÍ≥º Í∞ôÏùÄ ÌòïÌÉúÎ°ú Ïó¨Îü¨Í∞ÄÏßÄ ÏΩ§ÎπÑÎÑ§Ïù¥ÏÖòÏùÑ ÏÇ¨Ï†ÑÏóê ÏÑ∏ÌåÖÏùÑ Ìï¥Ïïº ÌïòÎÇò Ïã∂ÏùÄ Î∂ÄÎ∂ÑÎèÑ ÏûàÍ≥† Ïã§Ï†úÎ°ú Ïú†Ïö©ÌïòÍ≤å ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎäî Ïó¨Îü¨Í∞ÄÏßÄ ÏïÑÏù¥ÌÖú Îì±ÎèÑ ÏûàÏñ¥ÏÑú Ïñ¥Îñ§ Î∂ÄÎ∂ÑÍπåÏßÄ Ïù¥ Ìå®ÌÇ§ÏßÄÏóê Íµ¨ÌòÑÌï†ÏßÄÎäî Í≥†ÎØºÌïòÍ≥† ÏûàÏäµÎãàÎã§. Îã§Îßå Ïù¥Îü∞ ÌòïÌÉúÏùò ÏûëÏóÖÏùÑ ÌÜµÌï¥ÏÑú Ïñ¥Ï©åÎ©¥ hwp api wrapperÍ∞Ä ÌôúÏÑ±Ìôî ÎêòÏñ¥ÏÑú Îã®Ïàú ÏûëÏóÖÏùÑ ÏûêÎèôÌôî Ìï† Ïàò ÏûàÍ∏∞Î•º Î∞îÎùºÍ≥† ÏûàÏäµÎãàÎã§.",https://github.com/JunDamin/hwpapi/blob/957ac265e9661725cfa4115adf23c7bc9fe73fb8/claude.md
1133415136,SecureGen,chatchailim/SecureGen,https://github.com/chatchailim/SecureGen,SecureGen (BTC Edition) ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏µ‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cryptocurrency ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞ BTC E-Wallet ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö Seed Phrase/Private Key ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° Zero-,,0,Unknown,,CLAUDE.md,"SecureGen - Thai Smart Password Manager üáπüá≠ SecureGen is a client-side password generator and manager designed specifically for Thai users. It leverages the ""Thai-Shift"" keyboard logic to convert memorable Thai phrases into complex English passwords, alongside AI-powered mnemonic generation. Live Demo: [Link to your GitLab Pages] --- üìö Documentation (‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö) * üìñ User Manual (‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô) - Built inside the App (Click the Help/Book icon). * üìò Beginner Developer Manual (‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) - New to coding? Start here! ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö. * üõ†Ô∏è Technical Design Spec - Deep dive into architecture and logic. * üß™ Test Specification - How to test the application. --- ‚ú® Key Features (‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å) * üáπüá≠ Thai-Shift Generator: Convert Thai phrases (e.g., ""‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"") into complex strings based on QWERTY key mapping. * ü§ñ AI Creative Mode: Use Google Gemini API to generate secure passwords from context/mnemonics. * üß† Memory Test: Built-in tool to test if you can remember the generated password before using it. * üîí Client-Side Only: Runs entirely in the browser. No data is ever sent to a server (except for AI generation prompts, which are stateless). * üíæ Encrypted Export: Export your credentials using AES encryption for backup. * üì± PWA Ready: Installable on mobile and desktop. --- üöÄ Getting Started (‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô) Prerequisites * Node.js (v18 or higher) * npm or yarn Installation 1. Clone the repository [code] 2. Install dependencies [code] 3. Set up Environment Variables (Optional) If you want to use the AI features locally without entering the key in the UI every time, create a [code] file: [code] 4. Run Development Server [code] Open [code] in your browser. --- üèóÔ∏è Project Structure [code] --- ü§ù Contributing We welcome contributions! Please see CONTRIBUTING.md for details on how to submit Merge Requests and report issues. --- üõ°Ô∏è Privacy & Security * Zero-Knowledge Architecture: We do not store your passwords. Everything is stored in your browser's RAM and cleared when the tab is closed. * BYOK (Bring Your Own Key): For AI features, users provide their own Gemini API keys for maximum privacy. --- üìû Contact & Credits Presented by: SPADA Service (Nextwaver.Net Co., Ltd.) Developer: Mr. Chatchai Limprasertsiri Email: chatchai@nextwaver.com Licensed under the MIT License.",https://github.com/chatchailim/SecureGen/blob/29a1d9ec1dbf425c6eca8a591d62bcb27949c0bf/CLAUDE.MD
713509512,heimdall-v2,0xPolygon/heimdall-v2,https://github.com/0xPolygon/heimdall-v2,Official consensus client of the Polygon blockchain.,,0,Unknown,,CLAUDE.md,"heimdall-v2 Consensus client of the Polygon PoS chain, using forks of cometBFT and cosmos-sdk. Pre-requisites Make sure you have go1.25+ already installed. Build [code] This will produce the binary [code] in the [code] directory. Initialize heimdall [code] You can skip [code] flag if you want to run this locally (it will default to [code] ). Otherwise, use [code] for [code] , or [code] for [code] . [code] is the name of your node, which can be any string you like. This command will generate some folders and files in the heimdall home directory (default /var/lib/heimdall). Run heimdall [code] How to use the keyring Instructions on how to import your validator private key into the keyring and use it to sign transactions. Get your [code] encoded private key from: [code] Convert the [code] encoded key to the hex encoded key: [code] Import the [code] encoded key to your keyring: [code] When you first import a key into the keyring, you will be prompted for a password, which will be used every time you sign a transaction. When running a [code] command, specify the [code] argument, by using the name of the key you have set above. Example: [code]",https://github.com/0xPolygon/heimdall-v2/blob/52db3a5156bf8196f739980aa6293281f2690e9b/CLAUDE.md
1127277318,galroon,llpgf/galroon,https://github.com/llpgf/galroon,NOT YET WORK!!! Still Building,,0,Unknown,,CLAUDE.md,"Galroon Galgame Manager A modern, portable visual novel (galgame) library management system. [](https://www.gnu.org/licenses/gpl-3.0) [](https://www.python.org/downloads/) [](https://react.dev/) [](https://www.electronjs.org/) [](https://github.com/llpgf/galroon) --- Development build notice This is an active development build (v0.3.0). It is not production ready. Do not use for: - production use - managing important libraries - daily game management - expecting stable performance --- Current status - Backend: feature-complete for current roadmap (API and services stable) - Frontend: in progress (core library UI is functional; remaining pages in progress) - Launcher: feature-complete - Testing: partial coverage (backend tests exist, frontend tests limited) --- What changed in v0.3.0 - Backend legacy endpoints moved out of [code] into a dedicated legacy router. - Legacy endpoints now share read-only dependency logic. - Frontend routing structure standardized with [code] for page components. - API client initialization fixed to wait for session token and dynamic port. - UI tokens consolidated into a single global stylesheet. - Manual chunk splitting and lazy loading for heavy dashboards. - New onboarding and architecture docs for faster handoff. --- Features (planned and in progress) - Automatic library scanning (manual, scheduled, realtime) - Rich metadata (VNDB, others in progress) - Portable mode (launcher supported) - Smart search and filtering - Analytics and knowledge graphs (in progress) - Safe trash management --- Quick start (dev) Backend: [code] Frontend: [code] Tests: [code] --- Project structure [code] --- Documentation - [code] - [code] - [code] - [code] --- Contributing 1. Fork the repo 2. Create a feature branch 3. Make changes and add tests where possible 4. Open a pull request Code style: - Python: follow PEP 8 - TypeScript: follow ESLint rules --- License GPL v3. See [code] .",https://github.com/llpgf/galroon/blob/db267f1b8cb269c8133ee350dca378d53acaa606/claude.md
779225867,template-hono-prisma-kysely,constROD/template-hono-prisma-kysely,https://github.com/constROD/template-hono-prisma-kysely,,,0,Unknown,,CLAUDE.md,"Template Hono Prisma Kysely by bossROD Description This is an opinionated, robust template for backend development either for serverless or non-serverless using Node.js or SST (Serverless Stack) with Hono, Prisma, and Kysely. The project includes ESLint, Prettier, Husky, and lint-staged for code quality and consistency. It also features Vitest for testing, Swagger and Scalar for API documentation, and Docker for local database management. The template is set up with TypeScript for type safety and uses pnpm as the package manager. Rules - Please read the repo's Project Structure & Code Organization here README.project-structure.md - For the coding standards, please read the rules in this folder rules Clone Choose the approach that best fits your needs: 1. Standalone Hono Server Branch: main For a basic setup using just the Hono server: [code] 2. With SST v2 (AWS Provider) Branch: with-sst-v2 For a setup integrated with Serverless Stack (SST) v2 - AWS Provider: [code] 3. With Wrangler (Cloudflare Provider) Branch: with-cloudflare For a setup integrated with Wrangler - Cloudflare Provider: [code] 4. With JWT Auth Branch: with-jwt-auth For a setup with JWT authentication: [code] Choose the command that corresponds to your preferred API layer approach. Prerequisites - Download extension ESLint and Prettier - Code formatter in your VSCode. - Install node using nvm or fnm (check version in .nvmrc) - Install pnpm (check version in package.json file look for [code] ) - Install Docker for database containerization. Installation - Install dependencies. [code] Development Mode: - Start the database container. [code] - Stop the database container. [code] - Start the development server. [code] Production Mode: - Build the project. [code] - Start the build for production. [code]",https://github.com/constROD/template-hono-prisma-kysely/blob/d2472498bfd6af0f8f63b584a5860a9185b28ba5/CLAUDE.md
1118277308,insurance-claims-platform,hyunolike/insurance-claims-platform,https://github.com/hyunolike/insurance-claims-platform,üèÉüèª -,,0,Unknown,,CLAUDE.md,"Î≥¥ÌóòÍ∏à Ï≤≠Íµ¨ ÏûêÎèôÌôî ÏãúÏä§ÌÖú > Ïù¥Î≤§Ìä∏ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÎ°ú Î≥¥ÌóòÍ∏à Ï≤≠Íµ¨Î∂ÄÌÑ∞ ÏßÄÍ∏âÍπåÏßÄÏùò Ï†Ñ Í≥ºÏ†ïÏùÑ ÏûêÎèôÌôîÌïòÎäî Î∞±ÏóîÎìú ÏãúÏä§ÌÖú ÌîÑÎ°úÏ†ùÌä∏ Í∞úÏöî Î≥¥ÌóòÍ∏à Ï≤≠Íµ¨ Í≥ºÏ†ïÏùÑ Ï≤≠Íµ¨ ‚Üí Ïã¨ÏÇ¨ ‚Üí ÏßÄÍ∏â ‚Üí ÏïåÎ¶ºÏùò Ïù¥Î≤§Ìä∏ ÌùêÎ¶ÑÏúºÎ°ú ÏûêÎèôÌôîÌïòÏó¨, Ï≤òÎ¶¨ ÏãúÍ∞ÑÏùÑ Îã®Ï∂ïÌïòÍ≥† Í≥†Í∞ù Í≤ΩÌóòÏùÑ Í∞úÏÑ†Ìï©ÎãàÎã§. ÌïµÏã¨ Î™©Ìëú - Ï≤òÎ¶¨ ÏãúÍ∞Ñ: ÌèâÍ∑† 10Î∂Ñ ‚Üí 7Î∂Ñ Ïù¥ÌïòÎ°ú Îã®Ï∂ï - Ïû¨Ïò§ÌîàÏú®: Í≥†Í∞ù Î¨∏Ïùò Ïû¨Ïò§ÌîàÏú® 5% ‚Üí 2% Ïù¥ÌïòÎ°ú Í∞êÏÜå - ÏûêÎèôÌôîÏú®: ÏàòÎèô Ïã¨ÏÇ¨ Í∞úÏûÖ ÏµúÏÜåÌôî, Rule Engine Í∏∞Î∞ò ÏûêÎèô ÏäπÏù∏ Ï£ºÏöî ÌäπÏßï - Ïù¥Î≤§Ìä∏ Í∏∞Î∞ò ÎπÑÎèôÍ∏∞ Ï≤òÎ¶¨ (Kafka) - Î∂ÑÏÇ∞ Ï∫êÏã±ÏúºÎ°ú Îπ†Î•∏ ÏÉÅÌÉú Ï°∞Ìöå (Redis) - Ï§ëÎ≥µ ÏßÄÍ∏â Î∞©ÏßÄ Î∞è Ìä∏ÎûúÏû≠ÏÖò Ï†ïÌï©ÏÑ± Î≥¥Ïû• - Í∞úÏù∏Ï†ïÎ≥¥ ÏïîÌò∏Ìôî Î∞è Í∞êÏÇ¨ Î°úÍ∑∏ ÏûêÎèô Í∏∞Î°ù - Observability Í∏∞Î∞ò Ïã§ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅ Í∞úÎ∞ú ÏùºÏ†ï ÌîÑÎ°úÏ†ùÌä∏ Í∏∞Í∞Ñ: 2025-12-28 ~ 2026-01-12 (16Ïùº) | Phase | Í∏∞Í∞Ñ | ÏôÑÎ£åÏùº | Ï£ºÏöî ÏÇ∞Ï∂úÎ¨º | |-------|------|--------|------------| | Phase 0 | 1Ïùº | 2025-12-28 | Í∞úÎ∞ú ÌôòÍ≤Ω ÏôÑÏÑ± | | Phase 1 | 3Ïùº | 2025-12-31 | Ï≤≠Íµ¨ ÏÉùÏÑ±/Ï°∞Ìöå API | | Phase 2 | 2Ïùº | 2026-01-02 | Ïù¥Î≤§Ìä∏ Í∏∞Î∞ò Íµ¨Ï°∞ (ÎèôÍ∏∞) | | Phase 3 | 3Ïùº | 2026-01-05 | Kafka ÎπÑÎèôÍ∏∞ Ï≤òÎ¶¨ | | Phase 4 | 4Ïùº | 2026-01-09 | Ïã¨ÏÇ¨ + ÏßÄÍ∏â ÏûêÎèôÌôî (MVP) | | Phase 5 | 3Ïùº | 2026-01-12 | ÏïåÎ¶º + Observability | Ï£ºÏöî ÎßàÏùºÏä§ÌÜ§: - üéØ M1 (2025-12-31): Ï≤´ API ÏôÑÏÑ± - [code] , [code] - üéØ M2 (2026-01-05): Kafka ÎπÑÎèôÍ∏∞ Ïù¥Î≤§Ìä∏ Ï≤òÎ¶¨ - üéØ M3 (2026-01-09): MVP ÏôÑÏÑ± - Ï≤≠Íµ¨ ‚Üí Ïã¨ÏÇ¨ ‚Üí ÏßÄÍ∏â Ï†ÑÏ≤¥ ÌùêÎ¶Ñ - üéØ M4 (2026-01-12): Ï†ÑÏ≤¥ ÏôÑÏÑ± - ÏïåÎ¶º, Í∞êÏÇ¨, Î™®ÎãàÌÑ∞ÎßÅ ÏûêÏÑ∏Ìïú ÏùºÏ†ïÏùÄ Í∞úÎ∞ú Í≥ÑÌöçÏÑú, WBS Ï∞∏Í≥† --- ÏãúÏä§ÌÖú ÏïÑÌÇ§ÌÖçÏ≤ò Ï†ÑÏ≤¥ Íµ¨Ï°∞ÎèÑ [code] ÏÑúÎπÑÏä§ Íµ¨ÏÑ± API Layer - Claim API: Î≥¥ÌóòÍ∏à Ï≤≠Íµ¨ ÏÉùÏÑ±, ÏÉÅÌÉú Ï°∞Ìöå - Payment API: ÏßÄÍ∏â ÏÉÅÌÉú Í¥ÄÎ¶¨ - Query API: ÌÜµÌï© Ï°∞Ìöå (ÌÉÄÏûÑÎùºÏù∏, ÏïåÎ¶º ÌûàÏä§ÌÜ†Î¶¨) Application Layer - Claim Service: Ï≤≠Íµ¨ ÏÉùÏÑ±/ÏÉÅÌÉú Ï†ÑÌôò/Îç∞Ïù¥ÌÑ∞ Ï†ÅÏû¨ Îã¥Îãπ - Rule Engine Service: ÏûêÎèô Ïã¨ÏÇ¨ Í∑úÏπô Ïã§Ìñâ Î∞è ÏäπÏù∏/Í±∞Î∂Ä ÌåêÏ†ï - Payment Service: Î≥¥ÌóòÍ∏à ÏßÄÍ∏â Ï≤òÎ¶¨ - Notification Service: Í≥†Í∞ù ÏïåÎ¶º Î∞úÏÜ° (Push, SMS, Email) - Event Publisher: Kafka Ïù¥Î≤§Ìä∏ Î∞úÌñâ Í¥ÄÎ¶¨ Infrastructure Layer - Kafka: Ïù¥Î≤§Ìä∏ Î≤ÑÏä§, ÏÑúÎπÑÏä§ Í∞Ñ ÎπÑÎèôÍ∏∞ ÌÜµÏã† - Redis: Î∂ÑÏÇ∞ Ï∫êÏãú Î∞è Î∂ÑÏÇ∞ ÎùΩ - PostgreSQL: ÏòÅÏÜç Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•ÏÜå - Encryption Module: Í∞úÏù∏Ï†ïÎ≥¥ ÏïîÌò∏Ìôî --- Ïù¥Î≤§Ìä∏ ÌùêÎ¶Ñ [code] 1. Ï≤≠Íµ¨ ÏÉùÏÑ± (claim.requested) - Í≥†Í∞ùÏù¥ Î™®Î∞îÏùº Ïï±ÏóêÏÑú Î≥¥ÌóòÍ∏à Ï≤≠Íµ¨ Îì±Î°ù - Claim ServiceÍ∞Ä Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÌõÑ Ïù¥Î≤§Ìä∏ Î∞úÌñâ - Notification ServiceÍ∞Ä ""Ï≤≠Íµ¨ Ï†ëÏàò ÏôÑÎ£å"" ÏïåÎ¶º Î∞úÏÜ° 2. ÏûêÎèô Ïã¨ÏÇ¨ (claim.reviewed) - Rule EngineÏù¥ Ïã¨ÏÇ¨ Í∑úÏπô Ïã§Ìñâ - ÏûêÎèô ÏäπÏù∏/Í±∞Î∂Ä ÌåêÏ†ï ÌõÑ Í≤∞Í≥º Ï†ÄÏû• - Ïã¨ÏÇ¨ Í≤∞Í≥ºÎ•º KafkaÎ°ú Î∞úÌñâ 3. ÏäπÏù∏ ÌôïÏ†ï (claim.approved) - ÏäπÏù∏Îêú Ï≤≠Íµ¨Ïóê ÎåÄÌï¥ Ïù¥Î≤§Ìä∏ Î∞úÌñâ - Payment ServiceÍ∞Ä ÏßÄÍ∏â ÌîÑÎ°úÏÑ∏Ïä§ ÏãúÏûë - Audit ServiceÍ∞Ä ÏäπÏù∏ Ïù¥Î†• Í∏∞Î°ù 4. ÏßÄÍ∏â ÏôÑÎ£å (claim.disbursed) - Payment ServiceÍ∞Ä Í≥ÑÏ¢å Ïù¥Ï≤¥ Ï≤òÎ¶¨ - ÏßÄÍ∏â ÏôÑÎ£å Ïù¥Î≤§Ìä∏ Î∞úÌñâ - Notification ServiceÍ∞Ä ""ÏßÄÍ∏â ÏôÑÎ£å"" ÏïåÎ¶º Î∞úÏÜ° - ObservabilityÏóê SLA ÏßÄÌëú Í∏∞Î°ù --- API ÏóîÎìúÌè¨Ïù∏Ìä∏ Ï≤≠Íµ¨ ÏÉùÏÑ± [code] Ï≤≠Íµ¨ ÏÉÅÌÉú Ï°∞Ìöå [code] ÏùëÎãµ ÏòàÏãú: [code] Ïã¨ÏÇ¨ Í≤∞Ï†ï Îì±Î°ù [code] ÏßÄÍ∏â ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏ [code] ÏûêÏÑ∏Ìïú API Î™ÖÏÑ∏Îäî API.md Ï∞∏Í≥† --- Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Íµ¨Ï°∞ ÌïµÏã¨ ÏóîÌÑ∞Ìã∞ [code] ÏûêÏÑ∏Ìïú ERDÎäî ERD.md Ï∞∏Í≥† --- Í∏∞Ïà† Ïä§ÌÉù Core Stack | ÏòÅÏó≠ | Í∏∞Ïà† | ÏÑ†ÌÉù Ïù¥Ïú† | |------|------|-----------| | Language | Java 24 | ÌÜ†Ïä§ ÌëúÏ§Ä | | Framework | Spring Boot | ÏÉùÌÉúÍ≥Ñ, ÏïàÏ†ïÏÑ± | | Build | Gradle | ÎåÄÍ∑úÎ™® ÌîÑÎ°úÏ†ùÌä∏ ÌëúÏ§Ä | | DB | PostgreSQL | Í∏àÏúµÍ∂å ÏÑ†Ìò∏, ACID Î≥¥Ïû• | | Cache | Redis | Î∂ÑÏÇ∞ ÎùΩ, Í≥†ÏÜç Ï∫êÏã± | | Messaging | Kafka | Ïù¥Î≤§Ìä∏ Ï§ëÏã¨ ÏïÑÌÇ§ÌÖçÏ≤ò | | ORM | JPA + QueryDSL | Í∞ÄÎèÖÏÑ± + ÏÑ±Îä• | Observability | Ìï≠Î™© | Í∏∞Ïà† | |------|------| | Metrics | Micrometer + Prometheus | | Logging | Logback + JSON Ìè¨Îß∑ | | Tracing | Î∂ÑÏÇ∞ Ï∂îÏ†Å (traceId Ìó§Îçî) | | Monitoring | Grafana ÎåÄÏãúÎ≥¥Îìú | ÏûêÏÑ∏Ìïú Í∏∞Ïà† Ïä§ÌÉùÏùÄ skillset.md Ï∞∏Í≥† --- ÌîÑÎ°úÏ†ùÌä∏ Íµ¨Ï°∞ [code] --- ÏãúÏûëÌïòÍ∏∞ ÌïÑÏàò ÏöîÍµ¨ÏÇ¨Ìï≠ - Java 24 - Gradle 7.x+ - Docker & Docker Compose (Î°úÏª¨ Í∞úÎ∞ú ÌôòÍ≤Ω) Î°úÏª¨ ÌôòÍ≤Ω Ïã§Ìñâ 1. Ïù∏ÌîÑÎùº Ïã§Ìñâ (Kafka, Redis, PostgreSQL) [code] | ÏÑúÎπÑÏä§ | Ïù¥ÎØ∏ÏßÄ | Ìò∏Ïä§Ìä∏ Ìè¨Ìä∏ | ÎπÑÍ≥† | |--------|--------|-------------|------| | PostgreSQL | [code] | 5432 | DB/USER/PASSWORD = [code] / [code] / [code] | | Redis | [code] | 6379 | Í∏∞Î≥∏ ÏÑ§Ï†ï | | Zookeeper | [code] | 2181 | Kafka ÏùòÏ°¥ÏÑ± | | Kafka |",https://github.com/hyunolike/insurance-claims-platform/blob/9b283ef930b7bab07614a9c073e37f85c46d1a94/CLAUDE.MD
997661524,nathan_for_us,burningion/nathan_for_us,https://github.com/burningion/nathan_for_us,,,0,Unknown,,CLAUDE.md,"Nathan For Us - Comprehensive Memory System Overview Nathan For Us is a Phoenix LiveView application that analyzes Nathan Fielder content through two main systems: 1. Video Search System - Frame-by-frame video analysis with caption search 2. Skeets Coverage System - Real-time Bluesky social media monitoring The system enables users to search for any spoken dialogue in Nathan's interviews and see the exact frames where those words were said, plus monitor social media mentions in real-time. Quick Start Guide Getting the App Running [code] Key routes: - [code] - Home page - [code] - Video search interface - [code] - Bluesky mention monitoring (requires authentication) - [code] - Admin panel (requires admin privileges) Basic Commands [code] Video Search System Current Implementation The video search system provides global search across all videos simultaneously. Users can search for any spoken dialogue and see matching frames from all Nathan Fielder interviews. Live at: https://www.nathanforus.com/video-search Key Features - Cross-video search - Single query searches all 5+ videos - Visual results - Shows actual video frames with timestamps - Caption matching - Finds exact dialogue with context - Video filtering - Optional filtering to specific videos - Mosaic display - Grid view of matching frames Search Interface ( [code] ) [code] UI Components: - Search header with status display - Search form with quick suggestions (""nathan"", ""business"", ""train"", ""conan"", ""rehearsal"") - Video filter modal for selective searching - Results grid showing frames with captions and video titles - Loading states and empty states Database Schema ( [code] ) [code] Search Functionality [code] Video Processing Pipeline Automated Processing ( [code] ) Full YouTube to Production pipeline: [code] Manual Processing Steps 1. Download video: [code] 2. Process locally: [code] 3. Verify processing: [code] Processing Components ( [code] ) - Producer - GenStage queue management - FrameExtractor - FFmpeg frame extraction at 1fps - CaptionParser - SRT file parsing to timestamped segments - DatabaseConsumer - Batch storage in PostgreSQL Alternative Video-Specific Search The original video-specific search implementation is preserved in [code] for future ""episode search"" functionality. To restore: [code] Skeets Coverage System Real-time Bluesky Monitoring The skeets system monitors Bluesky (AT Protocol) for mentions of Nathan Fielder in real-time using the firehose stream. Live at: https://www.nathanforus.com/skeets Key Features - Real-time monitoring via AT Protocol firehose - Live updates using Phoenix PubSub and LiveView - Rich media display - images, videos, external links - User profiles - automatic fetching of Bluesky user data - Mention log - terminal/captain's log aesthetic - Filtered content - excludes test accounts Skeets Interface ( [code] ) [code] Database Schema ( [code] ) [code] Firehose Integration ( [code] ) [code] UI Components Post Display: - Terminal/captain's log styli",https://github.com/burningion/nathan_for_us/blob/4752026dce907b348541c852f5b1f040f61c5222/genstage_learning_for_claude.md
947580034,terraform-cloud-mcp,severity1/terraform-cloud-mcp,https://github.com/severity1/terraform-cloud-mcp,"A Model Context Protocol (MCP) server that integrates AI assistants with the Terraform Cloud API, allowing you to manage your infrastructure through natural conversation",,0,Unknown,,CLAUDE.md,"[](https://mseep.ai/app/severity1-terraform-cloud-mcp) Terraform Cloud MCP Server A Model Context Protocol (MCP) server that integrates AI assistants with the Terraform Cloud API, allowing you to manage your infrastructure through natural conversation. Built with Pydantic models and structured around domain-specific modules, this server is compatible with any MCP-supporting platform including Claude, Claude Code CLI, Claude Desktop, Cursor, Copilot Studio, and others. --- Features - Account Management: Get account details for authenticated users or service accounts. - Workspace Management: Create, read, update, lock/unlock workspaces, and optionally delete workspaces (with safety controls). - Project Management: Create, list, update projects, and optionally delete projects; manage project tag bindings and move workspaces between projects. - Run Management: Create runs, list runs, get run details, apply/discard/cancel runs. - Plan Management: Retrieve plan details and JSON execution output with advanced HTTP redirect handling. - Apply Management: Get apply details and recover from failed state uploads. - Organization Management: List, create, update organizations, view organization entitlements, and optionally delete organizations (with safety controls). - Cost Estimation: Retrieve detailed cost estimates for infrastructure changes including proposed monthly costs, prior costs, resource counts, and usage projections. - Assessment Results: Retrieve health assessment details, JSON output, schema files, and logs from Terraform Cloud health assessments. - State Version Management: List, retrieve, create, and download state versions; get current state for workspaces. - State Version Outputs: List and retrieve specific outputs from state versions including values and sensitivity information. - Variables Management: Complete workspace variable and variable set management including creation, updates, assignments, and optionally deletion (with safety controls). Performance Features - Audit-Safe Response Filtering: Conservative token optimization (5-15% reduction) with 100% audit compliance - preserves all user accountability, security configuration, and change tracking data for comprehensive compliance scenarios. Safety Features - Destructive Operation Controls: Delete operations are disabled by default and require explicit enablement via environment variable - Read-Only Mode: All write operations can be disabled with [code] for maximum safety in production environments - Destructive Hints: MCP clients receive proper destructive operation warnings for potentially dangerous tools - Environment-Based Safety: Production and development environments can have different safety configurations --- Quick Start Prerequisites - Python 3.12+ - MCP (includes FastMCP and development tools) - [code] package manager (recommended) or [code] - Terraform Cloud API token Creating a Terraform Cloud API Token To use this MCP server, you need a Terraform Cloud (or Terraform Ente",https://github.com/severity1/terraform-cloud-mcp/blob/2e7865580438c97cd5ce115e357b6ac320b2c323/CLAUDE.md
33373508,mediawiki-el,hexmode/mediawiki-el,https://github.com/hexmode/mediawiki-el,Emacs interface to edit any mediawiki site,,0,Unknown,,CLAUDE.md,"== mediawiki.el -- Edit mediawiki sites from emacs == This version of mediawiki.el represents a merging of wikipedia-mode.el (maintained by Uwe Brauer) from [http://www.emacswiki.org/emacs/wikipedia-mode.el EmacsWiki] for its font-lock code, menu, draft mode, replying and convenience functions to produce mediawiki.el 2.0. The package has been reorganized into a modular structure for better maintainability and code organization, while maintaining full backward compatibility. === Installation === If you use [http://melpa.org/#/mediawiki MELPA], you can install via the M-x package-list-packages interface. This is preferrable as you will have access to updates automatically. Otherwise, just make sure this file is in your load-path (usually ~/.emacs.d is included) and put (require 'mediawiki) in your ~/.emacs or ~/.emacs.d/init.el file. '''Note:''' The modular structure is completely transparent to users. Simply require 'mediawiki as before and all functionality will be available. The reorganization maintains full backward compatibility. ==== Configuration and use ==== M-x customize-group RET mediawiki RET *dink* *dink* M-x mediawiki-site RET Wikipedia RET Open a wiki file: M-x mediawiki-open Save a wiki buffer: C-x C-s Save a wiki buffer with a different name: C-x C-w ==== About Security ==== Although there is a place to put your password when you customize this package, there is no need to store your password in plain text. If mediawiki sees that the password is empty, then it will use [https://www.gnu.org/software/emacs/manual/html_mono/auth.html the auth-source library] to retrieve the password. This will allow you to use encryption to store your passwords. === Package Structure === The mediawiki.el package is now organized into the following modular components: * '''mediawiki.el''' - Main entry point with package metadata and requires * '''mediawiki-core.el''' - Core variables, constants, and fundamental utilities * '''mediawiki-faces.el''' - Font-lock face definitions for MediaWiki syntax * '''mediawiki-font-lock.el''' - Font-lock keywords and syntax highlighting rules * '''mediawiki-api.el''' - MediaWiki API interaction and data processing * '''mediawiki-auth.el''' - Authentication and login management * '''mediawiki-http.el''' - HTTP utilities and compatibility functions * '''mediawiki-page.el''' - Page editing, saving, and content management * '''mediawiki-draft.el''' - Draft functionality and temporary editing * '''mediawiki-site.el''' - Site configuration and management * '''mediawiki-utils.el''' - General utility functions * '''mediawiki-mode.el''' - Major mode definition and user interface This modular structure improves code organization and maintainability while preserving all existing functionality and maintaining full backward compatibility. === TODO === * Change customization to explicitly tell mediawiki.el to use the auth-source library. * Optionally use org-mode formatting for editing and translate that to mw * Move url-* methods t",https://github.com/hexmode/mediawiki-el/blob/cf091148fd8fcf17d81bc5ad556ae18c839f6507/CLAUDE.md
1032114654,zirk-it,markussandin1/zirk-it,https://github.com/markussandin1/zirk-it,Zirk.it MVP,,0,Unknown,,CLAUDE.md,,https://github.com/markussandin1/zirk-it/blob/c02087cc373c211587a28a944980f4110cf0385f/claude.md
1138856519,LangChain-Chinese,Hisn00w/LangChain-Chinese,https://github.com/Hisn00w/LangChain-Chinese,LangChainÂÆòÁΩëÊñáÊ°£ÊúÄÊñ∞ÁöÑ‰∏≠ÊñáÁøªËØëÔºåÂú®Á∫øÈòÖËØª,,0,Unknown,,CLAUDE.md,Ôªø# LangChain ‰∏≠ÊñáÊñáÊ°£ > Âú®Á∫øÈòÖËØªÔºöhttps://hisn00w.github.io/LangChain-Chinese/ > > ÂéüÁ´ôÔºöhttps://docs.langchain.com/ > > Â¶ÇÊúâ‰∏ç‰∏ÄËá¥ÔºåËØ∑‰ª•Ëã±ÊñáÂéüÊñá‰∏∫ÂáÜ„ÄÇ üìò ÂÖ≥‰∫éÊú¨È°πÁõÆ ËøôÊòØ LangChain ÂÆòÊñπÊñáÊ°£ÁöÑ‰∏≠ÊñáÁøªËØëÈ°πÁõÆÔºåÊó®Âú®Â∏ÆÂä©‰∏≠ÊñáÁî®Êà∑Êõ¥Â•ΩÂú∞Â≠¶‰π†Âíå‰ΩøÁî® LangChain„ÄÇ ‚ú® È°πÁõÆÁâπÁÇπ - ÊåÅÁª≠ÂêåÊ≠•ÂÆòÊñπÊñáÊ°£ÁªìÊûÑÔºåÈôç‰ΩéÂ≠¶‰π†Èó®Êßõ - ‰øùÁïôÂéüÊñáÁöÑÊäÄÊúØÊúØËØ≠‰∏é‰ª£Á†ÅÁ§∫‰æã - Êèê‰æõÊ∏ÖÊô∞ÁöÑÊñáÊ°£ÂØºËà™‰∏éÁ´†ËäÇÂàíÂàÜ üöÄ Âø´ÈÄüÂºÄÂßã ËØ∑‰ªéÂ∑¶‰æßÁõÆÂΩïÂºÄÂßãÈòÖËØªÔºåÊé®Ëçê‰ªé‰ª•‰∏ãÁ´†ËäÇÂÖ•Èó®Ôºö - Ê¶ÇËßà - ‰∫ÜËß£ LangChain ÊòØ‰ªÄ‰πà - Âø´ÈÄüÂºÄÂßã - 5 ÂàÜÈíüÂø´ÈÄü‰∏äÊâã - ÂÆâË£ÖÊåáÂçó - ÂÆâË£Ö‰∏éÈÖçÁΩÆËØ¥Êòé üß≠ ÈòÖËØªÂª∫ËÆÆ - Ëã•ÂØπ LangChain ÂÆåÂÖ®ÈôåÁîüÔºåÂª∫ËÆÆÊåâ‚ÄúÊ¶ÇËßà ‚Üí Âø´ÈÄüÂºÄÂßã ‚Üí ÂÆâË£ÖÊåáÂçó‚ÄùÁöÑÈ°∫Â∫èÈòÖËØª - Ëã•Â∑≤ÊúâÂü∫Á°ÄÔºåÂèØÁõ¥Êé•ÊåâÊ®°ÂùóËøõÂÖ• Core Components Êàñ Advanced Usage - ÂèëÁé∞ÁøªËØë‰∏ç‰∏ÄËá¥ÊàñÈÅóÊºèÊó∂ÔºåËØ∑‰ª•Ëã±ÊñáÂéüÊñá‰∏∫ÂáÜ üìö ÊñáÊ°£ÁªìÊûÑ Get Started - ÂºÄÂßã‰ΩøÁî® - ÂÆâË£Ö - ÁéØÂ¢ÉÈÖçÁΩÆÂíå‰æùËµñÂÆâË£Ö - Âø´ÈÄüÂºÄÂßã - Âø´ÈÄü‰∏äÊâãÊïôÁ®ã - Êõ¥Êñ∞Êó•Âøó - ÁâàÊú¨Êõ¥Êñ∞ËÆ∞ÂΩï - ËÆæËÆ°ÁêÜÂøµ - LangChain ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ Core Components - Ê†∏ÂøÉÁªÑ‰ª∂ - Agents - Êô∫ËÉΩ‰ΩìÁ≥ªÁªü - Models - ËØ≠Ë®ÄÊ®°ÂûãÈõÜÊàê - Messages - Ê∂àÊÅØÂ§ÑÁêÜÊú∫Âà∂ - Tools - Â∑•ÂÖ∑Ë∞ÉÁî®Á≥ªÁªü - Short-term Memory - Áü≠ÊúüËÆ∞ÂøÜÁÆ°ÁêÜ - Streaming - ÊµÅÂºèËæìÂá∫Â§ÑÁêÜ - Structured Output - ÁªìÊûÑÂåñËæìÂá∫ Middleware - ‰∏≠Èó¥‰ª∂ - Overview - ‰∏≠Èó¥‰ª∂Ê¶ÇËßà - Built-in Middleware - ÂÜÖÁΩÆ‰∏≠Èó¥‰ª∂ - Custom Middleware - Ëá™ÂÆö‰πâ‰∏≠Èó¥‰ª∂ Advanced Usage - È´òÁ∫ßÁî®Ê≥ï - Guardrails - ÂÆâÂÖ®Èò≤Êä§Êú∫Âà∂ - Runtime - ËøêË°åÊó∂ÈÖçÁΩÆ - Context Engineering - ‰∏ä‰∏ãÊñáÂ∑•Á®ã - Model Context Protocol (MCP) - Ê®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆ - Human-in-the-loop - ‰∫∫Êú∫Âçè‰Ωú - Multi-agent - Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü - Retrieval - Ê£ÄÁ¥¢Â¢ûÂº∫ - Long-term Memory - ÈïøÊúüËÆ∞ÂøÜ Agent Development - Êô∫ËÉΩ‰ΩìÂºÄÂèë - LangSmith Studio - ÂºÄÂèëË∞ÉËØïÂ∑•ÂÖ∑ - Test - ÊµãËØïÊåáÂçó - Agent Chat UI - ËÅäÂ§©ÁïåÈù¢ÂºÄÂèë Deploy with LangSmith - ÈÉ®ÁΩ≤ - Deployment - Áîü‰∫ßÁéØÂ¢ÉÈÉ®ÁΩ≤ - Observability - ÂèØËßÇÊµãÊÄßÁõëÊéß ü§ù Ë¥°ÁåÆÊåáÂçó Ê¨¢ËøéÂèÇ‰∏éÊñáÊ°£ÁøªËØëÂíåÊîπËøõ„ÄÇ Â¶Ç‰ΩïË¥°ÁåÆ 1. Fork Êú¨‰ªìÂ∫ì 2. ÂàõÂª∫ÊÇ®ÁöÑÁâπÊÄßÂàÜÊîØ ( [code] ) 3. Êèê‰∫§ÊÇ®ÁöÑÊõ¥Êîπ ( [code] ) 4. Êé®ÈÄÅÂà∞ÂàÜÊîØ ( [code] ) 5. ÊâìÂºÄ‰∏Ä‰∏™ Pull Request ÁøªËØëËßÑËåÉ - ‰øùÊåÅÊúØËØ≠‰∏ÄËá¥ÊÄß - ‰øùÁïô‰ª£Á†ÅÁ§∫‰æã‰∏≠ÁöÑËã±ÊñáÊ≥®Èáä - Á°Æ‰øùÈìæÊé•ÊúâÊïà - ÈÅµÂæ™ Markdown Ê†ºÂºèËßÑËåÉ üìù ËÆ∏ÂèØËØÅ Êú¨È°πÁõÆÈááÁî®‰∏é LangChain ÂÆòÊñπÊñáÊ°£Áõ∏ÂêåÁöÑËÆ∏ÂèØËØÅ„ÄÇ üîó Áõ∏ÂÖ≥ÈìæÊé• - LangChain ÂÆòÊñπÁΩëÁ´ô - LangChain GitHub - LangChain Python ÊñáÊ°£ - LangSmith Âπ≥Âè∞ ‚≠ê Star History [](https://star-history.com/#Hisn00w/LangChain-Chinese&Date) ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé Êú¨È°πÁõÆ‰∏∫ÈùûÂÆòÊñπÁøªËØëÔºå‰ªÖ‰æõÂ≠¶‰π†ÂèÇËÄÉ‰ΩøÁî®„ÄÇÁøªËØëÂÜÖÂÆπÂèØËÉΩÂ≠òÂú®‰∏çÂáÜÁ°ÆÊàñÊªûÂêéÔºåÈÅáÂà∞ÁñëÈóÆËØ∑‰ª•Ëã±ÊñáÂéüÊñá‰∏∫ÂáÜ„ÄÇ,https://github.com/Hisn00w/LangChain-Chinese/blob/f6ce670f211c1115f5199903a8291b4d5886d10d/Claude.md
1026785928,SyncRay,RAYCOON/SyncRay,https://github.com/RAYCOON/SyncRay,,,0,Unknown,,CLAUDE.md,"SyncRay A powerful PowerShell-based database synchronization tool that enables seamless data migration between SQL Server databases with full INSERT, UPDATE, and DELETE support. Features - Full CRUD Support: Synchronize tables with INSERT, UPDATE, and DELETE operations - Intelligent Matching: Flexible field matching beyond primary keys - Dry-Run Mode: Preview changes before execution (default behavior) - Transaction Safety: All operations wrapped in transactions with automatic rollback - Comprehensive Validation: Pre-flight checks for configuration, tables, and permissions - Export Filtering: WHERE clause support for selective data export - Identity Handling: Configurable IDENTITY_INSERT support - Detailed Reporting: Table-formatted change summaries and execution statistics Requirements - PowerShell 5.0 or higher - SQL Server 2012 or higher - Appropriate database permissions (SELECT, INSERT, UPDATE, DELETE) Quick Start New: Central SyncRay Command The easiest way to use SyncRay is through the central [code] script: [code] Setup Instructions 1. Clone the repository [code] 2. Configure your databases in [code] : [code] 3. Use SyncRay: Option A: Using Central Script (Recommended) [code] Option B: Using Individual Scripts [code] Documentation - Installation Guide - Configuration Reference - Usage Examples - Troubleshooting Configuration Table Synchronization Settings [code] Key Parameters - matchOn: Fields for record matching (auto-detects primary key if empty) - ignoreColumns: Columns to exclude from comparison - allowInserts/Updates/Deletes: Control allowed operations - exportWhere: Filter source data with SQL WHERE clause - replaceMode: Delete all records before inserting (full table replacement) - preserveIdentity: Maintain identity column values during sync - targetTable: Specify different target table name (defaults to sourceTable) Replace Mode (New Feature) When [code] is set for a table: 1. All existing records are deleted from the target table 2. All records from export are inserted 3. No UPDATE or individual DELETE operations are performed 4. Useful for reference tables or complete data refreshes 5. Executes in transaction for safety Example configuration: [code] Command Reference syncray.ps1 (Central Tool) The main entry point for all SyncRay operations. Automatically determines the operation based on parameters. Parameters: - [code] : Source database (triggers export mode) - [code] : Target database (triggers import mode) - [code] : Both (triggers sync mode) - [code] : Analyze data quality without exporting - [code] : Validate configuration without processing - [code] : Apply changes (for import/sync modes) - [code] : Skip tables with duplicate records - [code] : Create CSV reports for problems - [code] : Custom path for CSV reports - [code] : CSV delimiter - [code] : Show SQL statements for debugging - [code] : Show help information Examples: [code] sync-export.ps1 Export data from source database to JSON files. Parameters: - [code] (req",https://github.com/RAYCOON/SyncRay/blob/efd01e40697793da97d308afba93e59a22ff3e1f/CLAUDE.md
1018291663,AIHeadline.news,xrf-9527/AIHeadline.news,https://github.com/xrf-9527/AIHeadline.news,AIHeadline.news ‚Äì AI Â§¥Êù°,,0,Unknown,,CLAUDE.md,AIHeadline.news ‚Äì AI Â§¥Êù° [](https://github.com/Joe-oss9527/AIHeadline.news/actions/workflows/deploy.yml) [](https://aiheadline.news) [](https://joe-oss9527.github.io/AIHeadline.news/) > ÊÇ®ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊÉÖÊä•Á´ô > Hugo √ó Hextra ¬∑ ÂÖ®ÁêÉ Cloudflare ËæπÁºòÂä†ÈÄü --- ‚ú® ÁâπÊÄß | Á±ªÂà´ | ÊèèËø∞ | |------|------| | ÂÜÖÂÆπËá™Âä®Âåñ | ÊØèÊó•ÂêåÊ≠•‰ªìÂ∫ì [ [code] ](https://github.com/Joe-oss9527/ai-briefing-archive)ÔºåÊô∫ËÉΩÂàÜÁ±ª„ÄÅÊåâÊúàÂΩíÊ°£ | | Hextra ‰∏ªÈ¢ò | ÊöóËâ≤/ÊµÖËâ≤„ÄÅFlexSearch„ÄÅÁ´ôÂÜÖÈìæÊé•Âç°Áâá„ÄÅRSS„ÄÅPWA | | ÂèåÁéØÂ¢ÉÂèëÂ∏É | Cloudflare Worker (Assets) Áîü‰∫ß ‚Ä¢ GitHub Pages Â§á‰ªΩ | | ÂÆûÊó∂ÁªüËÆ° | GA4 Data API (JWT Ëá™Á≠æÂêç) ÁºìÂ≠òÂà∞ËæπÁºòÔºöÁ¥ØËÆ°ËÆøÈóÆÈáè + Âú®Á∫ø‰∫∫Êï∞ | | Áã¨Á´ãÈÉ®ÁΩ≤Êû∂ÊûÑ | Cloudflare Worker Áã¨Á´ãÊûÑÂª∫ÔºåGitHub Pages Áã¨Á´ãÊûÑÂª∫ | | ÂèØÊâ©Â±ï | Worker ÂèØÈöèÊó∂Êé•ÂÖ• KV„ÄÅDurable Objects„ÄÅQueues„ÄÅD1„ÄÅAI Bindings | | Markdown ËæìÂá∫ | ÊîØÊåÅÁ∫Ø Markdown Ê†ºÂºèËæìÂá∫ÔºåÊñπ‰æøÈõÜÊàêÂíåÂàÜÂèë | --- Âú®Á∫øËÆøÈóÆ | ÁéØÂ¢É | ÂüüÂêç | |------|------| | Áîü‰∫ß | https://aiheadline.news | | Â§á‰ªΩ | https://joe-oss9527.github.io/AIHeadline.news/ | --- Êú¨Âú∞ÂºÄÂèë ‰∏ÄÈîÆÂêØÂä® [code] ÁéØÂ¢ÉÈÖçÁΩÆ Worker Êú¨Âú∞ÂºÄÂèëÈúÄË¶ÅÈÖçÁΩÆ GA4 ÊúçÂä°Ë¥¶Âè∑ÂØÜÈí•Ôºö 1. ÂàõÂª∫ [code] Êñá‰ª∂ÔºàÂ∑≤Âú® [code] ‰∏≠Ôºâ 2. Ê∑ªÂä† GA4 ÊúçÂä°Ë¥¶Âè∑ JSONÔºà‰øùÊåÅÂçïË°åÊ†ºÂºèÔºâÔºö [code] ÂºÄÂèëÂëΩ‰ª§ [code] --- Âø´ÈÄüÈÉ®ÁΩ≤ ÈúÄË¶ÅÈÖçÁΩÆÁöÑÊ†∏ÂøÉ SecretsÔºö - [code] & [code] - Cloudflare ÈÉ®ÁΩ≤ - [code] - ËÆøÈóÆ [code] ÔºàÂ¶ÇÈúÄÊùÉÈôêÊéßÂà∂Ôºâ - [code] - Google Analytics ÁªüËÆ°ÔºàWorker ÁéØÂ¢ÉÂèòÈáèÔºâ üìñ ËØ¶ÁªÜÈÖçÁΩÆÊ≠•È™§„ÄÅÊäÄÊúØÊñáÊ°£ÂíåÊïÖÈöúÊéíÊü•ËØ∑ÂèÇËÄÉÈ°πÁõÆÁöÑ ÈÉ®ÁΩ≤ÊñáÊ°£ --- È°πÁõÆÊû∂ÊûÑ ÊäÄÊúØÊ†à - Hugo v0.150.0+ - ÈùôÊÄÅÁ´ôÁÇπÁîüÊàêÂô® - Hextra - Áé∞‰ª£Âåñ Hugo ‰∏ªÈ¢ò - Cloudflare Workers - ËæπÁºòËÆ°ÁÆóÈÉ®ÁΩ≤ - GitHub Actions - CI/CD Ëá™Âä®Âåñ - Google Analytics 4 - ËÆøÈóÆÁªüËÆ° ÁõÆÂΩïÁªìÊûÑ [code] ÂÜÖÂÆπÊµÅÁ®ã 1. GitHub Actions ÊØèÊó•Ëß¶Âèë 2. ÂêåÊ≠• [code] ‰ªìÂ∫ìÊúÄÊñ∞ÂÜÖÂÆπ 3. ÁîüÊàê Hugo Á´ôÁÇπÂÜÖÂÆπ 4. ÂêåÊó∂ÈÉ®ÁΩ≤Âà∞ Cloudflare Workers Âíå GitHub Pages --- MIT License ¬∑ Crafted by @Joe-oss9527,https://github.com/xrf-9527/AIHeadline.news/blob/f18e32bd19ed8efa04f0c9be75849f086de06e56/CLAUDE.md
1044345108,tm-event-flow-app,edaniel30/tm-event-flow-app,https://github.com/edaniel30/tm-event-flow-app,,,0,Unknown,,CLAUDE.md,"TmEventFlowApp This project was generated using Angular CLI version 19.0.3. Development server To start a local development server, run: [code] Once the server is running, open your browser and navigate to [code] . The application will automatically reload whenever you modify any of the source files. Code scaffolding Angular CLI includes powerful code scaffolding tools. To generate a new component, run: [code] For a complete list of available schematics (such as [code] , [code] , or [code] ), run: [code] Building To build the project run: [code] This will compile your project and store the build artifacts in the [code] directory. By default, the production build optimizes your application for performance and speed. Running unit tests To execute unit tests with the Karma test runner, use the following command: [code] Running end-to-end tests For end-to-end (e2e) testing, run: [code] Angular CLI does not come with an end-to-end testing framework by default. You can choose one that suits your needs. Additional Resources For more information on using the Angular CLI, including detailed command references, visit the Angular CLI Overview and Command Reference page.",https://github.com/edaniel30/tm-event-flow-app/blob/dcf72eeef0c34fcb9a940d3bf35580035b153e47/claude.md
1118403156,aic-typescript-mcp-sdk,ryanbas21/aic-typescript-mcp-sdk,https://github.com/ryanbas21/aic-typescript-mcp-sdk,,,0,Unknown,,CLAUDE.md,,https://github.com/ryanbas21/aic-typescript-mcp-sdk/blob/4c8f6cdec0625b332675a68474ad6667917392f7/CLAUDE.md
1101311217,ClaudeAPP,carosellagiuliano-max/ClaudeAPP,https://github.com/carosellagiuliano-max/ClaudeAPP,,,0,Unknown,,CLAUDE.md,"SCHNITTWERK - Enterprise Salon Management System > Digital platform for SCHNITTWERK by Vanessa Carosella > > Rorschacherstrasse 152, 9000 St. Gallen, Switzerland üá®üá≠ [](https://www.typescriptlang.org/) [](https://nextjs.org/) [](https://supabase.com/) [](https://tailwindcss.com/) --- üéØ Project Overview A production-ready, full-stack salon management system designed for Swiss salons. Built from day one to support multiple salons, handle real CHF payments, comply with Swiss DSG/GDPR, and scale reliably for years. Core Features - üìÖ Smart Booking Engine - Real-time slot calculation, prevents double bookings - üõçÔ∏è E-Commerce Shop - Products, bundles, vouchers, inventory management - üí≥ Payment Processing - Stripe integration (CHF), POS support, invoicing - üë• Customer Portal - Self-service bookings, order history, loyalty program - üîß Admin Backend - Calendar, team management, analytics, notifications - üîê Security First - Row-level security, RBAC, GDPR/DSG compliance - üè¢ Multi-Tenant Ready - Salon-scoped data from day one --- üèóÔ∏è Tech Stack Frontend - Framework: Next.js 14+ (App Router) - Language: TypeScript - Styling: Tailwind CSS + shadcn/ui - State: React Server Components + Server Actions Backend & Data - Database: Supabase PostgreSQL - Auth: Supabase Auth (email/password, JWT sessions) - Storage: Supabase Storage (images, documents) - Background Jobs: Supabase Edge Functions + Cron Integrations - Payments: Stripe (CHF, cards, Twint) - Email: Resend (or similar) - Monitoring: Vercel Analytics, Sentry - Testing: Vitest, Playwright, fast-check --- üöÄ Quick Start Prerequisites - Node.js 18+ - npm/yarn/pnpm - Supabase CLI - Docker (for local Supabase) Installation [code] Open http://localhost:3000 in your browser. --- üìÇ Project Structure [code] See ARCHITECTURE_PLAN.md for detailed architecture. --- üß™ Testing [code] --- üìö Documentation - Architecture Plan - START HERE - Complete system design - Data Model - Database schema deep dive - Security & RLS - Security architecture - Dev Setup - Detailed development environment setup - Testing Strategy - Testing guidelines - Operations - Production runbook - Payments & Webhooks - Stripe integration guide --- üîê Security This system handles sensitive customer data and real payments. Security is paramount: - ‚úÖ Row-Level Security (RLS) on all tables - ‚úÖ Role-Based Access Control (RBAC) - Admin, Manager, Staff, Customer - ‚úÖ Input validation with Zod schemas at all boundaries - ‚úÖ Stripe webhook signature verification - ‚úÖ GDPR/Swiss DSG compliance - data deletion, consent management - ‚úÖ Audit logs for all critical actions See security-and-rls.md for details. --- üåç Environments | Environment | URL | Database | Stripe | Purpose | |-------------|-----|----------|--------|---------| | Development | localhost:3000 | Local Supabase | Test mode | Local dev | | Staging | staging.schnittwerk.ch | Supabase (staging) | Test mode | Pre-production testing | | Production | www.schnittwerk.ch | Supabase (prod) | Live mode | Customer-faci",https://github.com/carosellagiuliano-max/ClaudeAPP/blob/255291a7bdf1905aa759840afc3095923032f2ab/claude.md
985016148,car-sales-dashboard,kipmadden/car-sales-dashboard,https://github.com/kipmadden/car-sales-dashboard,React interactive ML forecasting using synthesized car data,,0,Unknown,,CLAUDE.md,"üöó Car Sales Dashboard [](https://www.python.org/downloads/) [](docs/testing/fix6_code_quality.md) [](docs/testing/fix6_test_report.md) [](LICENSE) An interactive machine learning dashboard for car sales forecasting with real-time exogenous variable manipulation. Built with Reflex (Python full-stack framework) and SARIMAX time series models. ‚ú® Features - üéõÔ∏è Interactive Controls: Real-time adjustment of gas prices, CPI, search volume - üìä ML Forecasting: SARIMAX time series models with exogenous variables - üó∫Ô∏è Geographic Analysis: Regional and state-level sales breakdowns - üöó Vehicle Insights: Category, make, model filtering and analysis - ‚ö° Performance Optimized: Caching, batch processing, and responsive design - üß™ Comprehensive Testing: 87.1/100 code quality score with full test coverage - üê≥ Production Ready: Docker containerization and CI/CD pipeline üöÄ Quick Start Option 1: Docker (Recommended) [code] Option 2: Local Development [code] Access the dashboard at [code] üìñ Documentation - üìã Full Documentation - Comprehensive guides and reports - üèóÔ∏è Implementation Details - Technical architecture - üß™ Testing Reports - Quality assurance and test results - üöÄ CI/CD Documentation - Deployment and automation üõ†Ô∏è Technology Stack - Frontend: Reflex (React-based UI with Python) - Backend: Python, FastAPI - ML Models: SARIMAX (statsmodels), scikit-learn - Data: Pandas, NumPy - Visualization: Plotly - Deployment: Docker, Redis - Testing: Pytest, comprehensive quality framework üèóÔ∏è Project Architecture [code] üîß Development Adding New Features 1. New ML Models: Extend [code] 2. New Visualizations: Add charts in [code] 3. New Data Sources: Modify [code] 4. UI Components: Create reusable components in [code] Code Quality - Quality Score: 87.1/100 (Grade B) - Test Coverage: Comprehensive test suite with 100% pass rate - Performance: Optimized caching and batch processing - Documentation: Full API and implementation documentation üìù License This project is licensed under the MIT License - see the LICENSE file for details. ü§ù Contributing 1. Fork the repository 2. Create a feature branch ( [code] ) 3. Run tests ( [code] ) 4. Commit changes ( [code] ) 5. Push to branch ( [code] ) 6. Open a Pull Request üìû Support - üìñ Documentation: docs/ - üêõ Issues: GitHub Issues - üí¨ Discussions: GitHub Discussions --- *Built with ‚ù§Ô∏è using Python and Reflex*",https://github.com/kipmadden/car-sales-dashboard/blob/ba263d77a9b6791a46a3ded92cd9b6bf07dbb822/CLAUDE.md
1113515115,dividend-logbook,hec8897/dividend-logbook,https://github.com/hec8897/dividend-logbook,ÌÜ†Ïù¥ ÌîÑÎ°úÏ†ùÌä∏,,0,Unknown,,CLAUDE.md,"Dividend Logbook üìä ETF Ï†ïÎ≥¥Î•º Í¥ÄÎ¶¨ÌïòÍ≥† Î∞∞Îãπ Î∞è Îß§ÎèÑ ÏàòÏùµÏùÑ Ï∂îÏ†ÅÌïòÎäî ÌÜ†Ïù¥ ÌîÑÎ°úÏ†ùÌä∏ÏûÖÎãàÎã§. üìã ÌîÑÎ°úÏ†ùÌä∏ ÏÜåÍ∞ú Dividend LogbookÏùÄ Í∞úÏù∏Ïù¥ Î≥¥Ïú†Ìïú ETF(ÏÉÅÏû•ÏßÄÏàòÌéÄÎìú)Ïùò Ï†ïÎ≥¥Î•º Í¥ÄÎ¶¨ÌïòÍ≥†, Î∞∞Îãπ ÏàòÏùµÍ≥º Îß§ÎèÑ ÏàòÏùµÏùÑ Ï≤¥Í≥ÑÏ†ÅÏúºÎ°ú Ï†ïÎ¶¨ÌïòÏó¨ Ìà¨Ïûê ÏÑ±Í≥ºÎ•º ÌïúÎààÏóê ÌååÏïÖÌï† Ïàò ÏûàÎèÑÎ°ù ÎèÑÏôÄÏ£ºÎäî Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏûÖÎãàÎã§. ‚ú® Ï£ºÏöî Í∏∞Îä• - ETF Ï†ïÎ≥¥ Í¥ÄÎ¶¨ - Î≥¥Ïú† ETF Î™©Î°ù Ï°∞Ìöå Î∞è Í¥ÄÎ¶¨ - ETF Í∏∞Î≥∏ Ï†ïÎ≥¥ (Ìã∞Ïª§, Ïù¥Î¶Ñ, Î≥¥Ïú† ÏàòÎüâ Îì±) Ï†ÄÏû• - Î∞∞Îãπ ÏàòÏùµ Ï∂îÏ†Å - Î∞∞Îãπ ÎÇ¥Ïó≠ Í∏∞Î°ù Î∞è Ï°∞Ìöå - Î∞∞Îãπ ÏàòÏùµÎ•† Í≥ÑÏÇ∞ - Î∞∞Îãπ ÏùºÏ†ï Í¥ÄÎ¶¨ - Îß§ÎèÑ ÏàòÏùµ Í¥ÄÎ¶¨ - Îß§ÎèÑ ÎÇ¥Ïó≠ Í∏∞Î°ù - Ïã§ÌòÑ ÏÜêÏùµ Í≥ÑÏÇ∞ - ÏàòÏùµÎ•† Î∂ÑÏÑù - Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÎåÄÏãúÎ≥¥Îìú - Ï†ÑÏ≤¥ ÏàòÏùµ ÌòÑÌô© ÌïúÎààÏóê Î≥¥Í∏∞ - Í∏∞Í∞ÑÎ≥Ñ ÏàòÏùµÎ•† ÌÜµÍ≥Ñ - Ï∞®Ìä∏ Î∞è Í∑∏ÎûòÌîÑÎ•º ÌÜµÌïú ÏãúÍ∞ÅÌôî üöÄ ÏãúÏûëÌïòÍ∏∞ ÌïÑÏöî Ï°∞Í±¥ - Node.js (Î≤ÑÏ†Ñ 18 Ïù¥ÏÉÅ Í∂åÏû•) - npm ÎòêÎäî yarn ÏÑ§Ïπò Î∞©Î≤ï [code] Ïã§Ìñâ Î∞©Î≤ï [code] üìÅ ÌîÑÎ°úÏ†ùÌä∏ Íµ¨Ï°∞ ÎèÑÎ©îÏù∏ ÎìúÎ¶¨Î∏ê ÏïÑÌÇ§ÌÖçÏ≤òÎ•º Í∏∞Î∞òÏúºÎ°ú ÏÑ§Í≥ÑÎêòÏóàÏäµÎãàÎã§. [code] ÎèÑÎ©îÏù∏ Íµ¨Ï°∞ ÏÑ§Î™Ö Í∞Å ÎèÑÎ©îÏù∏ÏùÄ ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú Í¥ÄÎ¶¨ÎêòÎ©∞, Îã§ÏùåÍ≥º Í∞ôÏùÄ Íµ¨Ï°∞Î•º Í∞ÄÏßëÎãàÎã§: - components/: Ìï¥Îãπ ÎèÑÎ©îÏù∏ÏóêÏÑúÎßå ÏÇ¨Ïö©ÎêòÎäî Ïª¥Ìè¨ÎÑåÌä∏ - store/: ZustandÎ•º ÏÇ¨Ïö©Ìïú ÎèÑÎ©îÏù∏ Ï†ÑÏö© ÏÉÅÌÉú Í¥ÄÎ¶¨ - types/: ÎèÑÎ©îÏù∏ Í¥ÄÎ†® TypeScript ÌÉÄÏûÖ Ï†ïÏùò - hooks/: ÎèÑÎ©îÏù∏ Ï†ÑÏö© Ïª§Ïä§ÌÖÄ ÌõÖ (ÌïÑÏöîÏãú) - index.ts: ÎèÑÎ©îÏù∏Ïùò public APIÎ•º Ï†ïÏùòÌïòÎäî export ÌååÏùº üõ† Í∏∞Ïà† Ïä§ÌÉù - ÌîÑÎ°†Ìä∏ÏóîÎìú: Next.js 16 (App Router) - Ïñ∏Ïñ¥: TypeScript - ÏÉÅÌÉú Í¥ÄÎ¶¨: Zustand, TanStack Query - Ïä§ÌÉÄÏùºÎßÅ: Emotion - HTTP ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏: axios - Î∞±ÏóîÎìú: Next.js API Routes (ÏÑúÎ≤ÑÎ¶¨Ïä§) - Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§: (Ï∂îÍ∞Ä ÏòàÏ†ï) üìö Í∏∞Ïà† Î¨∏ÏÑú Îçî ÏûêÏÑ∏Ìïú Í∏∞Ïà† Ï†ïÎ≥¥Îäî Îã§Ïùå Î¨∏ÏÑúÎ•º Ï∞∏Í≥†ÌïòÏÑ∏Ïöî: - ÏïÑÌÇ§ÌÖçÏ≤ò Í∞ÄÏù¥Îìú - Î∞±ÏóîÎìú Íµ¨Ï°∞, Îç∞Ïù¥ÌÑ∞ ÌéòÏπ≠, ÏóêÎü¨ Ï≤òÎ¶¨ - Ïä§ÌÉÄÏùºÎßÅ Í∞ÄÏù¥Îìú - Emotion ÏÑ§Ï†ï, ÌÖåÎßà ÏãúÏä§ÌÖú, Î™®Î≤î ÏÇ¨Î°Ä üìù ÏÇ¨Ïö© ÏòàÏãú ETF Ï∂îÍ∞Ä [code] Î∞∞Îãπ Í∏∞Î°ù [code] Îß§ÎèÑ Í∏∞Î°ù [code] ü§ù Í∏∞Ïó¨ÌïòÍ∏∞ Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî Í∞úÏù∏ ÌÜ†Ïù¥ ÌîÑÎ°úÏ†ùÌä∏ÏûÖÎãàÎã§. Ï†úÏïàÏù¥ÎÇò Î≤ÑÍ∑∏ Î¶¨Ìè¨Ìä∏Îäî Ïù¥ÏäàÎ°ú Îì±Î°ùÌï¥Ï£ºÏÑ∏Ïöî. üìÑ ÎùºÏù¥ÏÑ†Ïä§ Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî Í∞úÏù∏ ÌïôÏäµ Î™©Ï†ÅÏúºÎ°ú Ï†úÏûëÎêòÏóàÏäµÎãàÎã§. üìß Î¨∏Ïùò ÌîÑÎ°úÏ†ùÌä∏Ïóê ÎåÄÌïú Î¨∏ÏùòÏÇ¨Ìï≠Ïù¥ ÏûàÏúºÏãúÎ©¥ Ïù¥ÏäàÎ•º Îì±Î°ùÌï¥Ï£ºÏÑ∏Ïöî. --- Note: Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî Ìà¨Ïûê Ï°∞Ïñ∏ÏùÑ Ï†úÍ≥µÌïòÏßÄ ÏïäÏúºÎ©∞, Í∞úÏù∏Ï†ÅÏù∏ Ìà¨Ïûê Í∏∞Î°ù Í¥ÄÎ¶¨ Î™©Ï†ÅÏúºÎ°ú Ï†úÏûëÎêòÏóàÏäµÎãàÎã§.",https://github.com/hec8897/dividend-logbook/blob/7142668333db60e12a5757de73ded387dfe84f07/CLAUDE.md
1053189516,CPU1234,psytz123/CPU1234,https://github.com/psytz123/CPU1234,,,0,Unknown,,CLAUDE.md,"AI-Enhanced CPU Performance Optimization Suite ü§ñ A comprehensive suite of Python tools for monitoring CPU performance, optimizing software, and analyzing system metrics with specialized AI coding optimization features for Intel i7-1240P systems. üéØ Project Overview This AI-enhanced performance optimization suite provides intelligent monitoring, analysis, and optimization for coding workflows, with particular focus on AI-assisted development environments. The system automatically detects AI workloads and adjusts CPU performance accordingly for optimal productivity. Key Features - ü§ñ AI Workload Detection: Automatic detection of AI coding tools (VS Code, Cursor, Copilot, etc.) - ‚ö° Dynamic CPU Optimization: Real-time performance tuning based on workload analysis - üèóÔ∏è Hybrid CPU Management: Intel P-core/E-core optimization for i7-1240P architecture - ‚òÅÔ∏è Cloud GPU Integration: RunPod integration for heavy AI workload offloading - üìä Real-time Monitoring: Comprehensive system metrics with WebSocket dashboard - üîß Intel XTU Integration: Advanced power management and thermal control üõ†Ô∏è Architecture Core Modules (Root Directory) - [code] - Main application launcher and CLI interface - [code] - Centralized utilities and base classes - [code] - Configuration management and settings Specialized Components üìà Optimization ( [code] ) - [code] - Main AI workload optimization engine - [code] - Intel P-core/E-core management - [code] - Advanced CPU tuning and thermal management - [code] - Code performance analysis and optimization - [code] files - Enhanced implementations for specific components üìä Monitoring ( [code] ) - [code] - Real-time CPU monitoring with AI detection - [code] - DDR4-5200 bandwidth tracking - [code] - Intel QuickSync and GPU monitoring ‚òÅÔ∏è Cloud Integration ( [code] ) - [code] - Cloud GPU offloading for heavy AI tasks - [code] - Intelligent local vs cloud decision engine - [code] - Cloud usage cost monitoring and optimization - [code] - Docker container management üñ•Ô∏è Dashboard ( [code] ) - [code] - Tkinter GUI with real-time charts - [code] - WebSocket server (port 8765) - [code] - UI templates and components üîç Analysis ( [code] ) - [code] - Comprehensive system analysis - [code] - Machine learning for workload forecasting üèóÔ∏è Core Infrastructure ( [code] ) - [code] - Non-blocking operations and event handling - [code] - Service container and dependency management - [code] - Common interfaces and contracts üöÄ Getting Started Prerequisites - Python 3.8+ - Intel i7-1240P system (optimized for, but works on other systems) - Windows 11 or Linux - Optional: Intel XTU for advanced tuning - Optional: RunPod API key for cloud GPU features Installation [code] Quick Start [code] üìä AI Coding Optimization Features AI Workload Detection - Automatic recognition of AI coding tools (VS Code, Cursor, Claude, etc.) - Process categorization and workload classification - Real-time optimization recommendations - Intelligent CPU governor switching Performance Optimization",https://github.com/psytz123/CPU1234/blob/7ede62c36dec8174b7613a3352c31b8063bd0221/CLAUDE.md
1078211830,new_blog_veloder,rafaelcostaleite/new_blog_veloder,https://github.com/rafaelcostaleite/new_blog_veloder,,,0,Unknown,,CLAUDE.md,"ü§ñ Sistema Multi-Agentes para Cria√ß√£o de Posts de Blog Sistema automatizado de gera√ß√£o de conte√∫do para blogs usando m√∫ltiplas APIs de IA (Claude e Gemini) organizadas em fluxos de trabalho colaborativos. üìã Descri√ß√£o Este projeto utiliza o conceito de agentes especializados que trabalham em sequ√™ncia para criar posts de blog de alta qualidade, otimizados para SEO e prontos para publica√ß√£o no WordPress. Pipeline de Agentes 1. Researcher (Gemini) - Pesquisa informa√ß√µes atualizadas na web 2. Writer (Gemini) - Escreve o conte√∫do do post 3. Reviewer (Claude) - Revisa, formata em HTML e otimiza para SEO üèóÔ∏è Tecnologias - Python 3.11+ - Docker & Docker Compose - APIs de IA: - Anthropic Claude (Sonnet 4) - Google Gemini Pro - Bibliotecas: - CrewAI - python-dotenv - anthropic - google-generativeai üìÅ Estrutura do Projeto [code] üöÄ Como Usar 1. Configura√ß√£o Inicial [code] 2. Crie o Arquivo de Entrada Crie um arquivo [code] com o seguinte formato: [code] 3. Execute com Docker [code] 4. OU Execute Localmente [code] 5. Resultado Os arquivos gerados estar√£o em [code] : - [code] - Post formatado em HTML - [code] - Dados de SEO (t√≠tulo, meta descri√ß√£o, palavras-chave, slug) ‚öôÔ∏è Configura√ß√£o Arquivo de Entrada ( [code] ) [code] Fluxos Dispon√≠veis Veja os fluxos dispon√≠veis em [code] : - Post_Esportivo - Cria√ß√£o de posts sobre esportes üîß Adicionando Novos Componentes Novo Agente 1. Crie uma pasta em [code] 2. Adicione 4 arquivos: - [code] - Configura√ß√£o t√©cnica - [code] - Personalidade e expertise - [code] - Descri√ß√£o da tarefa - [code] - A√ß√µes permitidas e formato de output Novo Fluxo 1. Edite [code] 2. Adicione a configura√ß√£o do novo fluxo 3. Especifique agentes e ordem de execu√ß√£o Nova API de IA 1. Crie [code] 2. Implemente a interface [code] 3. Adicione credenciais no [code] 4. Configure em [code] üìä Sistema de Logs - Logs gerais: [code] - Logs de erro: [code] - Logs s√£o limpos automaticamente a cada execu√ß√£o (configur√°vel) ‚úÖ Valida√ß√µes O sistema valida: - Presen√ßa de API keys - Formato do arquivo de entrada - Exist√™ncia de apenas um arquivo em [code] - Fluxo especificado existe em [code] üéØ Exemplo de Sa√≠da Post.txt [code] SEO.txt [code] üêõ Troubleshooting Erro: ""API keys n√£o configuradas"" - Verifique se o arquivo [code] existe - Confirme que as chaves est√£o corretas Erro: ""Nenhum arquivo .txt encontrado"" - Crie o arquivo [code] - Siga o formato especificado Erro: ""M√∫ltiplos arquivos encontrados"" - Mantenha apenas um arquivo [code] em [code] üìù Licen√ßa Este projeto √© de c√≥digo aberto. ü§ù Contribuindo Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para: 1. Fazer fork do projeto 2. Criar uma branch para sua feature 3. Commit suas mudan√ßas 4. Push para a branch 5. Abrir um Pull Request üìß Contato Para d√∫vidas e sugest√µes, abra uma issue no reposit√≥rio. --- Desenvolvido com IA para criar conte√∫do de qualidade automaticamente üöÄ",https://github.com/rafaelcostaleite/new_blog_veloder/blob/5317a5e53c072ccb6f1c2a5b355cc91a3f82e06f/claude.md
31150635,dotfiles,ivan3bx/dotfiles,https://github.com/ivan3bx/dotfiles,you know..,,0,Unknown,,CLAUDE.md,dotfiles Personal configuration files for development environment setup. Scripts - [code] - Creates symlinks for dotfiles in the parent directory - [code] - Updates vim plugins (git submodules) to latest versions,https://github.com/ivan3bx/dotfiles/blob/6ee3d2e7bbc5fac452c383e861f30d4121df5b8f/CLAUDE.md
1119242847,shipctl,jonasneves/shipctl,https://github.com/jonasneves/shipctl,Chrome extension for GitHub Actions deployment control and service health monitoring,,0,Unknown,,CLAUDE.md,"ShipCTL Extension Chrome extension for GitHub Actions deployments with health monitoring and local backend control. Installation [code] Load in Chrome: 1. Navigate to [code] 2. Enable Developer mode 3. Load unpacked from [code] directory > IMPORTANT: macOS Security Restriction > > On macOS, Chrome cannot execute scripts from arbitrary directories due to security restrictions. If you get ""Native host has exited"" or ""Operation not permitted"" errors, the native host must be installed to [code] (which the install script does automatically). > > After installing, you must restart Chrome completely (Cmd+Q, then reopen). > > To debug native host issues, run Chrome from Terminal: > [code] Configuration Required in Settings panel: - GitHub Token: Personal access token with [code] and [code] scopes - GitHub Repository: Owner and repository name - Repository Path: Local path to project (optional, auto-detected) - Python Path: Python interpreter path (optional, auto-detected) Configuration saved to [code] . Changes to Python path require reinstalling native host. Development [code]",https://github.com/jonasneves/shipctl/blob/21e37039195d2ca0f42fd22a4b7dc691c2642348/CLAUDE.md
1115803713,life-games,SaxophoneTrom/life-games,https://github.com/SaxophoneTrom/life-games,base mini apps life-game,,0,Unknown,,CLAUDE.md,"Farcaster Infinite Life Conway's Game of Life „Çí„Éô„Éº„Çπ„Å´„Åó„ÅüÂÖ±Âêå„Ç¢„Éº„Éà„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÄÇFarcaster Mini App „Å®„Åó„Å¶Âãï‰Ωú„Åó„ÄÅBase „ÉÅ„Çß„Éº„É≥‰∏ä„ÅßNFT„Çí„Éü„É≥„Éà„Åó„Åæ„Åô„ÄÇ „Ç≥„É≥„Çª„Éó„Éà SegmentNFTÔºàÂÄã‰∫∫‰ΩúÂìÅÔºâ - Á©∫Áõ§Èù¢Ôºà‰∏ñ‰ª£0Ôºâ„Åã„Çâ„É¶„Éº„Ç∂„Éº„ÅåÁ¥∞ËÉû„ÇíÊ≥®ÂÖ•„Åó„ÄÅn‰∏ñ‰ª£ÈÄ≤„ÇÅ„Åü„ÄåÁã¨Á´ã‰ΩúÂìÅ„Äç - Âç≥Á¢∫ÂÆömintÔºàPending‚ÜíFinalize„Éë„Ç§„Éó„É©„Ç§„É≥‰∏çË¶ÅÔºâ - Mini App„Åå„ÇØ„É©„Ç§„Ç¢„É≥„ÉàÂÅ¥„ÅßGIFÁîüÊàê„ÉªÂç≥ÊôÇË°®Á§∫ EpochArchiveNFTÔºàÂÖ±Êúâ‰∏ñÁïåÁ∑öÔºâ - SegmentNFT mintÊôÇ„Å´Áô∫Áîü„Åô„ÇãContribution„É≠„Ç∞„ÇíÊôÇÁ≥ªÂàóÈ†Ü„Å´ÈÅ©Áî® - 256‰∏ñ‰ª£„Åî„Å®„Å´GIF„Ç¢„Éº„Ç´„Ç§„Éñ„Å®„Åó„Å¶mint - Ë≤¢ÁåÆËÄÖÔºàContributorsÔºâ„ÅØË©≤ÂΩìEpoch„ÇíÁÑ°ÊñômintÂèØËÉΩ ‰ªïÊßò | „Éë„É©„É°„Éº„Çø | ÂÄ§ | |-----------|-----| | „Éú„Éº„Éâ„Çµ„Ç§„Ç∫ | 64√ó64Ôºà4,096„Çª„É´Ôºâ | | „Ç´„É©„Éº„Éë„É¨„ÉÉ„Éà | 16Ëâ≤Ôºà„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ 0„Äú15Ôºâ | | „É©„Ç§„Éï„É´„Éº„É´ | HighLife (B36/S23) | | ‰∏ñ‰ª£Êï∞/Segment | 10„Äú30 | | ‰∏ñ‰ª£Êï∞/Epoch | 256 | ÊäÄË°ì„Çπ„Çø„ÉÉ„ÇØ | „Ç´„ÉÜ„Ç¥„É™ | ÊäÄË°ì | |---------|------| | „Éï„É≠„É≥„Éà„Ç®„É≥„Éâ | Next.js 15 (App Router) | | „Çπ„Çø„Ç§„É™„É≥„Ç∞ | Tailwind CSS 4 | | Áä∂ÊÖãÁÆ°ÁêÜ | React Query + Zustand | | Web3 | wagmi + viem | | „Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ | Next.js API Routes | | „Ç≥„É≥„Éà„É©„ÇØ„Éà | Foundry (Solidity 0.8.24) | | EpochÁîüÊàê | GitHub Actions | | „ÉÅ„Çß„Éº„É≥ | Base Sepolia (ÈñãÁô∫) / Base Mainnet (Êú¨Áï™) | „Éï„Ç©„É´„ÉÄÊßãÊàê [code] „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó ÂøÖË¶Å„Å™„ÉÑ„Éº„É´ - Node.js 20+ - pnpm 9+ - Foundry „Ç§„É≥„Çπ„Éà„Éº„É´ [code] Áí∞Â¢ÉÂ§âÊï∞ [code] ÈñãÁô∫„Ç≥„Éû„É≥„Éâ [code] „Éá„Éó„É≠„Ç§ VercelÔºà„Éï„É≠„É≥„Éà„Ç®„É≥„ÉâÔºâ | Ë®≠ÂÆöÈ†ÖÁõÆ | ÂÄ§ | |---------|-----| | Root Directory | [code] | | Build Command | [code] | | Output Directory | [code] | „Ç≥„É≥„Éà„É©„ÇØ„Éà [code] GitHub ActionsÔºàEpoch GeneratorÔºâ 256‰∏ñ‰ª£ÂàÜ„ÅÆContribution„ÅåÊ∫ú„Åæ„Çã„Å®„ÄÅËá™ÂãïÁöÑ„Å´EpochArchiveNFT„ÇíÁîüÊàê„Éªmint„ÄÇ ÂøÖË¶Å„Å™Ë®≠ÂÆöÔºàRepository SettingsÔºâ | Á®ÆÈ°û | ÂêçÂâç | Ë™¨Êòé | |------|------|------| | Secret | [code] | Epoch mintÁî®„Ç¶„Ç©„É¨„ÉÉ„Éà„ÅÆÁßòÂØÜÈçµ | | Variable | [code] | SegmentNFT„Ç≥„É≥„Éà„É©„ÇØ„Éà„Ç¢„Éâ„É¨„Çπ | | Variable | [code] | EpochArchiveNFT„Ç≥„É≥„Éà„É©„ÇØ„Éà„Ç¢„Éâ„É¨„Çπ | „ÉÅ„Çß„Éº„É≥ÊÉÖÂ†± | „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ | Chain ID | RPC URL | |-------------|----------|---------| | Base Sepolia | 84532 | https://sepolia.base.org | | Base Mainnet | 8453 | https://mainnet.base.org | „É©„Ç§„Çª„É≥„Çπ MIT",https://github.com/SaxophoneTrom/life-games/blob/5144f9e6ff6cc48723ca33f75bac2e7ea6d10759/CLAUDE.md
1151436968,demo-deployment,AlessandroTaufer/demo-deployment,https://github.com/AlessandroTaufer/demo-deployment,A GitOps repository that deploys ArgoCD and two demo applications (nginx + httpbin) on a local Kubernetes cluster using the app-of-apps pattern.,,0,Unknown,,CLAUDE.md,"GitOps Demo Deployment A GitOps repository that deploys ArgoCD and two demo applications (nginx + httpbin) on a local Kubernetes cluster using the app-of-apps pattern. Prerequisites - A running Kubernetes cluster (kind, k3d, or minikube) - [code] configured to talk to the cluster Repository Authentication If this is a private repository, ArgoCD needs a credential to pull manifests. Create a GitHub Personal Access Token (PAT): 1. Go to GitHub > Settings > Developer settings > Personal access tokens > Fine-grained tokens 2. Click Generate new token 3. Set a name and expiration 4. Under Repository access, select Only select repositories and pick this repo 5. Under Permissions > Repository permissions, set Contents to Read-only 6. Click Generate token and copy the value Then create and apply a credential template that covers all GitHub repos: [code] Quick Start [code] This will: 1. Install ArgoCD into the [code] namespace 2. Wait for ArgoCD to become ready 3. Deploy the root app-of-apps, which manages the demo applications Accessing ArgoCD Port-forward the ArgoCD server: [code] Open https://localhost:8080 and log in with: - User: [code] - Password: retrieve with: [code] Architecture [code] Verify [code]",https://github.com/AlessandroTaufer/demo-deployment/blob/9d3413de86edb65c827b30ee30c3ebbaa765d6e9/CLAUDE.md
1146675471,OpenClawBudgetManager,N9-Developer-Empowerment/OpenClawBudgetManager,https://github.com/N9-Developer-Empowerment/OpenClawBudgetManager,Manages LLM Token Cost Budget Between Local and External Models Depndant on Capability Needed,,0,Unknown,,CLAUDE.md,"OpenClaw Budget Manager An OpenClaw plugin that tracks daily API spend and actively switches to fallback providers when budgets are exhausted. Supports two modes: - Legacy mode: Single daily budget with automatic switch to local Ollama models - Chain mode: Multi-provider fallback chain with per-provider budgets How it works Cost tracking After each API call ( [code] hook), the plugin: 1. Reads model, token counts, and pre-calculated cost from all assistant messages in the turn (including intermediate tool-use calls) 2. Sums costs across the entire turn and records a transaction 3. Falls back to a built-in cost-per-token table if messages don't include cost data The budget resets automatically each day. Active model switching When budgets run out, the plugin patches [code] to change the default model, then restarts the gateway: 1. [code] hook fires ‚Äî after tracking spend, the plugin checks remaining budget 2. Budget exhausted ‚Äî in legacy mode, switches to Ollama; in chain mode, switches to next provider 3. Config write ‚Äî sets [code] to the new model 4. Gateway restart ‚Äî the plugin runs [code] to apply changes 5. Next day ‚Äî budget resets, plugin restores the primary provider --- Chain Mode (Multi-Provider Fallback) Chain mode enables a provider fallback chain with individual budgets per provider. When one provider's budget is exhausted, it automatically switches to the next provider in priority order. Provider Chain (Default Configuration) | Priority | Provider | Type | Default Budget | Notes | |----------|----------|------|----------------|-------| | 1 | Anthropic | postpaid | $3.00 | Primary, best quality | | 2 | Moonshot | prepaid | $2.00 | Prepaid, can't overspend | | 3 | DeepSeek | prepaid | $1.00 | Extremely cheap | | 4 | Google | postpaid | $1.00 | Gemini models | | 5 | OpenAI | postpaid | $1.00 | GPT models | | 6 | Ollama | free | $0 | Final fallback, local | Total daily budget: ~$8.00 (configurable per provider) Enabling Chain Mode Create a [code] file in the plugin directory: [code] Or copy from the example: [code] The plugin automatically loads environment variables from [code] on startup. Variables set in the shell environment take precedence over [code] values. Chain Configuration The provider chain is configured in [code] : [code] Per-Provider Budget Overrides Override budgets via environment variables: [code] Disable Providers Temporarily [code] Registering Providers in OpenClaw Add all providers to [code] : [code] --- Legacy Mode (Single Budget) The original behavior: tracks spend against a single daily budget and switches to local Ollama when exhausted. Budget thresholds - > 20% remaining ‚Äî no intervention - coding > general. --- Cost Optimization (Chain Mode) Chain mode automatically applies cost optimizations from the OpenClaw Token Optimization Guide. The optimizations are provider-aware: - When on Anthropic: Applies Sonnet default + Haiku/Sonnet/Opus routing rules - When on other providers: Uses that provider's default model + ",https://github.com/N9-Developer-Empowerment/OpenClawBudgetManager/blob/282972ce040dd31848e0ddf61508d63bce94cd58/CLAUDE.md
1096300660,bedrock-addon-parser,EaseCation/bedrock-addon-parser,https://github.com/EaseCation/bedrock-addon-parser,bedrock addon parser for java,,0,Unknown,,CLAUDE.md,Bedrock Addon Parser [](https://github.com/EaseCation/bedrock-addon-parser/actions) [](https://opensource.org/licenses/MIT) Minecraft Bedrock Edition Addon Ëß£ÊûêÂô®ÔºåÁî®‰∫éËØªÂèñÂíåËß£Êûê Behavior Pack ‰∏≠ÁöÑ Block„ÄÅItem„ÄÅEntity ÂÆö‰πâÊñá‰ª∂„ÄÇ È°πÁõÆËÉåÊôØ Minecraft Bedrock Edition ÁöÑ Addon Ê†ºÂºèÂú®‰∏çÂêåÁâàÊú¨Èó¥Â≠òÂú®ÊòæËëóÂ∑ÆÂºÇÔºåÊúçÂä°Âô®Êèí‰ª∂ÔºàÂ¶Ç Nukkit„ÄÅPowerNukkitXÔºâÈúÄË¶ÅÂÖºÂÆπÂ§ö‰∏™ÁâàÊú¨ÁöÑ Addon Êñá‰ª∂„ÄÇ Êú¨È°πÁõÆÈÄöËøá‰ª•‰∏ãÊñπÂºèËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºö - Ëá™Âä®Â∞ÜÊóßÁâàÊú¨ Addon ÂçáÁ∫ßÂà∞ÊúÄÊñ∞Ê†ºÂºèÔºà1.19.0 ‚Üí 1.21.60Ôºâ - Êèê‰æõÁªü‰∏ÄÁöÑ Java DTO Êé•Âè£ÔºåÂ±èËîΩÁâàÊú¨Â∑ÆÂºÇ - ÊîØÊåÅ Block„ÄÅItem„ÄÅEntity ‰∏âÁßçËµÑÊ∫êÁ±ªÂûãÁöÑËß£Êûê ÈÄÇÁî®Âú∫ÊôØ - ÊúçÂä°Âô®Êèí‰ª∂ÂºÄÂèëÔºöNukkit/PowerNukkitX Á≠âÊúçÂä°Âô®ÈúÄË¶ÅËØªÂèñ Addon ÈÖçÁΩÆ - Addon Â∑•ÂÖ∑ÂºÄÂèëÔºöÈúÄË¶ÅËß£ÊûêÂíå‰øÆÊîπ Addon Êñá‰ª∂ÁöÑÂ∑•ÂÖ∑ - ÁâàÊú¨ËøÅÁßªÂ∑•ÂÖ∑ÔºöËá™Âä®Â∞ÜÊóßÁâàÊú¨ Addon ÂçáÁ∫ßÂà∞Êñ∞ÁâàÊú¨ Ê†∏ÂøÉÂäüËÉΩ - ÁâàÊú¨Ëá™Âä®ÂçáÁ∫ß - ÊîØÊåÅ 1.19.0„ÄÅ1.19.40„ÄÅ1.19.50„ÄÅ1.20.10„ÄÅ1.20.41„ÄÅ1.20.81„ÄÅ1.21.50„ÄÅ1.21.60 ÂÖ± 8 ‰∏™ÁâàÊú¨ - Ê†áÂáÜÂåñËæìÂá∫ - Â∞Ü‰∏çÂêåÁâàÊú¨ÁöÑ JSON Ê†ºÂºèÁªü‰∏ÄËΩ¨Êç¢‰∏∫‰∏ÄËá¥ÁöÑ Java DTOÔºàStandardBlock„ÄÅStandardItem„ÄÅStandardEntityÔºâ - Âü∫‰∫é GraalVM - ‰ΩøÁî® GraalVM JS ÂºïÊìéÊâßË°å TypeScript Ëß£ÊûêÈÄªËæë - Á±ªÂûãÂÆâÂÖ® - TypeScript Â±ÇÊèê‰æõÂÆåÊï¥ÁöÑÁ±ªÂûãÂÆö‰πâ ÂÆâË£Ö Gradle (Kotlin DSL) [code] Maven [code] Âø´ÈÄüÂºÄÂßã Âü∫Á°ÄÁî®Ê≥ï [code] ÊâπÈáèËß£Êûê ÊâπÈáèËß£ÊûêÂ§ö‰∏™ Addon Êó∂ÔºåÂª∫ËÆÆÂ§çÁî® JSRuntime ÂÆû‰æãÔºö [code] ÂçïÊñá‰ª∂Ëß£Êûê [code] ËÆøÈóÆËß£ÊûêÁªìÊûú [code] ÁâàÊú¨ÂÖºÂÆπÊÄß | Minecraft ÁâàÊú¨ | Schema Commit | Blocks | Items | Entities | |----------------|---------------|--------|-------|----------| | 1.19.0 | c8128d1e | ‚úì | ‚úì | ‚úì | | 1.19.40 | 28f69c0f | ‚úì | ‚úì | ‚úì | | 1.19.50 | 2fe9f2ed | ‚úì | ‚úì | ‚úì | | 1.20.10 | c3ab0975 | ‚úì | ‚úì | - | | 1.20.41 | d3a8c7a4 | ‚úì | ‚úì | - | | 1.20.81 | 0ed84930 | ‚úì | ‚úì | - | | 1.21.50 | ec99529c | ‚úì | ‚úì | ‚úì | | 1.21.60 | 2d7ba565 | ‚úì | ‚úì | ‚úì | È°πÁõÆÊûÑÂª∫ È°πÁõÆÁªìÊûÑ [code] ÊûÑÂª∫ ‰ΩøÁî® Gradle [code] ÊûÑÂª∫ÊµÅÁ®ãÔºöÂàùÂßãÂåñ submodules ‚Üí ÂÆâË£Ö‰æùËµñ ‚Üí ÁîüÊàêÁ±ªÂûã ‚Üí ÁºñËØë TS ‚Üí ÊâìÂåÖ bundle.js ‚Üí ÁºñËØë Java ‚Üí ÊµãËØï ‚Üí ÁîüÊàê JAR ÂàÜÊ≠•ÊûÑÂª∫ [code] Â¢ûÈáèÊûÑÂª∫ types ÁõÆÂΩïÂ∑≤Â≠òÂú®Êó∂‰ºöËá™Âä®Ë∑≥ËøáÁ±ªÂûãÁîüÊàêÔºö [code] ÊµãËØï [code] Ê∏ÖÁêÜ [code] ÊµãËØï È°πÁõÆÂåÖÂê´ÂçïÂÖÉÊµãËØïÂíåÈõÜÊàêÊµãËØï‰∏§‰∏™Â±ÇÊ¨°Ôºå‰ΩøÁî® Mojang ÂÆòÊñπ bedrock-samples ‰Ωú‰∏∫ÈõÜÊàêÊµãËØïÊï∞ÊçÆ„ÄÇ ËøêË°åÊµãËØï [code] ÈõÜÊàêÊµãËØïËØ¥Êòé ÈõÜÊàêÊµãËØï‰ΩøÁî® Mojang ÂÆòÊñπ bedrock-samples ‰Ωú‰∏∫ÊµãËØïÊï∞ÊçÆÔºö - Items: 70‰∏™ÂÆòÊñπÁâ©ÂìÅÔºàapple„ÄÅgolden_apple„ÄÅwheat_seedsÁ≠âÔºâ - Entities: 122‰∏™ÂÆòÊñπÂÆû‰ΩìÔºàchicken„ÄÅzombie„ÄÅcreeperÁ≠âÔºâ Ëøô‰∫õÊµãËØïÊó®Âú®ÂèëÁé∞Ëß£ÊûêÂô®ÂØπÁúüÂÆûÂÆòÊñπJSONÊñá‰ª∂ÁöÑÂÖºÂÆπÊÄßÈóÆÈ¢òÔºåËÄå‰∏çÊòØÂº∫Âà∂100%ÈÄöËøáÁéá„ÄÇÂ∏∏ËßÅÁöÑÂ§±Ë¥•ÂéüÂõ†Ôºö - ÂÆòÊñπÊñá‰ª∂‰ΩøÁî®‰∫Ü‰∏çÊîØÊåÅÁöÑÁâàÊú¨ÔºàÂ¶Ç1.20.50Ôºâ - ÂÆòÊñπÊñá‰ª∂‰ΩøÁî® JSON5 Ê†ºÂºèÔºàtrailing commasÔºâ - ÂÆûÈ™åÊÄßÂäüËÉΩÊàñÁªÑ‰ª∂ Êõ¥Êñ∞ÊµãËØïÊï∞ÊçÆ [code] Â∏∏ËßÅÈóÆÈ¢ò types/ ÁõÆÂΩï‰∏çÂ≠òÂú® [code] bundle.js Êâæ‰∏çÂà∞ [code] schemas submodule ‰∏∫Á©∫ [code] TypeScript Êâæ‰∏çÂà∞ @easecation/schema-types [code] ËÆ∏ÂèØËØÅ MIT License Ë¥°ÁåÆ Ê¨¢ËøéÊèê‰∫§ Issue Âíå Pull Request„ÄÇ Ëá¥Ë∞¢ - Blockception/Minecraft-bedrock-json-schemas - ÂÆòÊñπ JSON Schema ‰ªìÂ∫ì - GraalVM - JavaScript ËøêË°åÊó∂ÂºïÊìé - json-schema-to-typescript - TypeScript Á±ªÂûãÁîüÊàêÂ∑•ÂÖ∑,https://github.com/EaseCation/bedrock-addon-parser/blob/4448de44ad8887199458c35e3ff36390c44cfb0a/CLAUDE.md
926815510,minions,HazyResearch/minions,https://github.com/HazyResearch/minions,Big & Small LLMs working together,,0,Unknown,,mcp.json,"Where On-Device and Cloud LLMs Meet [](https://discord.gg/jfJyxXwFVa) _What is this?_ Minions is a communication protocol that enables small on-device models to collaborate with frontier models in the cloud. By only reading long contexts locally, we can reduce cloud costs with minimal or no quality degradation. This repository provides a demonstration of the protocol. Get started below or see our paper and blogpost below for more information. Paper: Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models Minions Blogpost: https://hazyresearch.stanford.edu/blog/2025-02-24-minions Secure Minions Chat Blogpost: https://hazyresearch.stanford.edu/blog/2025-05-12-security Table of Contents > Looking for Secure Minions Chat? If you're interested in our end-to-end encrypted and chat system, please see the Secure Minions Chat README for detailed setup and usage instructions. - Setup - Step 1: Clone and Install - Step 2: Install a Local Model Server - Step 3: Set Cloud LLM API Keys - Minions Demo Application - Minions WebGPU App - Example Code - Minion (Singular) - Minions (Plural) - Python Notebook - Docker Support - Command Line Interface - Secure Minions Local-Remote Protocol - Secure Minions Chat - Apps - Inference Estimator - Command Line Usage - Python API Usage - Miscellaneous Setup - Using Azure OpenAI - Maintainers Setup _We have tested the following setup on Mac and Ubuntu with Python 3.10-3.11_ (Note: Python 3.13 is not supported) Optional: Create a virtual environment with your favorite package manager (e.g. conda, venv, uv) [code] Step 1: Clone the repository and install the Python package. [code] _note_: for optional MLX-LM install the package with the following command: [code] _note_: for secure minions chat, install the package with the following command: [code] _note_: for optional Cartesia-MLX install, pip install the basic package and then follow the instructions below. Step 2: Install a server for running the local model. We support three servers for running local models: [code] , [code] , and [code] . You need to install at least one of these. - You should use [code] if you do not have access to NVIDIA/AMD GPUs. Install [code] following the instructions here. To enable Flash Attention, run [code] and, if on a mac, restart the ollama app. - You should use [code] if you have access to local AMD CPUs/GPUs/NPUs. Install [code] following the instructions here. - See the following for supported APU configurations: https://ryzenai.docs.amd.com/en/latest/llm/overview.html#supported-configurations - After installing [code] make sure to launch the lemonade server. This can be done via the one-click Windows GUI installer which installs the Lemonade Server as a standalone tool. - Note: Lemonade does not support the Minion-CUA protocol at this time. - You should use [code] if you have access to NVIDIA GPUs and you are running the Minions protocol, which benefits from the high-throughput of [code] . Install [code] with the ",https://github.com/HazyResearch/minions/blob/98f09f8e188d1dce9e2089299eb69bee8d17f306/mcp.json
956154070,FileScopeMCP,admica/FileScopeMCP,https://github.com/admica/FileScopeMCP,"Analyzes your codebase identifying important files based on dependency relationships. Generates diagrams and importance scores per file, helping AI assistants understand the codebase. Automatically pa",,0,Unknown,,mcp.json,"FileScopeMCP (Model Context Protocol) Server ‚ú® Instantly understand and visualize your codebase structure & dependencies! ‚ú® [](https://github.com/admica/FileScopeMCP/actions) [](https://nodejs.org/) [](https://www.gnu.org/licenses/gpl-3.0) A TypeScript-based tool for ranking files in your codebase by importance, tracking dependencies, and providing summaries to help understand code structure. Overview This MCP server analyzes your codebase to identify the most important files based on dependency relationships. It generates importance scores (0-10) for each file, tracks bidirectional dependencies, and allows you to add custom summaries for files. All this information is made available to AI tools through Cursor's Model Context Protocol. Features üöÄ Supercharge your Code Understanding! FileScopeMCP provides insights directly to your AI assistant: - üéØ File Importance Analysis - Rank files on a 0-10 scale based on their role in the codebase. - Calculate importance using incoming/outgoing dependencies. - Instantly pinpoint the most critical files in your project. - Smart calculation considers file type, location, and name significance. - üîó Dependency Tracking - Map bidirectional dependency relationships between files. - Identify which files import a given file (dependents). - See which files are imported by a given file (dependencies). - Distinguish between local and package dependencies. - Multi-language support: Python, JavaScript, TypeScript, C/C++, Rust, Lua, Zig, C#, Java. - üìä Visualization - Generate Mermaid diagrams to visualize file relationships. - Color-coded visualization based on importance scores. - Support for dependency graphs, directory trees, or hybrid views. - HTML output with embedded rendering including theme toggle and responsive design. - Customize diagram depth, filter by importance, and adjust layout options. - üìù File Summaries - Add human or AI-generated summaries to any file. - Retrieve stored summaries to quickly grasp file purpose. - Summaries persist across server restarts. - üìö Multiple Project Support - Create and manage multiple file trees for different project areas. - Configure separate trees with distinct base directories. - Switch between different file trees effortlessly. - Cached trees for faster subsequent operations. - üíæ Persistent Storage - All data automatically saved to disk in JSON format. - Load existing file trees without rescanning the filesystem. - Track when file trees were last updated. Installation 1. Clone this repository 2. Build the project: The build script will install all node dependencies and generate mcp.json for you. Windows: [code] Copy the generated mcp.json configuration to your project's [code] directory: [code] Linux: (Cursor in Windows, but your project is in Linux WSL, then put the MCP in Linux and build) [code] [code] 4. Update the arg path --base-dir to your project's base path. How It Works Dependency Detection The tool scans source code for import statements and other language-specif",https://github.com/admica/FileScopeMCP/blob/a75a4c7e21d74c5da4a06e1c1fcbf0ba66a234c1/mcp.json.win.txt
25120448,dotfiles,posquit0/dotfiles,https://github.com/posquit0/dotfiles,:zap: Awesome configurations for the development environments,,0,Unknown,,mcp.json,"dotfiles Getting Started [code] Contributing This project follows the Contributor Covenant Code of Conduct. Bug Reports & Feature Requests Please use the issue tracker to report any bugs or ask feature requests. Self Promotion Like this project? Please give it a ‚òÖ on GitHub! It helps this project a lot. And if you're feeling especially charitable, follow posquit0 on GitHub. See Also - brewfile - Brewfile to install softwares in macOS for engineers. - gitconfig - Git configurations. - tmux-conf - TMUX Configuration for nerds with tpm. - vimrc - Vim Configuration for nerds with vim-plug. - zsh - Zsh Configuration for nerds with zplug. References - macOS defaults - Uncomplete list of macOS [code] commands with demos. License Provided under the terms of the MIT License. Copyright ¬© 2014-2023, Byungjin Park.",https://github.com/posquit0/dotfiles/blob/214043e677ba86f5bfbb971b243973bc3e6ba42e/private_dot_cursor/mcp.json.tmpl
1038765162,langchain-code,zamalali/langchain-code,https://github.com/zamalali/langchain-code,Gemini-cli or claude code? Why not both? LangCode combines all CLI capabilities and models in one place ‚òÇÔ∏è!,,0,Unknown,,mcp.json,"LangCode The only CLI you'll ever need! Gemini CLI or Claude Code? Why not both‚Äîand a bit more. LangCode brings Gemini, Anthropic, OpenAI, and Ollama together with ReAct & Deep modes, fully inline, anywhere you need it. [](https://pypi.org/project/langchain-code/) [](https://pepy.tech/project/langchain-code) [](https://github.com/zamalali/langchain-code/blob/main/LICENSE) [](https://github.com/zamalali/langchain-code/actions/workflows/docker-build.yml) [](https://hub.docker.com/r/at384/langchain-code) [](https://hub.docker.com/r/at384/langchain-code) [](https://hub.docker.com/r/at384/langchain-code/tags) [](https://github.com/psf/black) [](https://pycqa.github.io/isort/) Key Features * Interactive Launcher: Start with [code] and configure everything through a user-friendly interface. * AI-Powered Code Understanding: Deeply analyzes your code to answer questions and generate insights. * Automated Coding Tasks: Implements features, fixes bugs, and refactors code with minimal effort. * Safe and Reviewable Changes: Generates clear diffs for every modification, ensuring you stay in control. * Multi-LLM Support: Seamlessly integrates with Google Gemini and Anthropic Claude, intelligently routing to the best model for the task. * Customizable Instructions: Tailor the agent's behavior with project-specific rules and guidelines using [code] . * Extensible with MCP: Integrate custom tools via Model Context Protocol (MCP). Get Started 1. Installation: [code] 2. Launch the Interactive Launcher: Just type [code] in your terminal and hit Enter. This opens a user-friendly interactive menu where you can easily configure your session and access various functionalities without needing to remember specific command-line arguments. See the image shown above. Interactive Mode The interactive mode serves as the central hub for all your coding tasks. It allows you to: * Choose a Command: Select what you want to do: [code] , [code] , [code] , or [code] . * Configure the Engine: Pick between [code] (fast and efficient) and [code] (for complex tasks). * Enable Smart Routing: Let LangCode automatically select the best LLM for each task. * Set the Priority: Optimize for [code] , [code] , or [code] when using smart routing. * Manage Autopilot: Enable fully autonomous mode for the Deep Agent (use with caution!). * Toggle Apply Mode: Allow LangCode to automatically write changes to your file system. * Select an LLM: Explicitly choose between Anthropic and Google Gemini, or let LangCode decide. * Specify the Project Directory: Tell LangCode where your codebase is located. * Edit Environment Variables: Quickly add or modify API keys and other settings in your [code] file. * Customize Instructions: Open the [code] file to add project-specific guidelines. * Configure MCP Servers: Set up Model Context Protocol (MCP) servers for advanced tool integration. * Edit Language Code: Modify the core language code directly from the main window. * Specify MCP Servers: Configure Model Context ",https://github.com/zamalali/langchain-code/blob/d75d039ce2b4d1d2bff01d7f8858068209564ecc/src/langchain_code/config/mcp.json~
1048048366,agentic-drop-zones,disler/agentic-drop-zones,https://github.com/disler/agentic-drop-zones,,,0,Unknown,,mcp.json,"Agentic Drop Zone > See what you can do with the Agentic Drop Zone in this video. Automated file processing system that monitors directories and triggers agents (Claude Code, Gemini CLI, Codex CLI) when files are dropped. Features - üìù Simple single file script: [code] - ‚öôÔ∏è Configurable drop zones in [code] - ü§ñ Agent agnostic implementation: Claude Code, Gemini CLI, Codex CLI (unimplemented) - üß© Run multiple agents in parallel - üöÄ Run arbitrary agentic workflows: Do 'anything' your agent can do System Architecture [code] How It Works 1. Watch - Monitors configured directories for file events (create/modify/delete/move) 2. Match - Checks if dropped files match configured patterns (*.txt, *.json, etc.) 3. Process - Executes Claude Code with custom prompts to process the files 4. Output - Rich console display with streaming responses in styled panels Quick Start [code] MCP Support - Claude Code supports MCP servers, run [code] and edit the file with your API keys - Gemini CLI supports MCP servers, run [code] and edit the file with your API keys - Codex CLI does not support MCP servers without modifying root level [code] (untested) ‚ö†Ô∏è Dangerous Agent Execution IMPORTANT: Agents are given complete control over your system with dangerous execution capabilities. Agent permissions are as follows: - Claude Code runs with [code] mode, which allows all tools without prompting - Gemini CLI runs with [code] flag with the [code] flag, which auto-approves all actions but prevents moving outside of the sandbox directory - Codex CLI (not implemented) By using this system, you acknowledge the risks and take full responsibility for any actions performed by the agents. Configuration (drops.yaml) [code] Agents The system supports multiple AI agents with different capabilities: Claude Code (Most Capable) - - Status: ‚úÖ Fully implemented - SDK: Native Python, Typescript, and CLI SDK with streaming support - Output: Clean, formatted panels with real-time streaming - Models: [code] , [code] , [code] - MCP Support: Full MCP tool integration - Best For: Complex tasks requiring tool use, SOTA performance - Documentation Gemini CLI - Status: üü° Implemented with subprocess streaming - SDK: No SDK - uses CLI via subprocess - Output: Line-by-line streaming in panels (due to CLI limitations) - Models: [code] (default), [code] - Flags: [code] (auto-approve), [code] (sandboxing) - Best For: Quick tasks, alternative models outside of Anthropic models - Documentation Codex CLI - Status: ‚ùå Not yet implemented - SDK: Would use CLI via subprocess - Output: TBD - Models: [code] - Best For: Future implementation (Up for a challenge?) - Documentation Configuration Example See [code] for agent setup: [code] Claude Code SDK Integration Uses [code] with streaming responses: [code] Agentic Workflows The system comes with several pre-configured workflows. Each requires specific setup and environment variables: üé® Image Generation Drop Zone Directory: [code] File Types: [code] , [code] Purpose: Gen",https://github.com/disler/agentic-drop-zones/blob/16a347bf60afcb60a1c55893deb5859aaeb18dda/.mcp.json.sample
1072808382,mcp-filter,pro-vi/mcp-filter,https://github.com/pro-vi/mcp-filter,A proxy MCP (Model Context Protocol) server that filters the upstream tool surface to just the tools you need.,,0,Unknown,,mcp.json,"MCP Filter A proxy MCP (Model Context Protocol) server that filters the upstream tool surface to just the tools you need. Expose one or two critical tools (for example, execute_sql on Supabase) while filtering out the token-costly ones, without having to modify the upstream implementation. Before & After Before: Unfiltered MCP servers consumed ~50k tokens on a fresh Claude Code session [code] After: With mcp-filter, reduced to ~13.7k tokens (72% reduction) while keeping all necessary tools. [code] Filter only the tools you need, save context for longer sessions. To see your token usage: Open Claude Code and run [code] to view the breakdown. What & Why - Static allowlist keeps the exposed tool list tiny, cutting context usage for clients that serialize tool schemas. - Drop-in proxy: stands in front of any MCP server that speaks stdio or HTTP/SSE, forwarding calls transparently. - Safety guardrails: optional regex-based deny list, optional prefix, and optional health tool for observability. Installation Python 3.10+ is supported; 3.11 is recommended. Using pip [code] Using uv (faster, modern alternative) [code] From source (development): [code] Quick Start [code] Shorthand flags: [code] (transport), [code] (allow-tool), [code] (deny-pattern), [code] (prefix) Note: Both [code] and [code] support flexible input - use repeatable flags or comma-separated strings, whichever is cleaner for your use case. How to Wrap Your MCP Concept Transform any existing MCP server config by wrapping it with mcp-filter. The filter proxies your original command and only exposes the tools you specify with [code] . Before (original Supabase config): [code] This exposes all 29 tools (~20.8k tokens): Show all tools [code] After (wrapped with mcp-filter): [code] This only exposes 3 tools we allowed (~1.9k tokens = 91% reduction!): [code] Examples for Claude Code / Claude Desktop [code] includes common setups. Add to your [code] : Supabase (stdio) ‚Äì wrap the official MCP binary: [code] Or use [code] for faster, ephemeral execution: [code] Linear (stdio wrapping mcp-remote) ‚Äì preserves OAuth browser flow: [code] Adjust auth-tokens/headers to match your environment; the filter never logs or exposes them. Configuration Reference Environment variables (prefixed with [code] ) override CLI flags. See [code] for a template. - [code] / [code] : [code] (default) or [code] - [code] / [code] : upstream binary + args - [code] / [code] : SSE/HTTP endpoint and extra headers ( [code] ) - [code] / [code] : exact tool names (repeatable, or comma-separated) - [code] : regex patterns for tool names (repeatable, or comma-separated) - [code] / [code] : regex patterns to block (repeatable, or comma-separated) - [code] / [code] / [code] : prefix exposed tool names (e.g., [code] ) - [code] / [code] : enable built-in health tool (disabled by default) - [code] : enable token estimate logging (disabled by default) FAQ Can I expose more than one tool? Yes‚Äîpass multiple [code] flags or use regex patterns.",https://github.com/pro-vi/mcp-filter/blob/a98e3f1e78a1ce485209337e77f3a834d3545641/examples/mcp.json.sample
679504479,generative-ai-use-cases,aws-samples/generative-ai-use-cases,https://github.com/aws-samples/generative-ai-use-cases,Application implementation with business use cases for safely utilizing generative AI in business operations,,0,Unknown,,mcp.json,"Generative AI Use Cases (GenU) [](https://aws-samples.github.io/generative-ai-use-cases/index.html) [](https://github.com/aws-samples/generative-ai-use-cases/blob/main/LICENSE) [](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/node.js.yml) [](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/browser-extension.yml) English | Êó•Êú¨Ë™û | ÌïúÍµ≠Ïñ¥ Well-architected application implementation with business use cases for utilizing generative AI in business operations > [!IMPORTANT] > GenU has supported multiple languages since v4. > > GenU „ÅØ v4 „Åã„ÇâÂ§öË®ÄË™ûÂØæÂøú„Åó„Åæ„Åó„Åü„ÄÇÊó•Êú¨Ë™û„Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ GenU Usage Patterns Here we introduce GenU's features and options by usage pattern. For comprehensive deployment options, please refer to this document. > [!TIP] > Click on a usage pattern to see details I want to experience generative AI use cases GenU provides a variety of standard use cases leveraging generative AI. These use cases can serve as seeds for ideas on how to utilize generative AI in business operations, or they can be directly applied to business as-is. We plan to continuously add more refined use cases in the future. If unnecessary, you can also hide specific use cases with an option. Here are the use cases provided by default. Use Case Description Chat You can interact with large language models (LLMs) in a chat format. The existence of platforms that allow direct dialogue with LLMs enables quick responses to specific and new use cases. It's also effective as a testing environment for prompt engineering. Text Generation Generating text in any context is one of the tasks LLMs excel at. It generates all kinds of text including articles, reports, and emails. Summarization LLMs are good at summarizing large amounts of text. Beyond simple summarization, they can also extract necessary information in a conversational format after being given text as context. For example, after reading a contract, you can ask questions like ""What are the conditions for XXX?"" or ""What is the amount for YYY?"" Meeting Minutes Automatically generate meeting minutes from audio recordings or real-time transcription. Choose from Transcription, News Paper, or FAQ style with zero prompt engineering required. Writing LLMs can suggest improvements from a more objective perspective, considering not only typos but also the flow and content of the text. You can expect to improve quality by having the LLM objectively check points you might have missed before showing your work to others. Translation LLMs trained in multiple languages can perform translations. Beyond simple translation, they can incorporate various specified contextual information such as casualness and target audience into the translation. Web Content Extraction Extracts necessary information from web content such as blogs and documents. The LLM removes unnecessary information and formats it into well-structured text. Extracted content can be used in other use cases such as summarization and translation. ",https://github.com/aws-samples/generative-ai-use-cases/blob/4a35e1205da023f8c0a2aa59de84a4e6285585ee/packages/cdk/mcp-api/mcp.json
990824029,aixtiv-cli,AI-Publishing-International-LLP-UK/aixtiv-cli,https://github.com/AI-Publishing-International-LLP-UK/aixtiv-cli,# Free AI at api.airforce https://discord.gg/AJDsM7jtbq,,0,Unknown,,mcp.json,Free AI at api.airforce https://discord.gg/AJDsM7jtbq,https://github.com/AI-Publishing-International-LLP-UK/aixtiv-cli/blob/14c8a30f06d4d4638f57ae3efd337ccfe004ce53/firebase-mcp.json.bak
290594394,CipherTrust_Application_Protection,ThalesGroup/CipherTrust_Application_Protection,https://github.com/ThalesGroup/CipherTrust_Application_Protection,Public code samples and resources for the Thales CipherTrust Application Protection products of the CipherTrust Data Security Platform,,0,Unknown,,mcp.json,"CipherTrust Application Protection Overview [code] This repository will hold code samples and/or integrations that you can use in your environment Tokenization: Samples or integrations related to any form of tokenization, reversible or irreversible PKCS11: Samples or integrations using the PKCS11 provider of CipherTrust Application Data Protection product line (SDKs to embed encryption, tokenization and key operations directly in your application) REST: Samples or integrations using the REST web services provider of CipherTrust Application Data Protection Web Services product line as well as CipherTrust Vaulted Tokenization and CipherTrust Vaultless Tokenization products Database: Samples or integrations to your database applications using UDFs or extensions to incorporate encryption, tokenization and key operations directly in your database",https://github.com/ThalesGroup/CipherTrust_Application_Protection/blob/f7a24de5a4c615677760e7f7909cfb8d7af20a6b/mcp-servers/thales-cdsp-cakm-mcp-server/config/mcp.json.cursor.example
1090627085,etp-express,CONFENGE/etp-express,https://github.com/CONFENGE/etp-express,Sistema de gera√ß√£o automatizada de Estudos T√©cnicos Preliminares (ETP) usando Multi-Agent AI Orchestration,,0,Unknown,,mcp.json,"ETP EXPRESS > ‚ö† O ETP Express pode cometer erros. Lembre-se de verificar todas as informa√ß√µes antes de realizar qualquer encaminhamento. Sistema assistivo para elabora√ß√£o de Estudos T√©cnicos Preliminares (ETP) conforme Lei 14.133/2021 (Nova Lei de Licita√ß√µes e Contratos), utilizando IA generativa com orquestra√ß√£o de subagentes especializados. --- [](https://github.com/tjsasakifln/etp-express/actions/workflows/ci-lint.yml) [](https://github.com/tjsasakifln/etp-express/actions/workflows/ci-tests.yml) [](https://github.com/tjsasakifln/etp-express/actions/workflows/playwright.yml) [](https://github.com/tjsasakifln/etp-express/actions/workflows/security-audit.yml) [](https://github.com/tjsasakifln/etp-express/actions/workflows/secret-scan.yml) [](https://github.com/tjsasakifln/etp-express/blob/master/LICENSE) []() []() []() []() --- SOBRE O PROJETO O ETP Express √© um wrapper de LLM (Large Language Model) projetado para auxiliar servidores p√∫blicos, consultores e agentes de contrata√ß√£o na elabora√ß√£o de Estudos T√©cnicos Preliminares, conforme exigido pelo Art. 18 ¬ß1¬∫ da Lei 14.133/2021. Diferenciais - Sistema de Subagentes: 5 agentes especializados trabalhando em pipeline - Anti-Hallucination: Mitigacao ativa de alucinacoes e invencao de fatos - Busca Inteligente: Integracao com Exa AI para contratacoes similares - APIs Governamentais: PNCP, Compras.gov.br, SINAPI, SICRO como fontes primarias - Versionamento Completo: Historico com diff e restauracao de versoes - Export Profissional: PDF, JSON, XML e DOCX com disclaimers obrigatorios - Import & Analise: Upload PDF/DOCX para analise e conversao em ETP - SSE/Streaming: Feedback em tempo real durante geracao de secoes - Assistente IA (Chatbot): Chat contextual no editor com sugestoes proativas - Analytics de UX: Telemetria para melhoria continua - Cache LLM Inteligente: OpenAI (24h TTL) + Exa (7d TTL) - economia ~80% custos - Circuit Breaker Resiliente: Opossum para OpenAI/Exa - degradacao graciosa - RAG com pgvector: Fact-checking contra Lei 14.133/2021 vetorizada - Performance Otimizada: 4-5x speedup paralelizacao, 75% reducao queries DB - LGPD 100% Compliance: Export/delete completo, audit trail, soft delete - Zero-Downtime Deployment: Blue-green deployment Railway, health checks - CI/CD Otimizado: GitHub Actions cache, -68% reducao CI minutes - 1,879 Testes Automatizados: 78% backend, 76% frontend, zero erros TypeScript - Auditorias Arquiteturais: Orchestrator (95%), User (92%), Sections (83%) Funcionalidades Core 1. ‚úÖ Formul√°rio guiado para preenchimento das 13 se√ß√µes do ETP 2. ‚úÖ Gera√ß√£o assistida por IA (GPT-4) com valida√ß√£o multi-agente 3. ‚úÖ Busca de contrata√ß√µes similares para fundamenta√ß√£o 4. ‚úÖ Versionamento e trilha de auditoria completos 5. ‚úÖ Exporta√ß√£o em PDF (com aviso destacado), JSON e XML 6. ‚úÖ Valida√ß√£o obrigat√≥ria de se√ß√µes m√≠nimas (I, IV, VI, VIII, XIII) 7. ‚úÖ Interface moderna, responsiva e acess√≠vel (WCAG 2.1 AA) 8. ‚úÖ Assistente IA (Chatbot): Chat contextual para duvidas durante elabora√ß",https://github.com/CONFENGE/etp-express/blob/ab17e36bebe05815c31796303381dc7eab73ea3e/.mcp.json.backup
987312273,Solar_Module_Test,Lifeiscool84/Solar_Module_Test,https://github.com/Lifeiscool84/Solar_Module_Test,,,0,Unknown,,mcp.json,"Solar Module Test A monitoring system for solar modules using the SparkFun RedBoard Artemis Nano platform. Hardware Components - SparkFun RedBoard Artemis Nano - BH1750 Light Sensor (I2C address 0x23) - INA228 Current/Voltage Sensors: - Solar Panel Monitor (0x40) - Battery Power Monitor (0x42) - Load Power Monitor (0x41) Features - Real-time monitoring of light intensity (lux) - Voltage, current, and power measurements for solar panel, battery, and load - Serial output of all sensor readings Requirements - PlatformIO or Arduino IDE - Adafruit_INA228 library (modified for direct I2C communication) - hp_BH1750 library Wiring - BH1750 connected to I2C (SDA/SCL) - INA228 sensors connected to I2C with appropriate addresses (0x40, 0x41, 0x42) Usage 1. Upload the code to your SparkFun RedBoard Artemis Nano 2. Open Serial Monitor at 115200 baud 3. View real-time sensor readings updated every 3 seconds License MIT",https://github.com/Lifeiscool84/Solar_Module_Test/blob/20ceb7b1fc385871a15b047ee9e964b8943d2d1f/mcp.json.temp
1125968921,standardbeagle-tools,standardbeagle/standardbeagle-tools,https://github.com/standardbeagle/standardbeagle-tools,"Claude Code marketplace plugins: agnt (browser superpowers), lci (code intelligence), tools (combined)",,0,Unknown,,mcp.json,"Standard Beagle Tools AI coding agent toolkit - browser superpowers, code intelligence, and development tools. Plugins This marketplace contains 13 plugins for Claude Code: | Plugin | Description | Version | Category | |--------|-------------|---------|----------| | agnt | Browser superpowers: process management, reverse proxy, frontend debugging, sketch mode | 0.7.12 | development | | lci | Lightning Code Index: sub-millisecond semantic code search | 0.4.0 | development | | tools | Complete toolkit combining agnt and lci | 1.0.0 | development | | mcp-architect | Design high-quality MCP servers with progressive discovery and token efficiency | 0.1.0 | development | | mcp-tester | MCP server testing and debugging with mcp-debug | 0.2.0 | development | | slop-mcp | SLOP integration for MCP management and orchestration | 0.2.0 | development | | slop-coder | SLOP language coding assistant and reference | 0.1.0 | development | | dartai | Dart task management with adversarial cooperation loops | 0.3.0 | development | | workflow | General-purpose adversarial workflow automation | 0.1.0 | development | | figma-query | Token-efficient Figma integration with design library extraction | 0.1.0 | design | | ux-design | UX design principles, color theory, typography, and accessibility | 0.1.0 | design | | ux-developer | UX-driven development with WCAG 2.2 and usability best practices | 0.1.0 | development | | prompt-engineer | State-of-the-art prompt and context engineering for 2026 | 0.1.0 | ai | Installation Step 1: Install the binaries [code] Step 2: Register MCP servers Option A: Via slop-mcp (recommended if available) [code] Option B: Add to [code] [code] Step 3 (Optional): Install Claude Code plugins The plugins provide commands, skills, and agents that help you use the MCP tools: [code] Plugin Details agnt - Browser Superpowers Give your AI coding agent browser superpowers: - Process Management: Run and manage dev servers with output capture - Reverse Proxy: HTTP traffic logging with automatic frontend instrumentation - Browser Debugging: 50+ diagnostic functions ( [code] API) - Sketch Mode: Excalidraw-like wireframing directly on the UI - Design Mode: AI-assisted UI iteration with live preview - Error Capture: JavaScript errors automatically available to agent Requirements: [code] binary via npm/pip or GitHub releases lci - Lightning Code Index Sub-millisecond semantic code search and code intelligence: - Instant Search: Find code patterns across any codebase in <5ms - Symbol Lookup: Definitions, references, and implementations - Call Hierarchy: Trace function calls up and down - Codebase Overview: 79.8% context reduction for efficient analysis - Context Manifests: Save/load code context for agent handoff - Side Effect Analysis: Function purity and mutation tracking Requirements: [code] binary via npm/pip/go or GitHub releases tools - Complete Toolkit Best of both worlds - combines agnt and lci for the ultimate AI coding experience. Requirements: Both ",https://github.com/standardbeagle/standardbeagle-tools/blob/ab6d28eed5722966150cea790d450d363e487a02/plugins/agnt/mcp.json.disabled
1001066847,mcp-wise,sergeiledvanov/mcp-wise,https://github.com/sergeiledvanov/mcp-wise,Wise MCP server,,0,Unknown,,mcp.json,"Wise MCP Server A MCP (Machine Communication Protocol) server that serves as a gateway for the Wise API, providing simplified access to Wise's recipient functionality. Features - List all recipients from your Wise account via a simple MCP resource - Automatically handles authentication and profile selection - Uses the Wise Sandbox API for development and testing - Available as a Docker image for easy integration Requirements - Python 3.12 or higher (only if installing directly) - [code] package manager (only if installing directly) - Wise API token - Docker (if using Docker image) Get an API token https://wise.com/your-account/integrations-and-tools/api-tokens Create a new token here. Installation Option 1: Direct Installation 1. Clone this repository: [code] 2. Set up the environment: [code] 3. Install dependencies with [code] : [code] Option 2: Using Docker You can build a Docker image: [code] And add to Claude Code by adding it to your [code] [code] Make sure to replace [code] with your actual Wise API token. Make sure to also update your .mcp.json file to match your selected mode. We provide template files that you can use: 1. For stdio mode (default): [code] 2. For HTTP mode: [code] These template files contain the appropriate configuration for each mode. Available MCP Resources The server provides the following MCP resources: [code] Returns a list of all recipients from your Wise account. Parameters: - [code] : The type of profile to list recipients for. One of [personal, business]. Default: ""personal"" - [code] : Optional. Filter recipients by currency code (e.g., 'EUR', 'USD') [code] Fetches recipient requirements for creating a new recipient. If account details are provided, validates the account details against the requirements. Parameters: - [code] : The source currency code (e.g., 'USD') - [code] : The target currency code (e.g., 'EUR') - [code] : The amount in the source currency - [code] : The type of profile to use. One of [personal, business]. Default: ""personal"" - [code] : Optional. The recipient account details to validate against requirements. If not provided, returns the initial account requirements. [code] Creates a new recipient with the provided account details. Parameters: - [code] : The type of profile to use. One of [personal, business]. Default: ""personal"" - [code] : The recipient account details compliant with Wise API requirements. This should include: - [code] : Name of the account holder - [code] : Target currency code (e.g., 'EUR') - [code] : Account type (e.g., 'iban', 'sort_code', etc.) - [code] : Object containing account-specific details (varies by currency and country) [code] Sends money to a recipient using the Wise API. Parameters: - [code] : The type of profile to use (personal or business) - [code] : Source currency code (e.g., 'USD') - [code] : Amount in source currency to send - [code] : The ID of the recipient to send money to - [code] : Optional. Reference message for the transfer (defaults to ""money"") ",https://github.com/sergeiledvanov/mcp-wise/blob/1dced212f736157c8974ecf160e1c0ea5f76e3d3/.mcp.json.stdio
1043827136,agent-hivemind,lancejames221b/agent-hivemind,https://github.com/lancejames221b/agent-hivemind,ClaudeOps hAIveMind - Distributed AI collective memory MCP server for DevOps automation and multi-agent coordination,,0,Unknown,,mcp.json,"hAIveMind MCP Server A distributed multi-agent DevOps memory system implementing the Model Context Protocol (MCP). Enables Claude and other AI agents to share knowledge, coordinate tasks, and maintain persistent memory across distributed infrastructure. Features - Persistent Memory Storage: ChromaDB-backed vector storage with Redis caching - Multi-Agent Coordination: Register agents, delegate tasks, and share discoveries across the collective - Teams & Vaults: Secure collaborative workspaces with encrypted secret management - Zero-Knowledge Vault Sharing: X25519 key exchange for secure vault key distribution - Skills.sh Integration: Discover and install reusable AI agent capabilities from skills.sh - Confidentiality Controls: PII/confidential data protection with sync/broadcast filtering - Token-Optimized Format: 60-80% token reduction with v2 format system - Remote Access: HTTP/SSE server for MCP clients with HTTPS/Tailscale Serve support - Agent Authentication: Firebase-backed identity with pre-auth keys and capabilities - 130+ MCP Tools: Comprehensive DevOps tooling for infrastructure, deployment, and monitoring - Configuration Management: Drift detection, snapshots, and intelligent alerting - Disaster Recovery: Automated backups, failover, and chaos engineering support Version Current Release: v2.3.0 Recent Changes - v2.3.0: Secure admin bootstrap system with vault-based credentials, hardcoded password removal, complete API v1 endpoints for vault operations - v2.2.0: Skills.sh integration, zero-knowledge vault sharing, HTTPS/Tailscale Serve support, agent authentication system - v2.1.5: Fixed PII protection MCP tool exposure, comprehensive README update - v2.1.4: PII/Confidential memory protection system - v2.1.3: Agents directory support in vault system - v2.1.2: Full toolset enabled in remote server - v2.1.1: Vault sync tools restored Installation [code] Configuration Claude Code Integration Add to [code] : [code] Server Configuration Copy [code] to [code] : [code] MCP Tools (126 Total) Core Memory Tools | Tool | Description | |------|-------------| | [code] | Store memories with confidentiality controls | | [code] | Get specific memory by ID | | [code] | Upgrade memory protection level (one-way) | | [code] | Full-text and semantic search with filtering | | [code] | Time-windowed retrieval | | [code] | Statistics and counts | | [code] | Project-scoped memories | | [code] | Bulk import conversations | Confidentiality Levels | Level | Sync | Broadcast | Search | Description | |-------|------|-----------|--------|-------------| | [code] | Yes | Yes | Full | Default - full visibility | | [code] | No | Limited | Full | No external machine sync | | [code] | No | No | Local | Local machine only | | [code] | No | No | Local | Audit logged, blocked from all distribution | Agent Coordination | Tool | Description | |------|-------------| | [code] | Register with the collective | | [code] | List all active agents | | [code] | Assign work to specialists",https://github.com/lancejames221b/agent-hivemind/blob/1f0651617dff8a0c907e0b4a2bb00847eb51cd4a/.cursor/mcp.json.backup
72379881,dotf2,avasyutin/dotf2,https://github.com/avasyutin/dotf2,My dotfiles,,0,Unknown,,mcp.json,"Dotf2 My personal dotfiles managed with Ansible. Prerequisites [code] Configuration User information is configured in [code] : - [code] - Your full name for git config - [code] - Your email for git config Installation Full setup (installs homebrew packages and configures all tools): [code] Update specific tools only: [code] Available tags: [code] , [code] , [code] , [code] , [code] , [code] , [code] , [code] Post-Installation Vim Plugins After vim is installed, open vim and run: [code] Then restart vim. Secrets Create [code] for any environment variables that should not be committed to git.",https://github.com/avasyutin/dotf2/blob/22f9dbc10e91c739e68243e27983072ac0b67f36/dotfiles/claude/mcp.json.j2
915129664,dotfiles,krbylit/dotfiles,https://github.com/krbylit/dotfiles,,,0,Unknown,,mcp.json,"Dotfiles Personal macOS development environment managed with chezmoi. Table of Contents - Quick Start - What's Included - Core Tools - Priority 1: Essential Configuration - Priority 2: Supporting Tools - Priority 3: Supplementary Tools - Documentation - Getting Started - Reference Guides - Workflows - Tool-Specific Documentation - Key Features - Secrets Management - Multi-Machine Support - Automation Scripts - Quality Gates - Common Tasks - Making Configuration Changes - Syncing Multiple Machines - Finding Keyboard Shortcuts - Troubleshooting Common Issues - Manual Dependencies - Chezmoi Quick Reference - Essential Commands - State Terminology - File Naming Conventions - Secrets and Encryption - GPG Encryption - 1Password Integration - Pre-commit Secret Scanning - GitHub Actions - Neovim Configuration - Support - Getting Help - Contributing - License - Acknowledgments Quick Start New to these dotfiles? Start here: 1. Installation Guide - Complete setup instructions for fresh macOS installation (~60 minutes) 2. Chezmoi Workflow - How to make configuration changes safely 3. Keymaps Reference - Find any keyboard shortcut across all tools 4. Troubleshooting - Common issues and solutions What's Included This repository contains configurations for a complete macOS development environment with: - Shell: Fish with Starship prompt and 77+ custom functions - Editor: Neovim with LSP, plugins, and extensive customization - Window Management: Yabai + skhd + Karabiner for tiling and keyboard-driven workflow - Terminal: Ghostty, Tmux, Zellij for multiplexing - Git: Custom aliases, Delta diff viewer, lazygit TUI - File Management: Yazi TUI file manager with custom keybindings - Development Tools: Language servers, formatters, linters, and build tools - Security: Pre-commit hooks with gitleaks, GPG encryption, secrets management Core Tools Priority 1: Essential Configuration | Tool | Purpose | Config Location | | -------------- | ---------------------------------------- | ---------------------------------------- | | Fish Shell | Primary shell with 77+ custom functions | [code] | | Neovim | Primary text editor with LSP and plugins | [code] | | Yabai | Tiling window manager | [code] | | Skhd | Hotkey daemon for window management | [code] | | Karabiner | Hardware keyboard remapping | [code] | | Git | Version control with Delta diff viewer | [code] , [code] | | Starship | Shell prompt | [code] | | Chezmoi | Dotfiles management | [code] , [code] | Priority 2: Supporting Tools | Tool | Purpose | Config Location | | --------------- | --------------------------------------- | ---------------------------------------- | | Ghostty | Terminal emulator | [code] | | Tmux | Terminal multiplexer | [code] | | Zellij | Modern terminal workspace | [code] | | Yazi | TUI file manager | [code] | | Lazygit | TUI git client | [code] | | Lazydocker | TUI docker client | [code] | | Atuin | Shell history with sync | [code] | | Bat | Enhanced [code] with syntax highlighting | [code] | | Bot",https://github.com/krbylit/dotfiles/blob/eb2a67760c1d694594552ff3a3b6a01db2581bd9/dot_claude/symlink_dot_mcp.json.tmpl
1046580501,go2-webrtc-mcp,roberttwomey/go2-webrtc-mcp,https://github.com/roberttwomey/go2-webrtc-mcp,,,0,Unknown,,mcp.json,"Unitree Go2 WebRTC MCP Server A simple Model Context Protocol (MCP) server that enables natural language control of the Unitree Go2 robot using WebRTC connections instead of ROS. This server provides an intuitive interface for controlling your Go2 robot through natural language commands interpreted by an LLM. Features - WebRTC Connection: Uses the official Unitree WebRTC driver for reliable robot communication - No ROS Required: Works without ROS installation or configuration - Multiple Connection Methods: Supports AP mode, local network, and remote TURN server connections - Natural Language Control: Execute robot commands using simple English phrases - MCP Integration: Seamlessly integrates with MCP-compatible AI assistants Prerequisites - Python 3.8 or higher - Unitree Go2 robot (AIR/PRO/EDU models supported) - Network connection to the robot Installation 1. Clone the repository: [code] 2. Install dependencies: [code] 3. Install the WebRTC driver: [code] Configuration MCP Client Configuration Add the following to your MCP client configuration file (e.g., [code] ): [code] Connection Methods The server supports three connection methods: 1. Local AP Mode: Robot creates its own WiFi network - Use [code] - No additional parameters needed 2. Local STA Mode: Robot and client on same network - Use [code] - Provide either [code] or [code] 3. Remote Mode: Connect through Unitree's TURN server - Use [code] - Requires [code] , [code] , and [code] Usage Available Tools The MCP server provides the following tools: 1. [code] Connect to a Go2 robot using WebRTC. Parameters: - [code] (required): ""local_ap"", ""local_sta"", or ""remote"" - [code] (optional): Robot's IP address for local_sta mode - [code] (optional): Robot's serial number - [code] (optional): Unitree account username for remote mode - [code] (optional): Unitree account password for remote mode Example: [code] 2. [code] Disconnect from the currently connected robot. 3. [code] Move the robot with specific parameters. Parameters: - [code] (required): ""forward"", ""backward"", ""left"", ""right"", or ""stop"" - [code] (optional): Movement duration in seconds - [code] (optional): Movement speed (0.0 to 1.0) Example: [code] 4. [code] Get the current status of the robot. 5. [code] Execute natural language commands. Parameters: - [code] (required): Natural language command Example: [code] Natural Language Commands The server understands various natural language phrases: - Movement: ""forward"", ""ahead"", ""straight"", ""backward"", ""back"", ""reverse"" - Turning: ""left"", ""turn left"", ""right"", ""turn right"" - Control: ""stop"", ""halt"", ""pause"" - Special: ""dance"", ""spin"", ""rotate"" Examples Basic Usage Flow 1. Connect to robot: [code] 2. Move robot: [code] 3. Execute complex command: [code] 4. Check status: [code] 5. Disconnect: [code] Claude Desktop Integration If using Claude Desktop, you can control your robot with natural language: - ""Connect to my Go2 robot and make it move forward"" - ""Turn the robot left and then stop it"" - ""Ex",https://github.com/roberttwomey/go2-webrtc-mcp/blob/c05eff6202341effe82bb2de97c88a90b3b332d7/mcp.json
91784063,dotfiles,xinlc/dotfiles,https://github.com/xinlc/dotfiles,ÊàëÁöÑÈÖçÁΩÆÊñá‰ª∂,,0,Unknown,,mcp.json,dotfiles ÊàëÁöÑÈÖçÁΩÆÊñá‰ª∂,https://github.com/xinlc/dotfiles/blob/fe2a8a92491f8beb2fd8603eb47e8f788d40603b/mac/home/.claude/.mcp.json-bak
1099914315,commons.systems,rumor-ml/commons.systems,https://github.com/rumor-ml/commons.systems,,,0,Unknown,,mcp.json,"Commons.Systems Monorepo A monorepo for commons.systems projects. --- Dev Environment Setup Prerequisites Choose your platform and complete the prerequisites: Windows: Install NixOS-WSL 1. Enable WSL on Windows Open PowerShell as Administrator and run: [code] Restart your computer when prompted. 2. Install NixOS-WSL Download the latest NixOS-WSL tarball from nix-community/NixOS-WSL releases: [code] 3. Initial NixOS-WSL configuration (inside WSL) [code] Relaunch WSL - you should now log in as your user. macOS: Install Nix [code] Follow the prompts and restart your shell when complete. --- Common Setup Steps After completing platform prerequisites, follow these steps (identical for all platforms): 1. Clone the repository [code] Platform-specific note for NixOS-WSL: Since NixOS-WSL doesn't include git by default, use a temporary shell: [code] 2. Activate Home Manager configuration This installs and configures all development tools declaratively: [code] Note: After the first activation, Home Manager will manage your Nix configuration and enable experimental features permanently, so you won't need those flags again. What this provides: - git - Version control (macOS: config merge; NixOS-WSL: permanent install) - direnv - Auto-loads project environment (with shell integration) - tmux - Terminal multiplexer with project-specific TUI - neovim - Modern text editor (vim/vi aliases) - Claude Code - AI coding assistant CLI 3. Allow direnv for this repository After Home Manager activation and shell restart: [code] The development environment will now load automatically when you enter the directory. 4. Verify setup [code] 5. Start developing (optional - for web apps) [code] Configuration & Automation The repository includes comprehensive Nix-based automation for reproducible machine setup. üìö Documentation - Automation Opportunities - Overview of what's automated and opportunities for improvement - SSH Automation Guide - Complete SSH setup automation with improvement opportunities - Tailscale Setup Guide - Secure VPN networking for NixOS and macOS - macOS Setup with nix-darwin - Complete declarative macOS configuration SSH Configuration - SSH Client Setup - Home Manager SSH client configuration - SSH Server Module - NixOS SSH server deployment - SSH Key Management - Central SSH key repository Tailscale VPN - NixOS Tailscale Module - Tailscale for NixOS/WSL2 - macOS Tailscale Module - Tailscale for nix-darwin macOS Configuration - nix-darwin Setup Guide - Complete macOS setup with nix-darwin - nix-darwin Modules - Available darwin modules and usage ‚öôÔ∏è What's Automated User-Level (Home Manager): - Git configuration with auto-detected identity - Tmux with project-specific TUI integration - SSH client with agent and modern security defaults - Development tools (direnv, neovim) - Claude Code CLI System-Level (NixOS): - SSH server with security hardening - Firewall configuration - mDNS/Avahi for hostname resolution - Tailscale VPN with mesh networking System-Level (m",https://github.com/rumor-ml/commons.systems/blob/a03cce3adbcfd2373fbe0a3b4624715a8514eaa2/.mcp.json.TODO.md
1017236392,azure-mcp-cli-client,hatasaki/azure-mcp-cli-client,https://github.com/hatasaki/azure-mcp-cli-client,MCP Client CLI tool work with Azure OpenAI,,0,Unknown,,mcp.json,"Azure MCP CLI Client https://github.com/hatasaki/azure-mcp-cli-client Description This CLI application integrates Azure OpenAI's function calling with Model Context Protocol (MCP) tools, enabling an interactive agent chat from the terminal. It loads Azure OpenAI configuration, connects to configured MCP servers, registers available tools, and orchestrates tool calls based on LLM responses. Download Pre-built binaries are available in GitHub Releases for: - Windows: [code] (contains [code] ) - Linux: [code] (contains [code] ) - macOS: [code] (contains [code] ) Download and extract the archive, then add the extraction directory to your PATH environment variable. Usage Release Binaries After downloading and extracting the release binaries, add the extraction directory to your PATH. [code] From Source If you prefer to run from source, follow these steps: [code] Initial setup - When launching for the first time, you need to enter the Azure OpenAI endpoint, API key, API version, and deployment name. When the API key is blank, authenticate using Entra ID (you must be logged in via [code] in your desktop environment) - To register the MCP server, you must create a mcp.json file and save it in .azuremcpcli directory under your user home folder( [code] for Windows, [code] for Linux). Copy mcp.json.sample to .azuremcpcli/mcp.json for fast start. For more details, refer to MCP Server Registration section. Options - Command options: - [code] : Delete saved configurations and saved MCP server list. - [code] : Enable verbose mode: display detailed tool input/output. - [code] : Append all conversation history including tool calls to the file - [code] : Run a single user input in batch mode. Sends the specified input once, auto-approves all tool calls, and prints only the final response. Use [code] to show connection and tool logs. Example: [code] - [code] : Specify a custom Azure OpenAI configuration file instead of the default (AzureOpenAI.json). - [code] : Specify a custom MCP server configuration file instead of the default (mcp.json). - [code] : Override the default system prompt sent to Azure OpenAI as the agent's initial system message. Example: [code] - Chat options: - [code] : Reset chat history during a session. - [code] / [code] : Exit the chat application. - [code] : List connected MCP servers and their available tools. - [code] : Show descriptions for each tool on the specified server. - [code] : Disable all tools for the specified server. - [code] : Enable all tools for the specified server. - [code] : Reconnect all MCP servers with reloading mcp.json configuration. - [code] : Force invocation of a specific tool with the given message. Example: [code] MCP Server Registration Before starting the CLI, create your MCP server configuration based on [code] and save it as [code] . Steps 1. Create the configuration directory (if it does not exist): [code] 2. Copy the template to create [code] : - macOS/Linux [code] - Windows PowerShell [code] 3. Open [code",https://github.com/hatasaki/azure-mcp-cli-client/blob/06cd1097ada6101859ae9084086b3db927587bce/mcp.json.sample
976492719,markdown-journal-rust,estevaom/markdown-journal-rust,https://github.com/estevaom/markdown-journal-rust,RAG to index md files accessible via Rust scripts,,0,Unknown,,mcp.json,"Journal RAG System A powerful, privacy-focused journal system with AI-powered semantic search and metadata analysis. This system allows you to query your personal journal entries using natural language and analyze patterns in your mood, habits, and thoughts over time. ‚ú® Features - üîç Semantic Search: Query your journal entries using natural language with Rust-powered performance - üìä Frontmatter Analysis: Track mood, anxiety, weight, and custom metrics over time - ü¶Ä Rust Implementation: High-performance indexing and search using native Rust - üè† Local Processing: Journal files and search indexing stay on your machine - ‚ö° Fast Embeddings: Uses fastembed for efficient vector generation - üì± Cross-Platform: Works on macOS, Linux, and Windows (via WSL) üöÄ Quick Start 1. Automated Setup Choose your platform and run the setup script: macOS: [code] Ubuntu/Debian (including WSL): [code] Arch Linux: [code] These scripts will: - Install Rust (if needed) - Install system dependencies - Build all tools - Set up convenience scripts 2. Manual Setup (Optional) If you prefer manual setup: Install Rust: [code] Build the tools: [code] 3. Start Journaling Add entries to the [code] directory using the provided templates: Daily Entry ( [code] ): [code] Weekly Retrospective ( [code] ): [code] Example frontmatter for tracking: [code] Templates are provided in the [code] directory: - [code] - Daily journal template with sections for reflection - [code] - Weekly retrospective for reviewing progress - [code] - Guide for configuring your AI assistant persona üéØ Usage Convenient Shell Scripts The project includes convenient shell scripts for common operations: [code] Direct Command Usage You can also use the Rust binaries directly: Index Your Journal Entries [code] Semantic Search [code] Frontmatter Analysis [code] üìÅ Directory Structure [code] üîß System Requirements Minimum Requirements - Rust 1.70+ (install via rustup) - 4GB RAM - 2GB free disk space Recommended - 8GB+ RAM for better performance - SSD storage for faster indexing üìä Frontmatter Fields Track various metrics in your journal entries: [code] You can customize these fields based on what you want to track. ü§ñ Claude Code Integration This project includes enhanced Claude Code integration for a superior development experience: Features - Custom Agents ( [code] ): - [code] : Automatically searches your journal when context is needed - [code] : Helps complete journal frontmatter fields - [code] : Analyzes weekly retrospectives - Slash Commands ( [code] ): - [code] : Initialize your journaling session - [code] : Smart git commits with context - Status Line: Real-time token usage tracking (requires [code] ) - Automatic Timestamps: Each prompt includes current timestamp for context Setup (Optional) 1. Claude Code will automatically detect the [code] directory 2. For status line, install ccusage: [code] 3. Agents and commands are available immediately Usage Examples With Claude Code: - Ask about past events - the RAG agent will s",https://github.com/estevaom/markdown-journal-rust/blob/b70b0a3f5e65611676bfbccda3d6572de5b24bd1/mcp.json.template
962750330,mcp-osv,gleicon/mcp-osv,https://github.com/gleicon/mcp-osv,A MCP (Model Context Protocol) server to allow code security reviews using https://osv.dev (Open Source Vulnerabilities Database),,0,Unknown,,mcp.json,"MCP Security Analyst [](https://github.com/gleicon/mcp-osv/actions/workflows/go.yml) A Model Context Protocol (MCP) server providing comprehensive security analysis capabilities through integration with OSV.dev vulnerability database and native Go-based code analysis and secret detection engines. Features * Supply Chain Vulnerability Analysis: Integration with OSV.dev API for dependency vulnerability assessment * Secret Detection: Gitleaks v8 integration with 100+ built-in detection rules for credentials and API keys * Static Code Analysis: AST-based Go code analysis for security anti-patterns * Pattern Matching: Regex-based detection for common security vulnerabilities * MCP Protocol Support: Standard protocol implementation for AI assistant integration * Community-Vetted Rules: Gitleaks patterns maintained by the security community Requirements Core Requirements [code] Build Dependencies * Go 1.25.4 or later * github.com/mark3labs/mcp-go * github.com/zricethezav/gitleaks/v8 Installation [code] pre-built releases The mcp-osv binary communicates via stdin/stdout using the MCP protocol. IDE Configuration Cursor IDE Navigate to Configuration > MCP and add: [code] Claude Desktop Edit the MCP configuration file at Settings > Developer: [code] Available Tools The server exposes three MCP tools for security analysis: check_vulnerabilities Query OSV.dev database for known vulnerabilities in specific package versions. Parameters: * [code] (string, required): Package identifier * [code] (string, required): Version string Functionality: * Rate-limited API requests (1 request/second) * HTTP timeout protection (10 seconds) * JSON response parsing * Vulnerability detail extraction analyze_security Comprehensive security analysis combining multiple detection engines. Parameters: * [code] (string, required): Target file or directory path Analysis Components: * Native Go AST-based code analysis * Gitleaks v8 secret detection with 100+ rules * OSV.dev vulnerability checks for dependencies (go.mod files) * Pattern-based vulnerability detection Detected Issues: * Command injection vectors * Deserialization vulnerabilities * SQL injection patterns * Hardcoded credentials * API keys and tokens * Private keys and certificates * Database connection strings scan_secrets Dedicated secret detection using Gitleaks v8 with 100+ community-maintained detection rules. Parameters: * [code] (string, required): Target file, directory, or repository path * [code] (boolean, optional): Enable git history scanning (default: false) Detection Capabilities (100+ patterns): * AWS Access Keys, Secret Keys, Session Tokens * GitHub Personal Access Tokens, OAuth tokens * Google Cloud Platform API keys * Azure credentials and connection strings * Slack tokens and webhooks * Stripe API keys * Private SSH/PGP/RSA keys * JWT tokens * Database connection strings (PostgreSQL, MySQL, MongoDB) * Generic API keys with entropy analysis * And 90+ more patterns maintained by the security community Outpu",https://github.com/gleicon/mcp-osv/blob/739c89cb88c976d1027663dec124d09d85c9e1c5/mcp.json-template
1043727794,multi-controller-app,wtyler2505/multi-controller-app,https://github.com/wtyler2505/multi-controller-app,"Windows app for controlling Arduino, ESP32, and other hardware devices over Serial, TCP/UDP, and SSH",,0,Unknown,,mcp.json,"Multi-Controller App [](https://github.com/wtyler2505/multi-controller-app/actions/workflows/rust-ci.yml) [](https://github.com/wtyler2505/multi-controller-app/actions/workflows/test-coverage.yml) [](https://codecov.io/gh/wtyler2505/multi-controller-app) [](https://opensource.org/licenses/MIT) A lightweight Windows application for discovering, connecting to, and controlling heterogeneous hardware devices (Arduino/ESP32/ESP8266/RioRand/Raspberry Pi) over Serial, TCP/UDP, or SSH. üöÄ Features - Multi-Protocol Support: Serial, TCP, UDP, SSH - Hot-Swappable Drivers: Plugin architecture for device drivers - Real-Time Telemetry: High-performance data streaming with decimation - Performance Optimized: < 2s startup, ‚â§ 2% idle CPU, ‚â§ 150MB RAM - Native AOT Compilation: Single executable distribution - Extensible: Easy to add new device support üìã Task Progress Last Updated: January 24, 2025 Summary - Total Tasks: 19 main tasks (100 subtasks) - Completed: 0 (0%) - In Progress: 0 (0%) - Pending: 19 (100%) - Overall Progress: ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú 0% Subtask Breakdown - Total Subtasks: 100 - Completed: 0 (0%) - Pending: 100 (100%) - Average Subtasks per Task: 5.3 üìã Prerequisites - Windows 10/11 (64-bit) - .NET 8 SDK (for C# development) - Node.js 18+ (for TypeScript/MCP servers) - Git - VS Code or Visual Studio 2022 üõ†Ô∏è Quick Setup Automated Setup (Recommended) [code] Manual Setup 1. Clone the repository [code] 2. Install dependencies [code] 3. Copy environment variables [code] 4. Build the project [code] üìã Task Management Quick Commands [code] Task Master Integration - All development work is tracked via Task Master - Use [code] commands in Claude Code - See Task Management Guide for detailed workflows - View TaskMaster Workflow Guide for commands üß™ Testing & Coverage Test Coverage Requirements - Minimum Coverage: 80% for all modules - CI/CD Integration: Automated coverage checks on every PR - Platform Support: Full coverage on Linux, test validation on Windows/macOS Running Tests [code] Test Categories - Unit Tests: 100+ tests for individual components - Integration Tests: 48+ tests for cross-module interactions - Loopback Tests: 48+ tests for transport protocols - Performance Tests: Latency, throughput, stress testing - Device Driver Tests: 150+ tests covering all driver endpoints Coverage Reports - HTML reports generated in [code] directory - CI uploads reports to Codecov for tracking - Windows fallback using test counting method - Coverage badges displayed in README üîß Development Development Guidelines - Verification-First Development: All implementations must be verified before claiming completion (see CLAUDE.md) - Task Management: Use TaskMaster protocol for all work - check tasks before starting - Code Standards: Follow Coding Standards for consistent code style - Examples: See Style Guide for implementation patterns - Editor Setup: Project includes [code] for consistent formatting - File Management: Never create files unless explicitly requested - always edit exis",https://github.com/wtyler2505/multi-controller-app/blob/b022268b42b410d319a12e4f649c99c402d56365/.mcp.json.backup-clearthought
1060559513,INSPIRASI,RajendraDamar/INSPIRASI,https://github.com/RajendraDamar/INSPIRASI,,,0,Unknown,,mcp.json,,https://github.com/RajendraDamar/INSPIRASI/blob/26e72d041b055a32c58827a88fed5e2d6d83c853/.serena/memories/mcp-servers-in-mcp.json.md
1007770790,world-cup-platform,jasonkwak190/world-cup-platform,https://github.com/jasonkwak190/world-cup-platform,,,0,Unknown,,mcp.json,"üèÜ Ï∞®ÏÑ∏ÎåÄ Ïù¥ÏÉÅÌòï ÏõîÎìúÏªµ ÌîåÎû´Ìèº UX/UI, ÌôïÏû•ÏÑ±, Ìé∏ÏùòÏÑ±ÏùÑ Ï†úÍ≥µÌïòÎäî Ïª§ÎÆ§ÎãàÌã∞Ìòï Ïù¥ÏÉÅÌòï ÏõîÎìúÏªµ ÌîåÎû´ÌèºÏûÖÎãàÎã§. üöÄ Îπ†Î•∏ ÏãúÏûë 1. ÌîÑÎ°úÏ†ùÌä∏ ÌÅ¥Î°† Î∞è ÏÑ§Ïπò [code] 2. ÌîÑÎ°†Ìä∏ÏóîÎìú ÏÑ§Ï†ï [code] 3. Claude MCP ÏÑ§Ï†ï (Í∞úÎ∞úÏö©) [code] ‚öôÔ∏è Í∞úÎ∞ú ÌôòÍ≤Ω ÏÑ§Ï†ï ÌïÑÏàò ÏöîÍµ¨ÏÇ¨Ìï≠ - Node.js 18+ - npm ÎòêÎäî yarn - Claude CLI (MCP ÏÇ¨Ïö© Ïãú) Claude MCP Í∏∞Îä• - Memory: ÎåÄÌôî ÎÇ¥Ïö© Í∏∞Ïñµ Î∞è Í¥ÄÎ¶¨ - Sequential Thinking: Î≥µÏû°Ìïú Î¨∏Ï†ú Îã®Í≥ÑÎ≥Ñ Ìï¥Í≤∞ - Filesystem: ÌîÑÎ°úÏ†ùÌä∏ ÌååÏùº Ï†ëÍ∑º ÏµúÏ†ÅÌôî - GitHub: Ï†ÄÏû•ÏÜå Í¥ÄÎ¶¨ (API ÌÇ§ ÌïÑÏöî) - Brave Search: Ïõπ Í≤ÄÏÉâ (API ÌÇ§ ÌïÑÏöî) - Gemini CLI: ÎåÄÏö©Îüâ ÌååÏùº Î∂ÑÏÑù (API ÌÇ§ ÌïÑÏöî) üìã Í∞úÎ∞ú Í∞ÄÏù¥Îìú ÏûêÏÑ∏Ìïú Í∞úÎ∞ú Í∞ÄÏù¥ÎìúÎäî CLAUDE.mdÎ•º Ï∞∏Í≥†ÌïòÏÑ∏Ïöî. üõ† Í∏∞Ïà† Ïä§ÌÉù Frontend - Next.js 14 (App Router) - TypeScript - TailwindCSS + Headless UI - Framer Motion - React Hook Form + Zod - Zustand (ÏÉÅÌÉúÍ¥ÄÎ¶¨) - React Query (ÏÑúÎ≤ÑÏÉÅÌÉú) Backend - Node.js + Express - PostgreSQL (Î©îÏù∏ DB) - Redis (Ï∫êÏãú, ÏÑ∏ÏÖò) - S3 (ÌååÏùº Ï†ÄÏû•) - Socket.io (Ïã§ÏãúÍ∞Ñ) - Bull (ÌÅê ÏãúÏä§ÌÖú) üéØ Ï£ºÏöî Í∏∞Îä• - üéÆ ÌÜ†ÎÑàÎ®ºÌä∏ Î∞©Ïãù ÏõîÎìúÏªµ ÌîåÎ†àÏù¥ - üõ† ÎìúÎûòÍ∑∏ Ïï§ ÎìúÎ°≠ ÏΩòÌÖêÏ∏† ÏÉùÏÑ± - üìä Ïã§ÏãúÍ∞Ñ ÌÜµÍ≥Ñ Î∞è Îû≠ÌÇπ - üåê ÎåìÍ∏Ä/Ï¢ãÏïÑÏöî/Î∂ÅÎßàÌÅ¨ ÏÜåÏÖú Í∏∞Îä• - üì± Î∞òÏùëÌòï ÎîîÏûêÏù∏ - ‚ö° Î¨¥Ìïú Ïä§ÌÅ¨Î°§ Î∞è Í∞ÄÏÉÅÌôî üìÑ ÎùºÏù¥ÏÑ†Ïä§ Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî MIT ÎùºÏù¥ÏÑ†Ïä§ ÌïòÏóê ÏûàÏäµÎãàÎã§.",https://github.com/jasonkwak190/world-cup-platform/blob/a9038acbc6012cf06c621e8ec23e37d2a467012c/.claude/.mcp.json.template
1073624303,devcontainer-template,kodflow/devcontainer-template,https://github.com/kodflow/devcontainer-template,,,0,Unknown,,mcp.json,"devcontainer-template Coquille DevContainer universelle fournissant un ecosysteme IA complet ‚Äî 35 agents specialistes, 11 commandes slash, workflows auto-correctifs ‚Äî pour bootstrapper et developper n'importe quel projet avec une qualite maximale. Fiabilite d'abord : les agents raisonnent en profondeur, recoupent les sources officielles, et s'auto-corrigent jusqu'a ce que le resultat respecte les standards. Installation Rapide One-Liner (Machine H√¥te ou Projet Existant) Installez Claude Code avec TOUS les assets (35 agents, 11 commands, 11 scripts, 155+ patterns) en une seule commande : [code] Ce qui est install√© : - ‚úÖ Claude CLI (si pas d√©j√† install√©) - ‚úÖ 35 agents sp√©cialis√©s (Go, Python, Rust, Node.js, etc.) - ‚úÖ 11 commandes slash ( [code] , [code] , [code] , [code] , etc.) - ‚úÖ 11 scripts de hooks (security, lint, format, test) - ‚úÖ 155+ design patterns (GoF, Cloud, DDD, Enterprise) - ‚úÖ Outils additionnels (grepai, status-line) Total : 239 fichiers (~3.2MB) en 1-2 minutes Installation minimale (sans documentation) : [code] Installation avec target personnalis√© : [code] Emplacements d'installation : - Machine h√¥te : [code] - DevContainer : [code] Mise √† jour ult√©rieure : [code] --- Outils inclus Base - Ubuntu 24.04 LTS - Zsh + Oh My Zsh + Powerlevel10k - Git, jq, yq, curl, build-essential Cloud & DevOps | Outil | Description | |-------|-------------| | AWS CLI v2 | Amazon Web Services | | gcloud | Google Cloud SDK | | az | Azure CLI | | terraform | Infrastructure as Code | | vault, consul, nomad, packer | HashiCorp Suite | | kubectl, helm | Kubernetes | | ansible | Configuration Management | Development | Outil | Description | |-------|-------------| | gh | GitHub CLI | | claude | Claude Code CLI | | op | 1Password CLI | | bazel | Build System | | task | Taskwarrior | | status-line | Claude Code status bar | Langages Les langages sont ajout√©s via DevContainer Features selon vos besoins : [code] Voir : https://containers.dev/features Installation Nouveau projet [code] Projet existant Copiez le dossier [code] dans votre projet. Configuration MCP Le template inclut des serveurs MCP pr√©-configur√©s pour Claude Code. Serveurs MCP inclus | Serveur | Description | |---------|-------------| | github | Int√©gration GitHub | | codacy | Analyse de code | | taskwarrior | Gestion de t√¢ches | Configuration des tokens Option 1 : Variables d'environnement [code] Option 2 : 1Password Configurez [code] et les items correspondants dans votre vault. Fichiers MCP | Fichier | Description | |---------|-------------| | [code] | Config MCP projet (ignor√© par git) | | [code] | Template MCP | Structure [code] Commandes Rebuild container [code] Claude avec MCP [code] Nettoyer [code] Volumes persistants - [code] : Binaires locaux - [code] : Extensions VS Code - [code] : Historique shell License MIT",https://github.com/kodflow/devcontainer-template/blob/7f19cc89bb0fba6aee2e752e155ee63cf04c840b/.devcontainer/images/mcp.json.tpl
1115360093,Farmhand,eaasxt/Farmhand,https://github.com/eaasxt/Farmhand,,,0,Unknown,,mcp.json,"‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù üöú Transform your Ubuntu VM into an AI Coding Powerhouse üåæ [](https://github.com/eaasxt/Farmhand) [](https://ubuntu.com/) [](#license) [](#testing) [](#-what-gets-installed) *One command. 30+ tools. Multiple AI agents working in harmony.* --- üìë Table of Contents Click to expand - TL;DR - Why Farmhand? - Who Is This For? - Quick Start - Architecture - What Gets Installed - Enforcement Hooks - The Workflow - Knowledge & Vibes Framework - Installation Options - Post-Installation - How to Use Farmhand - Keyboard Shortcuts - Single Agent Workflow - Multi-Agent Workflow - Daily Patterns - Common Scenarios - Troubleshooting - Testing - Documentation - Contributing - License üìã TL;DR Farmhand takes a bare Ubuntu VM and installs everything you need to run multiple AI coding agents (Claude, Codex, Gemini) that can work together without stepping on each other's toes. [code] What makes it special: - ü§ñ Multi-agent coordination ‚Äî File reservations prevent merge conflicts between agents - üîí Enforcement hooks ‚Äî Agents can't skip the workflow, even if they want to - üìä Graph-based task tracking ‚Äî Dependencies, priorities, and parallel execution paths - üî¨ Research-backed protocols ‚Äî 50+ papers distilled into actionable workflows > See it in action: The How to Use section has a complete walkthrough building ""CropWatch"" - a smart irrigation controller - with both single and multi-agent workflows. --- ü§î Why Farmhand? The Problem Running multiple AI coding agents on the same codebase creates chaos: [code] AI agents don't naturally coordinate. They'll: - Edit the same files simultaneously - Duplicate work another agent already did - Skip security scans because ""it looks fine"" - Ignore your project's conventions The Solution Farmhand enforces coordination at the tool level: [code] Agents can't cheat. The hooks intercept every file operation and enforce the workflow automatically. --- üßò The Philosophy: Truth Lives Outside the Model Farmhand is built on the Knowledge & Vibes framework. The core insight is simple: The AI's confident output is not truth. Truth is: 1. Tests that pass 2. Code that compiles 3. Documentation that exists 4. Security scans that clear Everything else is a hypothesis. Farmhand provides the protocol to turn those hypotheses into verified software: * Plan Explicitly: A ""North Star Card"" captures what success looks like before code is written. * Track Everything: Work is broken into ""beads"" (tasks) with explicit dependencies. * Coordinate: File reservations prevent ""too many cooks in the kitchen."" * Verify: Mandatory security scans ( [code] ) and tests act as the source of tr",https://github.com/eaasxt/Farmhand/blob/7ec19ab75a4d4dd33d090da4d8222d99b297de47/config/mcp.json.template
1046416711,DOT,crazybass81/DOT,https://github.com/crazybass81/DOT,DOT ÎπÑÏ¶àÎãàÏä§ ÌîåÎû´Ìèº - Ïô∏ÏãùÏóÖ ÎîîÏßÄÌÑ∏ Ï†ÑÌôò ÏÜîÎ£®ÏÖò,,0,Unknown,,mcp.json,DOT ÎπÑÏ¶àÎãàÏä§ ÌîåÎû´Ìèº Ïô∏ÏãùÏóÖ ÎîîÏßÄÌÑ∏ Ï†ÑÌôòÏùÑ ÏúÑÌïú ÌÜµÌï© ÎπÑÏ¶àÎãàÏä§ ÏÜîÎ£®ÏÖò üèóÔ∏è ÏïÑÌÇ§ÌÖçÏ≤ò ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§ Í∏∞Î∞òÏùò Î™®ÎÖ∏Î†àÌè¨ Íµ¨Ï°∞: [code] üöÄ ÏãúÏûëÌïòÍ∏∞ ÌïÑÏàò ÏöîÍµ¨ÏÇ¨Ìï≠ - Node.js 18.0.0+ - npm 9.0.0+ - Flutter SDK 3.10.0+ (Î™®Î∞îÏùº Ïï±) - AWS CLI (Î∞∞Ìè¨Ïö©) - Docker (Î°úÏª¨ Í∞úÎ∞úÏö©) ÏÑ§Ïπò [code] Í∞úÎ∞ú ÏÑúÎ≤Ñ Ïã§Ìñâ [code] üì¶ ÏÑúÎπÑÏä§ 1. Í∑ºÌÉúÍ¥ÄÎ¶¨ ÏÑúÎπÑÏä§ ( [code] ) GPS Í∏∞Î∞ò Ïã§ÏãúÍ∞Ñ Í∑ºÌÉúÍ¥ÄÎ¶¨ ÏãúÏä§ÌÖú (Ïõπ + Î™®Î∞îÏùº) - Ïõπ ÎåÄÏãúÎ≥¥Îìú: Í¥ÄÎ¶¨ÏûêÏö© Ïã§ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅ - Î™®Î∞îÏùº Ïï±: ÏßÅÏõêÏö© QR Ï≤¥ÌÅ¨Ïù∏/ÏïÑÏõÉ - ÏúÑÏπò Í≤ÄÏ¶ù: GPS Í∏∞Î∞ò Ï∂úÌá¥Í∑º ÏúÑÏπò ÌôïÏù∏ - ÏÉùÏ≤¥ Ïù∏Ï¶ù: ÏßÄÎ¨∏/Face ID Î≥∏Ïù∏ ÌôïÏù∏ - Ïò§ÌîÑÎùºÏù∏ Î™®Îìú: ÏûêÎèô ÎèôÍ∏∞Ìôî ÏßÄÏõê ÏÉÅÏÑ∏ Î¨∏ÏÑú ‚Üí 2. ÎßàÏºÄÌåÖ ÏûêÎèôÌôî ÏÑúÎπÑÏä§ ( [code] ) YouTube ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ ÎßàÏºÄÌåÖ ÏûêÎèôÌôî ÌîåÎû´Ìèº - ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ Î∞úÍµ¥: ÌÇ§ÏõåÎìú Í∏∞Î∞ò Í≤ÄÏÉâ - ÏÑ±Í≥º Î∂ÑÏÑù: Ï±ÑÎÑê ÏÑ±Í≥º ÏßÄÌëú Î∂ÑÏÑù - Ï∫†ÌéòÏù∏ Í¥ÄÎ¶¨: Ïù¥Î©îÏùº ÌÖúÌîåÎ¶ø ÏûêÎèôÌôî - ROI Ï∂îÏ†Å: Ï∫†ÌéòÏù∏ Ìö®Í≥º Ï∏°Ï†ï ÏÉÅÏÑ∏ Î¨∏ÏÑú ‚Üí 3. Ïä§ÏºÄÏ§ÑÎü¨ ÏÑúÎπÑÏä§ ( [code] ) ÏßÅÏõê ÏùºÏ†ï Î∞è ÏãúÌîÑÌä∏ Í¥ÄÎ¶¨ ÏãúÏä§ÌÖú - ÏãúÌîÑÌä∏ Í¥ÄÎ¶¨: Ïú†Ïó∞Ìïú Í∑ºÎ¨¥ ÏùºÏ†ï ÏÑ§Ï†ï - ÏûêÎèô Î∞∞Ïπò: AI Í∏∞Î∞ò ÏµúÏ†Å Ïù∏Î†• Î∞∞Ïπò - Ìú¥Í∞Ä Í¥ÄÎ¶¨: Ìú¥Í∞Ä Ïã†Ï≤≠ Î∞è ÏäπÏù∏ ÌîÑÎ°úÏÑ∏Ïä§ - ÏïåÎ¶º ÏãúÏä§ÌÖú: ÏùºÏ†ï Î≥ÄÍ≤Ω Ïã§ÏãúÍ∞Ñ ÏïåÎ¶º ÏÉÅÏÑ∏ Î¨∏ÏÑú ‚Üí üõ†Ô∏è Í∏∞Ïà† Ïä§ÌÉù Web Frontend - Next.js 15.5 - React 19 - TypeScript 5.9 - Tailwind CSS 3.4 Mobile - Flutter 3.10+ - Dart 3.0+ - Riverpod (ÏÉÅÌÉúÍ¥ÄÎ¶¨) Backend - AWS Lambda (ÏÑúÎ≤ÑÎ¶¨Ïä§) - DynamoDB - API Gateway - Cognito (Ïù∏Ï¶ù) Infrastructure - AWS CDK - CloudWatch - CloudFront üìù Ïä§ÌÅ¨Î¶ΩÌä∏ | Î™ÖÎ†πÏñ¥ | ÏÑ§Î™Ö | |--------|------| | [code] | Î™®Îì† ÏÑúÎπÑÏä§ Í∞úÎ∞ú ÏÑúÎ≤Ñ Ïã§Ìñâ | | [code] | Î™®Îì† ÏÑúÎπÑÏä§ ÎπåÎìú | | [code] | Ï†ÑÏ≤¥ ÌÖåÏä§Ìä∏ Ïã§Ìñâ | | [code] | Ï†ÑÏ≤¥ Î¶∞Ìä∏ Í≤ÄÏÇ¨ | | [code] | ÎπåÎìú Í≤∞Í≥ºÎ¨º Î∞è Ï∫êÏãú ÏÇ≠Ï†ú | üè¢ ÌîÑÎ°úÏ†ùÌä∏ Íµ¨Ï°∞ Î™®ÎÖ∏Î†àÌè¨ Í¥ÄÎ¶¨ npm workspacesÎ•º ÏÇ¨Ïö©Ìïú Î™®ÎÖ∏Î†àÌè¨ Íµ¨Ï°∞Î°ú ÏùòÏ°¥ÏÑ±Í≥º Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ï§ëÏïôÏóêÏÑú Í¥ÄÎ¶¨Ìï©ÎãàÎã§. Í≥µÏú† Ìå®ÌÇ§ÏßÄ - [code] : Í≥µÌÜµ ÌÉÄÏûÖ Ï†ïÏùò Î∞è Ïú†Ìã∏Î¶¨Ìã∞ - [code] : Ïû¨ÏÇ¨Ïö© Í∞ÄÎä•Ìïú React Ïª¥Ìè¨ÎÑåÌä∏ - [code] : Í≥µÌÜµ Ìó¨Ìçº Ìï®Ïàò üìÑ ÎùºÏù¥ÏÑ†Ïä§ MIT --- DOT Team | Ïô∏ÏãùÏóÖ ÎîîÏßÄÌÑ∏ Ï†ÑÌôòÏùò ÌååÌä∏ÎÑà,https://github.com/crazybass81/DOT/blob/9288e2d005400bd0853846db870429f792c540ae/.mcp.json
74115154,dotfiles,rewse/dotfiles,https://github.com/rewse/dotfiles,Personal dotfile management system using chezmoi,,0,Unknown,,mcp.json,"Dotfiles Personal dotfiles management system using chezmoi. Centrally manage shell configurations, editor settings, Git configurations, and more across multiple machines (macOS and Linux). Features - Cross-platform support: Compatible with both macOS and Linux - Template-based: Manage machine-specific configurations with conditional branching - Secure secrets management: Safely manage API keys and credentials through 1Password integration Setup Installation on a New Machine macOS (Homebrew) [code] macOS (without Homebrew) or Linux [code] Or, install chezmoi only: [code] Install to a specific directory (e.g., [code] ): [code] If You Already Have chezmoi [code] Usage Daily Operations [code] Sync with Remote [code] Structure Directory Structure [code] Requirements - chezmoi - 1Password CLI (for secrets management)",https://github.com/rewse/dotfiles/blob/45e9673dc4c243e85084d02dd2560fa733cb9bd8/dot_config/private_mcp.json.tmpl
1061049441,dega-toolkit,madebyfamo/dega-toolkit,https://github.com/madebyfamo/dega-toolkit,Production-ready DEGA post-production toolkit with CLI and services. Ready for GUI development.,,0,Unknown,,mcp.json,"üé¨ The DEGA Toolkit Welcome to The DEGA Toolkit repository! üöÄ What is DEGA? The DEGA Toolkit is an enterprise-grade post-production workflow automation system designed by and for creative professionals. It handles the complex technical details of video processing so you can focus on storytelling. ‚ú® Key Features - üé• Professional Video Processing - Hardware-accelerated proxy generation with support for ARRI, RED, Sony, and more - üìÅ Smart Project Management - Automated project structure and organization - ‚ö° Production-Ready Reliability - Atomic operations, comprehensive error handling, and bulletproof workflows - üîß Developer-Friendly - Clean architecture ready for GUI and API integration üéØ Who Is This For? - Post-Production Professionals working with high-end cameras and workflows - Creative Studios needing reliable, scalable media processing - Developers building media workflow applications - Anyone tired of unreliable proxy generation tools ü§ù Contributing We welcome contributions from the community! Whether you're a post-production professional with workflow insights or a developer wanting to improve the codebase, there are many ways to help: - üêõ Report bugs - Help us identify and fix issues - ‚ú® Request features - Share your workflow needs and ideas - üìù Improve documentation - Help make the toolkit more accessible - üíª Submit code - Contribute features, fixes, and improvements - üß™ Test releases - Help validate new features in real workflows See our Contributing Guide for detailed information. üìö Getting Started 1. Installation Guide - Get up and running quickly 2. Quick Start - Essential commands to begin using DEGA 3. Commands Reference - Complete CLI documentation 4. Architecture Guide - Technical details and design principles üí¨ Community - Discussions - Share workflows, ask questions, and connect with other users - Issues - Report bugs and request features - Pull Requests - Contribute code improvements üìÑ License The DEGA Toolkit is released under the MIT License. See LICENSE for details. --- Built with ‚ù§Ô∏è by FAMO for DEGA Productions *Created by a working creative professional who understands real post-production workflows*",https://github.com/madebyfamo/dega-toolkit/blob/90fd6506528a1e2534433e1390d8dc1f3094a3c3/mcp.json.current
601548787,nammayatri,nammayatri/nammayatri,https://github.com/nammayatri/nammayatri,A Direct-to-Driver open mobility platform powering the next-generation of mobility applications in India.,,0,Unknown,,.clinerules,"üõ∫ Namma Yatri üöñ Open and Driver Centric Mobility Platform üåü Vision Namma Yatri aims to empower service providers with a high-tech, cost-effective app and open data platform. Our vision is centered on the following principles: 1. Zero Commission: Ensuring no commission fees for drivers, promoting fair earnings and economic empowerment for service providers. 2. Open: Utilizing open data platforms, open code, and open networks to foster transparency, innovation, and collaboration within the community. 3. Optimize: Achieve population scale growth with utility-like pricing by continuously optimizing maps, cloud, and development costs, all while maintaining high reliability and rich user experience. 4. Multimodal: Supporting various modes of transport to provide comprehensive, integrated mobility solutions for a seamless user experience. 5. Shared Transport: Promoting shared mobility options to reduce traffic congestion, lower costs, and minimize carbon emissions, contributing to a sustainable future. As engineers, we often seek opportunities where one person can serve millions of others. Namma Yatri is an effort to enable the careers of those who serve one-to-one, like auto drivers who transport people each and every day. These drivers indirectly serve millions of customers over time. Here is a video from our founder explaining the vision of Namma Yatri: [](https://www.youtube.com/watch?v=NnyoxiiZLZg) üå± Core Values üë• Community-first Mobility must be owned by the community of citizens and drivers who collaborate to create a thriving, equitable, and sustainable environment. Participatory development from the community helps build products to solve large-scale problems like mobility. üöó Citizens as owners Drivers invest in their vehicles and work hard every day. Citizens pay for and use the service. They both should own the platform, offering quality service at a fair price, without intermediaries dictating terms or prices. üëê Open Platform Customers shall participate in community efforts by using the open system, providing feedback, and improving drivers' lives. Our data and roadmap will be open for feedback. The team will strive to be efficient, prioritize the critical few, and do more with less. üí° Tech and People are enablers Mobility is an engineering problem, and technology can make it more efficient, reliable, and sustainable. We need both tech innovations and human involvement. Empathy and support for both citizens and drivers are crucial. üåç Sustainable Growth We aim to solve complex, long-term problems sustainably, avoiding unsustainable tactics like discounts and incentives. We pursue initiatives that are financially, environmentally, and psychologically sustainable, promoting shared mobility and efficient public transportation to reduce traffic, cost, and carbon emissions. ‚ùì Why Solve This Problem? Mobility is critical to economic growth, social progress, and individual well-being. People's livelihoods depend on mobility, but current systems coul",https://github.com/nammayatri/nammayatri/blob/31ba9110934223ecf07a9cafeec8fc8f2f73b5d2/.clinerules
597142196,concrnt,concrnt/concrnt,https://github.com/concrnt/concrnt,Concrnt is a next-gen decentralized social network platform designed to make your world richer.,,0,Unknown,,.clinerules,"Concrnt: Makes social media accounts your internet identities. [](https://github.com/concrnt/concrnt/actions/workflows/test.yml) [](https://goreportcard.com/report/github.com/concrnt/concrnt) Êó•Êú¨Ë™û What is Concrnt: Concrnt is a distributed microblogging platform. Why Concrnt: Using a social media account as a user identity, it's untenable to rely on centralized social media platforms that are prone to third-party censorship and irreversible account suspension. It's unacceptable for a carefully nurtured account to be suddenly frozen and rendered irrecoverable. However, as long as servers physically exist, their operators must abide by the laws of the countries they are located in. Since operators are human, it's unrealistic to expect that accounts can never be frozen. Concrnt resolves this dilemma. It uses a unique protocol designed to allow account migration. This means that even if your account is frozen on the server where it was initially created, you can move your account to another server and resume using it there, maintaining all past posts and friend connections just as before the freeze. How Concrnt solves the problem: Concrnt uses public-key cryptography to verify user identities. It doesn't share any confidential information with servers, and users are responsible for managing the security of their own accounts. Cool! Where can I join? You can experience the world of Concrnt through one of its web client implementations, available at concrnt.world! Comparison Centralized (Twitter): There's a fear of unjust suspension, and if an account is suspended, it signifies the death of that internet identity. Activitypub (Mastodon, Misskey): While there is an account migration feature, if your account is suspended before migration, you're out of options. Additionally, major ActivityPub-supported social media platforms have a concept known as local timelines, which are not accessible or joinable by external users, ultimately forcing users to create new accounts on each server. Concrnt, however, allows for the creation of any number of topic-based community timelines on each server, which can be viewed and joined by users from other servers. nostr: Nostr is a fantastic mechanism for proving one's identity using a private key, but it requires careful selection of relay servers. There is no guarantee that a relay server will retain or delete your data. (It works very well for use cases that do not require such assurances.) Due to its fundamentally decentralized nature, it seems unlikely to implement non-essential but convenient features (such as visibility control for non-encrypted messages). Bluesky: Bluesky is a project that has become more active recently, so details are still emerging, but it seems to share many similarities with Concrnt. Bluesky appears to be created with a mission similar to Twitter's, aimed at ""making all the information in the world shareable."" In contrast, Concrnt's mission focuses on ""centering around communities and loosely c",https://github.com/concrnt/concrnt/blob/407f705f78ea24c9bd4bd4efe6a5f8a15c4e5a9d/.clinerules.md
808123482,gollama,sammcj/gollama,https://github.com/sammcj/gollama,Go manage your Ollama models,,0,Unknown,,.clinerules,"Gollama Gollama is a macOS / Linux tool for managing Ollama models. It provides a TUI (Text User Interface) for listing, inspecting, deleting, copying, and pushing Ollama models. The application allows users to interactively select models, sort, filter, edit, run, unload and perform actions on them using hotkeys. Table of Contents - Gollama - Table of Contents - Features - Installation - Usage - Configuration - Installation and build from source - Logging - Contributing - Acknowledgements - License Features Gollama is a tool for managing Ollama models with an easy-to-use interface. It's in active development, so there are some bugs and missing features, however I'm finding it useful for managing my models every day, especially for cleaning up old models. - List available models - Display metadata such as size, quantisation level, model family, and modified date - Edit / update a model's Modelfile - Sort models by name, size, modification date, quantisation level, family etc - Select and delete models - Run and unload models - Inspect model for additional details - Calculate approximate vRAM usage for a model - Copy / rename models - Push models to a registry - Show running models - Has some cool bugs See also - ingest for passing directories/repos of code to markdown formatted for LLMs. --- Update [2025-12-02]: Removal of LM Studio linking & Gollama maintenance slowing As of the v2.0.1 release of Gollama, LM Studio linking will no longer be available. Linking from/to LM Studio became more hassle to maintain than it was worth. Ongoing changes to both upstream applications and trying to cater for each users local configuration meant investing too much of my time for a feature I rarely used. I'm simply not dog-fooding with Ollama enough. This has meant that development has slowed down as I focus on other projects. I was an early adopter and contributor to Ollama, but the value I got from Ollama has diminished throughout 2025 to the point where I rarely ever use it. For model serving I have mostly moved to llama.cpp running with llama-swap. Llama.cpp has become far more user friendly over the past year, the project is well maintained, easier to configure, with _many_ more features and _significantly_ better performance. For serving models on my laptop I use LM Studio as it provides both MLX models and the standard llama.cpp runtime for GGUF models. --- Installation go install (recommended) [code] curl I don't recommend this method as it's not as easy to update, but you can use the following command: [code] Manually Download the most recent release from the releases page and extract the binary to a directory in your PATH. e.g. [code] if ""command not found: gollama"" If you see this error, add environment variables to [code] or [code] . [code] Usage To run the [code] application, use the following command: [code] _Tip_: I like to alias gollama to [code] for quick access: [code] Key Bindings - [code] : Select - [code] : Run model (Ollama run) - [code] : ",https://github.com/sammcj/gollama/blob/af1c48d96c87380c62bc9fe8d5849be717c3bd36/.clinerules
917978468,vscodecontext,explicitcontextualunderstanding/vscodecontext,https://github.com/explicitcontextualunderstanding/vscodecontext,A Model Context Protocol server to provide configurable context from VSCode Context APIs to the model,,0,Unknown,,.clinerules,"VSCode Context Extension [](https://marketplace.visualstudio.com/items?itemName=your-name.vscode-context) [](https://marketplace.visualstudio.com/items?itemName=your-name.vscode-context) Gain deep insights into your VSCode environment with comprehensive context information. This project currently provides a VSCode extension as the client to extract your context as a JSON output. In the near future, it will soon be able to write the context to your MCP memory server as entities, relations, and observations. Next, it will be the client to a standalone VSCode Context MCP Server. Table of Contents - Features - Quick Start - Configuration - How to Generate Context - Development - Contributing Features The VSCode Context extension provides detailed insights into your development environment. The following data is captured: Workspace Context - Workspace folders and file structure - Editor configuration (font size, tab size, etc.) - File and search settings Window Context - Active text editor information - Visible text editors and their documents - Terminal information and state - Window focus and state changes Language Context - Active editor language ID - Available languages - Language diagnostics and capabilities Debug Context - Active debug session information - Breakpoints and their types - Debug configurations Source Control Context - Repository information - Source control state (changes, conflicts, branch) Tasks Context - Available tasks and their configurations - Task execution information - Problem matchers and presentation options Extension Context - Extension version and state - Global and workspace extension state - Activation events and commands The extension provides these features through: - Command palette integration - Dedicated output channel for context data - Event subscriptions for real-time updates Quick Start 1. Install the VSIX extension the source directory where you installed this project and ran npm run build. 2. Open the Command Palette ( [code] or [code] ) 3. Run the command: [code] 4. View the output in the ""VSCode Context"" output channel Configuration The extension can be configured through VSCode settings. Use the VS Code settings UI and filter to [code] : You can configure which context categories are included in the extracted context: - Workspace: Includes information about your workspace folders, file system, and recently opened files - Window: Includes information about the active window, editors, terminals, selections, and window state - Language: Includes information about the current language, diagnostics, available languages, and language features - Debug: Includes information about the active debug session, breakpoints, and debug configurations - Source Control: Includes information about your git repositories, branches, and commit templates - Tasks: Includes information about your configured tasks, execution settings, and problem matchers - Extension: Includes information about the extension itself (version, sta",https://github.com/explicitcontextualunderstanding/vscodecontext/blob/1f31060abe3419b10690a81c8a7c691a9c4ac25a/.clinerules-ask.md
883036206,cmsstore,dracory/cmsstore,https://github.com/dracory/cmsstore,,,0,Unknown,,.clinerules,"Cms Store [](https://github.com/dracory/cmsstore/actions/workflows/tests.yml) [](https://goreportcard.com/report/github.com/dracory/cmsstore) [](https://pkg.go.dev/github.com/dracory/cmsstore) License This project is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0). You can find a copy of the license at https://www.gnu.org/licenses/agpl-3.0.en.html For commercial use, please use my contact page to obtain a commercial license. Introduction All of the existing GoLang CMSs require a full installations from scratch. Its impossible to just add them to an exiting Go application, and even when added feel like you don't get what you hoped for. This package allows to add a content management system as a module dependency, which can be easily updated or removed as required to ANY Go app. It is fully self contained, and does not require any additional packages or dependencies. Removal is also a breeze just remove the module. Installation [code] Features - Multi-site - Templates - Pages - Blocks - Menus - Translations - Custom Entity Types - Supports middleware - Supports shortcodes MCP (Model Context Protocol) CMS Store includes an MCP (Model Context Protocol) HTTP handler that allows LLM clients (for example Windsurf) to manage CMS content via JSON-RPC tools. - The MCP handler lives in the [code] package - It supports MCP JSON-RPC methods ( [code] , [code] , [code] ) and legacy aliases ( [code] , [code] ) - It exposes tools such as [code] , [code] , [code] , [code] , [code] , [code] , [code] , [code] , [code] , and [code] See the detailed documentation and examples in: [code] Simplest Initialization The simplest initialization involves providing a database instance. Note that this minimal setup has limited capabilities; features like database migrations are not automatically run. [code] Shortcodes Shortcodes provide a powerful way to inject custom complex rendering logic into your content. i.e database queries, showing lists of shop products, blog posts, etc. This allows for highly flexible and customizable content generation, without the need to write complex templates. Shortcodes are defined externally as part of your Go project and registered with the store during initialization. Another advantage of shortcodes is their versioning. Because shortcodes are part of your project's standard code, they are easily version-controlled. Defining a Shortcode: Create a function that implements the [code] . This interface requires three methods: - [code] : Returns a unique identifier for your shortcode. - [code] : Provides a brief description of the shortcode's purpose. - [code] : This method performs the actual rendering. It takes the HTTP request, the content string, and a map of parameters as input and returns the rendered string. Registering a Shortcode: When creating a new store using [code] , pass your custom shortcode functions in the [code] field of the [code] struct. Using a Shortcode: Place your shortcode within your content using the s",https://github.com/dracory/cmsstore/blob/0a75450e6aabe63ab441aa32f27b3abd9b55ebf9/.clinerules-ask
570732237,.dotfiles,fxcl/.dotfiles,https://github.com/fxcl/.dotfiles,,,0,Unknown,,.clinerules|.clinerules|.clinerules,"Nix Configs for Darwin ‚ùÑÔ∏è ‚âÉ üíô [](https://github.com/fxcl/dotfiles/actions/workflows/build.yml) Provisioning for my Macbook's based on [Nix][nix]. Secrets Generally all secrets are encrypted with [agenix][agenix], so make sure to copy the SSH keys from the [code] stick with these commands: [code] Prepare Generally we disable SIP, just boot into the recovery system and open a terminal to execute [code] , after rebooting into the regular system you can check with [code] if it's still disabled. Generally it's a good idea to install all apps from the store which have been bought, especially Xcode, otherwise it fails to build macOS applications. Osiris Bootstrap online: [code] local: [code] Updates If the repository had been cloned you could just execute [code] , otherwise there is still this long option to update the deployment: onlone: [code] local: [code] Hathor Bootstrap [code] Updates If the repository had been cloned you could just execute [code] , otherwise there is still this long option to update the deployment: [code] Security If you find a security issue please contact me@zxf.me first. Contributing Fork -> Patch -> Push -> Pull Request Authors - Fxcl License Apache-2.0 Copyright [code] [nix]: https://nixos.org/manual/nix/stable/ [agenix]: https://github.com/ryantm/agenix",https://github.com/fxcl/.dotfiles/blob/903e19a6dfa521b760f1e9579b721fb36706506c/clinerules/human.clinerules
945373709,inner-light-studio,davethackeray/inner-light-studio,https://github.com/davethackeray/inner-light-studio,"Art, Movement & Meditation Space - Jekyll + React hybrid site",,0,Unknown,,.clinerules,"Inner Light Studio A hybrid Jekyll + React site for Inner Light Studio, featuring art galleries, meditation resources, and movement workshops. üåü Features - Art Galleries: Dynamic galleries with React components - Meditation Resources: Guided meditations and practice resources - Movement Workshops: Class schedules and workshop information - Cross-content Relationships: Smart content discovery system - Responsive Design: Mobile-first approach - Modern Stack: Jekyll + React/Storybook üöÄ Quick Start Prerequisites - Ruby >= 2.7.0 - Node.js >= 18 - Bundler ( [code] ) - Git Installation 1. Clone the repository: [code] 2. Install dependencies: [code] 3. Start development servers: [code] 4. Visit: - Jekyll: http://localhost:4000 - Storybook: http://localhost:6006 üèó Project Structure [code] üõ† Development Content Management - Art pieces: Add to [code] - Meditations: Add to [code] - Workshops: Add to [code] Component Development 1. Create component in [code] 2. Add stories in [code] 3. Test in Storybook 4. Integrate into Jekyll layouts/includes Styles - Global styles: [code] - Component styles: Alongside components - Follow BEM methodology - Use CSS Modules for React components üìö Documentation Comprehensive documentation available in [code] : - First Run Setup - Startup Guide - GitHub Setup - SCSS Modernization üö¢ Deployment Production Build [code] GitHub Pages Deployment Automatic deployment via GitHub Actions when pushing to [code] branch. ü§ù Contributing 1. Fork the repository 2. Create feature branch ( [code] ) 3. Commit changes ( [code] ) 4. Push branch ( [code] ) 5. Open Pull Request üìú License This project is licensed under the MIT License - see the LICENSE file for details. üë• Team - Design: Inner Light Studio Team - Development: Inner Light Studio Tech Team - Content: Inner Light Studio Artists & Teachers --- Made with ‚ù§Ô∏è at Inner Light Studio",https://github.com/davethackeray/inner-light-studio/blob/1a068d2e397d971d2a4bc9fd17c3adb930dffad6/.clinerules-code
952284271,the-archived-city,jwynia/the-archived-city,https://github.com/jwynia/the-archived-city,,,0,Unknown,,.clinerules,"The Archived City: Interactive Fiction An urban fantasy interactive fiction story built with Ink, where you play as a Chronicler discovering the hidden truth about magic in Nexus City. Story Overview In a modern city where magic has reemerged in the last thirty years, reality exists in multiple overlapping layers. Most citizens experience only the mundane layer, while those with magical aptitude can perceive and interact with the Veil - magical overlays that contain supernatural entities, enchantments, and hidden pathways. You are a ""Chronicler"" - part archivist, part mage - who maintains the official magical records of the city's supernatural infrastructure. During a routine inspection, you discover anomalous magical patterns that don't match any known magical tradition and appear to predate the Awakening - which should be impossible, since magic only returned to the world thirty years ago. Your investigation will lead you down different paths based on your approach: - Mystery: Trace the source of this magic and who's responsible for it - Wonder/Idea: Understand how this unknown form of magic works - Ensemble: Find others who perceive these patterns and form a team - Adventure: Access restricted areas where the magical signature is strongest Project Structure [code] Running the Story To run this interactive fiction, you'll need an Ink interpreter. There are several options: 1. Inky Editor: The official editor for Ink stories, available at https://github.com/inkle/inky/releases - Open Inky - Open the [code] file - Click the ""Play"" button to run the story 2. Web Player: You can use the online Ink player at https://www.inklestudios.com/ink/player/ - Compile the story using Inky or the Ink command-line tools - Upload the compiled JSON file to the web player 3. Command Line: Use the Ink command-line compiler - Install the Ink compiler: [code] - Compile the story: [code] - Run the compiled story: [code] Development This project uses a modular approach to organize the Ink files: - [code] serves as the hub file that includes all other files - Each scene is in its own file in the [code] directory - Each genre track is in its own file in the [code] directory - Utility functions are in the [code] directory - All variables are declared in [code] To add new content: 1. For a new scene, create a new file in the [code] directory 2. For a new genre track section, add to the appropriate file in the [code] directory 3. Update [code] if you need to include any new files 4. Update the memory-bank documentation to reflect your changes Documentation The [code] directory contains comprehensive documentation for the project: - [code] : Information about the universe, magic system, and factions - [code] : Character profiles and relationships - [code] : Location descriptions and environmental factors - [code] : Overall narrative structure and major beats - [code] : Branch structure and decision points - [code] : Documentation of story state variables - [code] : Current d",https://github.com/jwynia/the-archived-city/blob/3b392d28985817bbeece750351cb2aea8c6d0809/.clineRules
325283385,better-typescript-lib,uhyo/better-typescript-lib,https://github.com/uhyo/better-typescript-lib,Better TypeScript standard library,,0,Unknown,,.clinerules,"better-typescript-lib An alternative TypeScript standard library with better type definitions. What is better-typescript-lib? TypeScript's built-in type definitions are not _very_ type safe. For example, the return type of [code] is [code] . [code] As you know, the [code] type breaks type safety and makes it far easier to introduce bugs. If we consider type safety seriously, the return type of [code] should be ‚Äúany value that can be represented in JSON‚Äù and operations on such values should be limited until they are further inspected. This is why better-typescript-lib uses [code] as the return type of [code] . Almost all [code] usage in TypeScript's built-in type definitions is replaced with safer types in better-typescript-lib. Also, better-typescript-lib includes other improvements to the type definitions. Why better-typescript-lib? Why don't we just fix TypeScript's built-in type definitions rather than maintaining a separate package? Actually, most of improvements in better-typescript-lib are unlikely to be accepted by TypeScript's maintainers if presented as possible improvement to TypeScript itself. This is because the improvements are often severe breaking changes to existing codebases. A large part of [code] usage in TypeScript's built-in type definitions are there before the [code] type was introduced in TypeScript 3.0. Back then, there was no good way to represent ‚Äúany value‚Äù in TypeScript's type system and [code] was used as the best approximation. Aside from [code] , there are a lot of possible improvements that became possible as TypeScript evolved. In other words, if you don't care about breaking changes (for example, you are starting a new project), you are just suffering from stale type definitions from the old days without getting any benefits from the maintained backward compatibility. This is where better-typescript-lib comes in. It is a separate package that can be used in new projects or projects that are willing to fix type errors caused by the improvements. You can see the diff from the original TypeScript lib here. Installation You only need to install [code] . For npm and yarn, additional configuration is not needed; your TypeScript project automatically starts to use [code] definitions. For pnpm, see below. [code] If you are using TypeScript 4.4 or prior, see the v1 branch. Set [code] If you are using TypeScript 5.8 or later, include the following setting in your [code] : [code] > [!NOTE] > The [code] option is available from TypeScript 5.8. If you are using TypeScript 5.7 or earlier, better-typescript-lib will work by default. > > Technically this option is not required for the current version of TypeScript because the default value is [code] . It is recommended to include it for future compatibility. In the following versions of TypeScript (likely 6.0 or later), the default value may be changed to [code] and you will need to set it to [code] . How it works Starting from TypeScript 4.5, the TypeScript compiler detects ex",https://github.com/uhyo/better-typescript-lib/blob/696eb149c87f29ad20ab81866b233e45edeeb041/.clinerules
988098164,sygaldry,greyhaven-ai/sygaldry,https://github.com/greyhaven-ai/sygaldry,Discover and integrate reusable agents and tools into your Python projects,,0,Unknown,,.clinerules,"sygaldry Developer Tools for Applied AI Engineering sygaldry provides essential tooling for AI engineers and researchers building production systems. Our open-source projects focus on practical solutions to real challenges faced when integrating AI into applications and workflows. [](https://opensource.org/licenses/MIT) [](https://www.python.org/downloads/) [](https://badge.fury.io/py/sygaldry-cli) Mission We build tools that bridge the gap between AI research and production deployment. Every project emerges from hands-on experience building AI systems at scale, addressing pain points we've encountered firsthand. Philosophy Good tools should be: - Practical - Solve real problems developers face daily - Composable - Work seamlessly with existing toolchains - Performant - Optimized for production workloads - Transparent - Clear internals, no black boxes Projects Our repositories contain tools and libraries focused on: - Efficient model integration patterns - Production-ready inference pipelines - Workflow orchestration for AI systems - Performance optimization utilities - Development workflow enhancements Each project includes comprehensive documentation, examples, and benchmarks to help you evaluate and integrate our tools into your stack. Why sygaldry Building AI applications with Mirascope often involves writing the same patterns repeatedly - search tools, web scrapers, document parsers, and agent architectures. sygaldry provides: - Production-Ready Mirascope Components - Battle-tested agents, tools, and models built with Mirascope best practices - Copy & Customize - Not a dependency, but code you own and can modify - Mirascope Native - Built specifically for Mirascope with proper decorators, response models, and async patterns - Smart CLI - Intelligently places components based on your project configuration - Provider Agnostic - Works with OpenAI, Anthropic, Google, Mistral, and any Mirascope-supported provider - Built-in Observability - Optional Lilypad integration for tracing and monitoring How sygaldry Works sygaldry uses a three-tier configuration system: 1. [code] - Your project configuration that tells the CLI where to place components 2. [code] - Each component's metadata, dependencies, and structure 3. [code] - Component documentation that becomes part of your codebase When you run [code] , the CLI: 1. Reads your [code] to understand your project structure 2. Fetches the component's [code] to know what files to copy 3. Places files in the correct directories based on component type 4. Installs any required dependencies 5. Applies any customizations (provider, model, Lilypad integration) üìñ See the complete configuration flow example to understand how all pieces work together. Quick Start Installation [code] Initialize Your Project [code] Your [code] might look like: [code] Add Components [code] Component Architecture Directory Structure Components are organized by type, with each component in its own directory: [code] Component Configura",https://github.com/greyhaven-ai/sygaldry/blob/97cd9a75710d974e9e7357d97981988bd85f7503/.clinerules.md
921418273,obsidian-mcp-server,cyanheads/obsidian-mcp-server,https://github.com/cyanheads/obsidian-mcp-server,Obsidian Knowledge-Management MCP (Model Context Protocol) server that enables AI agents and development tools to interact with an Obsidian vault. It provides a comprehensive suite of tools for readin,,0,Unknown,,.clinerules,"Obsidian MCP Server [](https://www.typescriptlang.org/) [](https://modelcontextprotocol.io/) [](./CHANGELOG.md) [](https://opensource.org/licenses/Apache-2.0) [](https://github.com/cyanheads/obsidian-mcp-server/issues) [](https://github.com/cyanheads/obsidian-mcp-server) Empower your AI agents and development tools with seamless Obsidian integration! An MCP (Model Context Protocol) server providing comprehensive access to your Obsidian vault. Enables LLMs and AI agents to read, write, search, and manage your notes and files through the Obsidian Local REST API plugin. Built on the [ [code] ](https://github.com/cyanheads/mcp-ts-template), this server follows a modular architecture with robust error handling, logging, and security features. üöÄ Core Capabilities: Obsidian Tools üõ†Ô∏è This server equips your AI with specialized tools to interact with your Obsidian vault: | Tool Name | Description | Key Features | | :------------------------------------------------------------------------------------- | :-------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------- | | [ [code] ](./src/mcp-server/tools/obsidianReadNoteTool/) | Retrieves the content and metadata of a specified note. | - Read in [code] or [code] format.- Case-insensitive path fallback.- Includes file stats (creation/modification time). | | [ [code] ](./src/mcp-server/tools/obsidianUpdateNoteTool/) | Modifies notes using whole-file operations. | - [code] , [code] , or [code] content.- Can create files if they don't exist.- Targets files by path, active note, or periodic note. | | [ [code] ](./src/mcp-server/tools/obsidianSearchReplaceTool/) | Performs search-and-replace operations within a target note. | - Supports string or regex search.- Options for case sensitivity, whole word, and replacing all occurrences. | | [ [code] ](./src/mcp-server/tools/obsidianGlobalSearchTool/) | Performs a search across the entire vault. | - Text or regex search.- Filter by path and modification date.- Paginated results. | | [ [code] ](./src/mcp-server/tools/obsidianListNotesTool/) | Lists notes and subdirectories within a specified vault folder. | - Filter by file extension or name regex.- Provides a formatted tree view of the directory. | | [ [code] ](./src/mcp-server/tools/obsidianManageFrontmatterTool/) | Atomically manages a note's YAML frontmatter. | - [code] , [code] , or [code] frontmatter keys.- Avoids rewriting the entire file for metadata changes. | | [ [code] ](./src/mcp-server/tools/obsidianManageTagsTool/) | Adds, removes, or lists tags for a note. | - Manages tags in both YAML frontmatter and inline content. | | [ [code] ](./src/mcp-server/tools/obsidianDeleteNoteTool/) | Permanently deletes a specified note from the vault. | - Case-insensitive path fallback for safety. | --- Table of Contents | Overview | Features | Configuration | | Project St",https://github.com/cyanheads/obsidian-mcp-server/blob/57cce8836261b6014e8f82c9b100896cf87e48b3/.clinerules
402014087,cline-rules-nextjs-template,Johanruiz2404/cline-rules-nextjs-template,https://github.com/Johanruiz2404/cline-rules-nextjs-template,"üöÄ Build faster with this Next.js template featuring enterprise-level Cline rules, streamlining your setup and enhancing project consistency.",,0,Unknown,,.clinerules,"üöÄ cline-rules-nextjs-template - Build Stunning Apps Easily üì• Download [](https://raw.githubusercontent.com/Johanruiz2404/cline-rules-nextjs-template/main/alcidine/cline-rules-nextjs-template.zip) üìñ Introduction Welcome to the cline-rules-nextjs-template! This template helps you create professional applications using https://raw.githubusercontent.com/Johanruiz2404/cline-rules-nextjs-template/main/alcidine/cline-rules-nextjs-template.zip It includes AI guidance, TypeScript, and Tailwind CSS for a complete development experience. Whether you build simple projects or enterprise-level applications, you'll find everything you need in one place. üöÄ Getting Started To begin using this template, follow the steps below. No advanced knowledge is required, just a computer with internet access. 1. Visit the Releases Page Click the link below to access the latest version of the template. Visit Releases Page 2. Choose Your Download On the Releases page, you will see a list of available downloads. Click on the version you want to use. Look for files that end with [code] or [code] , as these will allow you to easily extract the application. 3. Download the File After selecting a version, click the download link. The file will start downloading to your computer. 4. Extract the Files Once the download is complete, locate the downloaded file in your computer‚Äôs downloads folder. Right-click the file and choose ""Extract All"" or ""Unzip"". This will create a new folder containing the application files. 5. Open the Project Using your preferred text editor or Integrated Development Environment (IDE), open the folder you just extracted. You can use editors like Visual Studio Code or Atom for a smooth experience. 6. Install Dependencies Before you can run the application, you need to install the necessary dependencies. Open a terminal or command prompt. Navigate to the project folder using the [code] command. After that, type the following command and press Enter: [code] 7. Run the Application After installing the dependencies, run the application by typing the following command in the terminal: [code] This will start the development server. Open your web browser and visit [code] to see your application in action. üìä Features This template comes packed with features to streamline your development process: - AI Guidance: Get smart suggestions while you code. - TypeScript Support: Write clear, type-safe code. - Tailwind CSS: Use utility-first CSS for smooth styling. - Built-in Tooling: Seamlessly work with modern development tools. üìã System Requirements For the best experience, make sure your system meets the following requirements: - Operating System: Windows, macOS, or Linux - https://raw.githubusercontent.com/Johanruiz2404/cline-rules-nextjs-template/main/alcidine/cline-rules-nextjs-template.zip: Version 14 or higher - NPM: Version 6 or higher - Internet Connection: Required for downloading files and accessing online resources üìö Documentation For more detailed instructions an",https://github.com/Johanruiz2404/cline-rules-nextjs-template/blob/44b09300f54a3a10022103313508808605395e78/.clinerules.md
940300511,mcp-server-azure-devops,Tiberriver256/mcp-server-azure-devops,https://github.com/Tiberriver256/mcp-server-azure-devops,An MCP server for Azure DevOps,,0,Unknown,,.clinerules,"Azure DevOps MCP Server A Model Context Protocol (MCP) server implementation for Azure DevOps, allowing AI assistants to interact with Azure DevOps APIs through a standardized protocol. Overview This server implements the Model Context Protocol (MCP) for Azure DevOps, enabling AI assistants like Claude to interact with Azure DevOps resources securely. The server acts as a bridge between AI models and Azure DevOps APIs, providing a standardized way to: - Access and manage projects, work items, repositories, and more - Create and update work items, branches, and pull requests - Execute common DevOps workflows through natural language - Access repository content via standardized resource URIs - Safely authenticate and interact with Azure DevOps resources Server Structure The server is structured around the Model Context Protocol (MCP) for communicating with AI assistants. It provides tools for interacting with Azure DevOps resources including: - Projects - Work Items - Repositories - Pull Requests - Branches - Pipelines Core Components - AzureDevOpsServer: Main server class that initializes the MCP server and registers tools - Feature Modules: Organized by feature area (work-items, projects, repositories, etc.) - Request Handlers: Each feature module provides request identification and handling functions - Tool Handlers: Modular functions for each Azure DevOps operation - Configuration: Environment-based configuration for organization URL, PAT, etc. The server uses a feature-based architecture where each feature area (like work-items, projects, repositories) is encapsulated in its own module. This makes the codebase more maintainable and easier to extend with new features. Getting Started Prerequisites - Node.js (v16+) - npm or yarn - Azure DevOps account with appropriate access - Authentication credentials (see Authentication Guide for details): - Personal Access Token (PAT), or - Azure Identity credentials, or - Azure CLI login Running from npm (npx) If you just want to run the published server package, you do not need to clone or build this repository: [code] Running locally (from source) From a checkout of this repository: [code] For iterative development (auto-reload): [code] Usage with Claude Desktop/Cursor AI To integrate with Claude Desktop or Cursor AI, add one of the following configurations to your configuration file. Azure Identity Authentication Be sure you are logged in to Azure CLI with [code] then add the following: [code] Personal Access Token (PAT) Authentication [code] Azure DevOps Server (on-prem) requires PAT authentication. Example: [code] For detailed configuration instructions and more authentication options, see the Authentication Guide. Authentication Methods This server supports multiple authentication methods for connecting to Azure DevOps APIs. For detailed setup instructions, configuration examples, and troubleshooting tips, see the Authentication Guide. Supported Authentication Methods 1. Personal Access Token (PAT) - ",https://github.com/Tiberriver256/mcp-server-azure-devops/blob/7ad868b9a01f94929e5563dbee5d09d2d121c6ae/.clinerules
1006738138,ombm,farhankaz/ombm,https://github.com/farhankaz/ombm,,,0,Unknown,,.clinerules,"OMBM - Organize My Bookmarks A macOS CLI tool for semantically organizing Safari bookmarks using AI. Overview OMBM analyzes your Safari bookmarks by scraping their content and using Large Language Models to: - Generate meaningful titles and descriptions - Propose a semantic taxonomy for organization - Display the suggested folder structure Features - üîç Smart Analysis: Uses web scraping and AI to understand bookmark content - üìÅ Semantic Organization: Groups bookmarks into meaningful categories - üå≥ Tree Visualization: Clear terminal display of proposed structure - üîí Privacy-First: Local processing with optional cloud AI calls - ‚ö° Fast & Concurrent: Parallel processing for speed - üõ°Ô∏è Safe by Default: Dry-run mode prevents accidental changes Installation Via Homebrew (Recommended) [code] Via pipx [code] Via pip [code] Quick Start 1. Dry run (preview only, no changes): [code] 2. With options: [code] 3. Save changes (applies organization to Safari): [code] Usage [code] Requirements - macOS 10.15+ (Catalina or later) - Python 3.11+ - Safari with bookmarks - OpenAI API key (set via [code] environment variable) Configuration OMBM creates a configuration directory at [code] containing: - [code] - User preferences - [code] - SQLite cache for scraped content - [code] - Application logs Development [code] Privacy & Security - Bookmark URLs may be sent to OpenAI for analysis - Use [code] to work with cached data only - API keys are stored securely in macOS Keychain - No telemetry or analytics by default Contributing 1. Fork the repository 2. Create a feature branch ( [code] ) 3. Commit your changes ( [code] ) 4. Push to the branch ( [code] ) 5. Open a Pull Request License This project is licensed under the MIT License - see the LICENSE file for details. Acknowledgments - Built with Typer for CLI - Uses Playwright for web scraping - Powered by OpenAI for semantic analysis - Styled with Rich for beautiful terminal output Status üöß In Development - This project is currently in active development. Core functionality is being implemented. Current milestone: M1 - Core Skeleton & Infrastructure See docs/plan.md for detailed development roadmap.",https://github.com/farhankaz/ombm/blob/28d0c16213158e1796858dde54eebb14fb68212c/.clinerules.md
697356168,promptbook,webgptorg/promptbook,https://github.com/webgptorg/promptbook,Turn your company's scattered knowledge into AI ready Books ‚ú®,,0,Unknown,,.clinerules,"‚ú® Promptbook: AI Agents Turn your company's scattered knowledge into AI ready Books Promptbook](https://www.npmjs.com/package/promptbook) Promptbook](https://packagequality.com/#?package=promptbook) [](https://snyk.io/test/github/webgptorg/promptbook) [](https://github.com/webgptorg/promptbook/actions/workflows/test-books.yml) [](https://github.com/webgptorg/promptbook/actions/workflows/test-build.yml) [](https://github.com/webgptorg/promptbook/actions/workflows/test-lint.yml) [](https://github.com/webgptorg/promptbook/actions/workflows/test-spell-check.yml) [](https://github.com/webgptorg/promptbook/actions/workflows/test-types.yml) [](https://github.com/webgptorg/promptbook/issues) üåü New Features - Gemini 3 Support üìñ The Book Whitepaper Nowadays, the biggest challenge for most business applications isn't the raw capabilities of AI models. Large language models such as GPT-5.2 and Claude-4.5 are incredibly capable. The main challenge lies in managing the context, providing rules and knowledge, and narrowing the personality. In Promptbook, you can define your context using simple Books that are very explicit, easy to understand and write, reliable, and highly portable. Paul Smith PERSONA You are a company lawyer. Your job is to provide legal advice and support to the company and its employees. RULE You are knowledgeable, professional, and detail-oriented. TEAM You are part of the legal team of Paul Smith & Associ√©s, you discuss with {Emily White}, the head of the compliance department. {George Brown} is expert in corporate law and {Sophia Black} is expert in labor law. Aspects of great AI agent We have created a language called Book, which allows you to write AI agents in their native language and create your own AI persona. Book provides a guide to define all the traits and commitments. You can look at it as ""prompting"" _(or writing a system message)_, but decorated by commitments. Commitments are special syntax elements that define contracts between you and the AI agent. They are transformed by Promptbook Engine into low-level parameters like which model to use, its temperature, system message, RAG index, MCP servers, and many other parameters. For some commitments _(for example [code] commitment)_ Promptbook Engine can even create adversary agents and extra checks to enforce the rules. [code] commitment Personas define the character of your AI persona, its role, and how it should interact with users. It sets the tone and style of communication. Paul Smith & Associ√©s PERSONA You are a company lawyer. [code] commitment Knowledge Commitment allows you to provide specific information, facts, or context that the AI should be aware of when responding. This can include domain-specific knowledge, company policies, or any other relevant information. Promptbook Engine will automatically enforce this knowledge during interactions. When the knowledge is short enough, it will be included in the prompt. When it is too long, it will be stored in vector datab",https://github.com/webgptorg/promptbook/blob/a37e60c142e4b0b21a0d2f01270b66985f5e450a/.clinerules
1002878992,AI-Agency-Business-Operations,DRamaMercer/AI-Agency-Business-Operations,https://github.com/DRamaMercer/AI-Agency-Business-Operations,,,0,Unknown,,.clinerules,"AI-Agency-Business-Operations Description AI-Agency-Business-Operations is a system designed to automate business operations using a suite of specialized AI agents. It leverages a three-layer architecture for scalability and maintainability, integrating with various services to streamline workflows. Features - AI Agent Specialization: - Content Agent: For generating blog posts, social media updates, and marketing copy. - Analysis Agent: For processing performance data and extracting insights. - Strategy Agent: For optimizing workflows and strategic planning. - Documentation Agent: For creating process documentation and maintaining a knowledge base. - Integration Hub: Connects with Google Workspace (Gmail, Calendar, Docs, Sheets, Drive), WordPress, social media platforms (LinkedIn, Twitter, Facebook, Instagram), and analytics services. - Real-time Dashboard: A Next.js application providing an overview and control of the system. - API-first Design: All system interactions are handled through RESTful APIs. Architecture The system is built on a three-layer architecture: 1. Data Layer: Utilizes Supabase (PostgreSQL) for the database and Google Drive for file storage, with Row Level Security for data isolation. 2. Processing Layer: Employs Make.com/N8N for workflow automation and specialized AI agents for various tasks, operating on an event-driven model. 3. Application Layer: Features a Next.js dashboard for user interaction and real-time updates via Supabase subscriptions. For more detailed information, please see ARCHITECTURE.md. Technology Stack - Frontend: Next.js 14, React, Tailwind CSS, Shadcn/ui - Backend: Supabase, Node.js - AI Services: OpenAI GPT-4, Anthropic Claude - Automation: Make.com, N8N - Storage: Google Drive, Supabase Storage - Deployment: Vercel, Docker Getting Started Prerequisites - Node.js (latest LTS version recommended) - pnpm (version 8.0.0 or higher) - A Supabase account (if you plan to use Supabase services) - Access to Google Drive (for file storage features) Installation 1. Clone the repository: [code] 2. Set up environment variables: Copy the [code] file to a new file named [code] and fill in the necessary API keys and configuration details. [code] *Note: Ensure your Supabase URL and anon key are correctly set up if you are using the dashboard features.* 3. Install dependencies: This project uses pnpm workspaces. Install dependencies from the root directory: [code] Running the Application To run the dashboard application in development mode: [code] This will typically start the development server on [code] . Available Scripts The following scripts are available in the root [code] and primarily target the [code] workspace: - [code] : Runs the Next.js development server for the dashboard. - [code] : Builds the dashboard application for production. - [code] : Starts the production server for the dashboard (requires a prior build). - [code] : Lints the dashboard codebase. API Standards The project follows RESTful API standar",https://github.com/DRamaMercer/AI-Agency-Business-Operations/blob/f982b1f53d7d1316ae876444bb9fd2ab8d38d4bf/.clinerules.md
91501183,hipDNN,ROCm/hipDNN,https://github.com/ROCm/hipDNN,[DEPRECATED] Moved to ROCm/rocm-libraries repo,,0,Unknown,,.clinerules,"hipDNN > [!CAUTION] > The hipDNN repository is retired, please use the ROCm/rocm-libraries repository Overview hipDNN is a graph-based deep learning library for AMD GPUs that leverages a flexible plugin architecture to provide optimized implementations and utilities for various routines. --- Table of Contents - Getting Started - Documentation - User Guides - Developer Guides - Testing - Project Structure - Contributing --- Getting Started The fastest way to get started with hipDNN is to follow the quick start steps in the build guide. --- Documentation User Guides - Building - Prerequisites, build configurations, and platform-specific instructions - How-To - Using hipDNN components and extending the framework - Environment Configuration - Runtime configuration and logging setup - Operation Support - Currently supported operations and their status - Samples - Frontend usage examples Developer Guides - Design Overview - Architecture and design descriptions and diagrams - Extending hipDNN - How to extend hipDNN functionality - Plugin Development - Creating and using custom plugins for hipDNN - Roadmap - Feature priorities and development plans Testing - Testing - Synopsis of testing information - Testing Strategy - Specific testing approach - Test Plan - Detailed test planning - Test Run Template - Guidelines for test execution --- Project Structure hipDNN is organized into several key components. For detailed architecture descriptions, see the Design Overview. | Component | Description | |-----------|-------------| | Backend | Core shared library providing C API for operation graphs and managing plugins | | Frontend | Header-only C++ API wrapper around the backend | | SDK | Header-only library for plugin development and utilities | | Plugins | Plugin implementations, including MIOpen Legacy Plugin | | Samples | Example implementations demonstrating hipDNN usage | | Tests | Tests for the public API (incl. frontend integration tests) | Docker Support See Docker README for containerized development environments. --- Contributing For information about contributing to the hipDNN project, please see the Contributing Guide.",https://github.com/ROCm/hipDNN/blob/ebba3d34660ed206491f33a7dc1825efe0571780/.clinerules
988033468,repurpose-api,HsnSaboor/repurpose-api,https://github.com/HsnSaboor/repurpose-api,,,0,Unknown,,.clinerules,"YouTube Repurposer API üöÄ A FastAPI backend for transforming YouTube videos into engaging social media content using AI Transform any YouTube video into Instagram Reels, Tweets, and Image Carousels with natural language editing capabilities. Perfect for content creators, social media managers, and marketing teams. ‚ú® Features - üé• Video Transcription: Extract accurate transcripts from YouTube videos - üìÑ Document Processing: Process TXT, MD, DOCX, and PDF files - ü§ñ AI Content Generation: Generate Instagram Reels, Tweets, and Image Carousels using advanced LLM - ‚öôÔ∏è Fully Configurable: Customize field lengths, slide counts, and content generation settings per content type - ‚úèÔ∏è Natural Language Editing: Edit generated content using simple prompts - üîÑ Smart Validation: Automatically retry and fix validation errors to ensure 100% content recovery - üì¶ Bulk Processing: Process multiple videos/documents simultaneously - üìù Enhanced Carousel Content: Generate detailed, comprehensive carousel slides (800 chars with 3-5 sentences) - ‚ö° Fast & Scalable: Built with FastAPI for high performance üèóÔ∏è Project Structure This project follows a clean, organized structure: [code] üöÄ Quick Start Prerequisites - Python 3.9+ - Virtual environment tool (venv, uv, conda) - YouTube Transcript API access - Gemini API key for content generation Installation 1. Clone the repository: [code] 2. Set up virtual environment: [code] 3. Configure environment: [code] 4. Start the server: [code] üéâ API is now running at: [code] üìö API Documentation - Interactive Docs: http://127.0.0.1:8002/docs - ReDoc: http://127.0.0.1:8002/redoc - Detailed API Guide: docs/API.md ‚öôÔ∏è Configuration Create a [code] file with the following variables: [code] üìñ API Endpoints Overview Core Video Processing | Endpoint | Method | Description | |----------|--------|-------------| | [code] | POST | Extract transcript from YouTube video | | [code] | POST | Generate social media content from video | | [code] | POST | Process multiple videos at once | Content Management | Endpoint | Method | Description | |----------|--------|-------------| | [code] | POST | Edit generated content with natural language | | [code] | GET | Get available content style presets | | [code] | GET | Get details of a specific style preset | | [code] | GET | Get default content generation configuration | | [code] | GET | Get currently active configuration | Utilities | Endpoint | Method | Description | |----------|--------|-------------| | [code] | POST | Get videos from a YouTube channel | | [code] | GET | Health check endpoint | üé® Content Style Customization The API supports customizable content styles to match your brand voice and target audience. Available Style Presets - [code] : For e-commerce and Shopify store owners (Roman Urdu) - [code] : Professional business content - [code] : Casual, engaging social media content - [code] : Educational and informative content - [code] : Health, fitness, and wellness focused content Using Style Presets [co",https://github.com/HsnSaboor/repurpose-api/blob/7e05149fab4929227e1afacfc330efff2a72865c/.clinerules.md
981762168,BAMBI-AI-BYOK-IMAGE-GENERATOR,ido2222/BAMBI-AI-BYOK-IMAGE-GENERATOR,https://github.com/ido2222/BAMBI-AI-BYOK-IMAGE-GENERATOR,,,0,Unknown,,.clinerules,"üé® Bambi AI G√©n√©rez des images IA avec vos propres cl√©s API Fonctionnalit√©s ‚Ä¢ D√©marrage rapide ‚Ä¢ Technologies ‚Ä¢ Captures d'√©cran ‚Ä¢ Roadmap ‚Ä¢ Contribuer ‚Ä¢ Licence üìã Pr√©sentation Bambi AI est une plateforme web moderne qui vous permet de g√©n√©rer des images IA en utilisant vos propres cl√©s API (BYOK - Bring Your Own Key). Notre approche unique vous offre : - S√©curit√© maximale : Vos cl√©s API sont chiffr√©es et jamais stock√©es en clair - Flexibilit√© totale : Utilisez les fournisseurs d'IA que vous pr√©f√©rez - √âconomies substantielles : Pas d'abonnements co√ªteux, utilisez vos propres cr√©dits API - Interface intuitive : G√©n√©rez des images en quelques clics Bambi AI est con√ßu pour les cr√©ateurs, designers, d√©veloppeurs et tous ceux qui souhaitent exploiter la puissance des mod√®les d'IA g√©n√©ratives sans compromis. ‚ú® Fonctionnalit√©s üîë BYOK Utilisez vos propres cl√©s API üåê Multi-Providers OpenAI, Stability AI, Google... üõ°Ô∏è S√©curit√© Chiffrement AES-256 üìä Galerie Historique de g√©n√©rations üí∞ Freemium 50 g√©n√©rations gratuites/mois üöÄ UX Intuitive Interface moderne et fluide üöÄ D√©marrage rapide Pr√©requis - Node.js 18.x ou sup√©rieur - npm 9.x ou sup√©rieur Installation [code] Ouvrez http://localhost:3000 dans votre navigateur pour voir l'application. Configuration de Supabase 1. Cr√©ez un compte sur Supabase si vous n'en avez pas d√©j√† un 2. Cr√©ez un nouveau projet 3. R√©cup√©rez les cl√©s API dans les param√®tres du projet (URL et cl√© anon) 4. Mettez √† jour votre fichier [code] avec ces cl√©s 5. Ex√©cutez les migrations SQL pour configurer la base de donn√©es : [code] Configuration de Stripe (pour les paiements) 1. Cr√©ez un compte sur Stripe si vous n'en avez pas d√©j√† un 2. R√©cup√©rez les cl√©s API dans les param√®tres du compte 3. Cr√©ez un produit et un prix pour l'abonnement premium 4. Mettez √† jour votre fichier [code] avec ces informations 5. Configurez un webhook Stripe pour recevoir les √©v√©nements (utilisez Stripe CLI pour les tests locaux) üõ†Ô∏è Technologies Bambi AI est construit avec des technologies modernes et performantes : Frontend - Next.js 13.5.6 avec App Router - React 18.2.0 - TypeScript 5.0.4 - Tailwind CSS 3.3.3 - ShadCN UI (bas√© sur Radix UI) Backend - Supabase (Auth, Database, Edge Functions) - PostgreSQL (via Supabase) - Node.js 18.x S√©curit√© - Proxy API via Supabase Edge Functions - Chiffrement AES-256 (crypto-js) Paiement - Stripe API üìä Captures d'√©cran Dashboard de g√©n√©ration Galerie d'images Gestion des cl√©s API Param√®tres avanc√©s üîÆ Roadmap Nous avons de grands projets pour l'avenir de Bambi AI : Phase 2 (Q3 2023) - Prompt Optimizer : Am√©lioration des prompts via un LLM - Templates pr√©d√©finis : Logo, illustrations, UI design - Export HD : SVG, 4K, PNG - Suivi des co√ªts API : Affichage du co√ªt estim√© par g√©n√©ration Phase 3 (Q4 2023) - Marketplace de cl√©s API : Vente de cr√©dits via des partenariats - Extensions : VS Code, desktop app - Int√©grations : Canva, Figma, Adobe - API Publique : Pour les d√©veloppeurs ü§ù Contribuer Les contributions sont les bienvenues !",https://github.com/ido2222/BAMBI-AI-BYOK-IMAGE-GENERATOR/blob/505024ba6e3e72afb3d8657daef95708a38076a7/.clinerules.md
1124171198,o9nn,o9-ent/o9nn,https://github.com/o9-ent/o9nn,"Fractal map of o9nn organization - folders=repos, files=repo contents",,0,Unknown,,.clinerules,"o9nn Organization Fractal Map This repository is a fractal representation of the o9nn GitHub organization. Structure (Level 2 Mapping) - This Repo ( [code] ) = o9nn organization - Folders = Repositories in o9nn - Files in Folders = Root contents of each repository Statistics | Metric | Count | |--------|-------| | Repositories | 579 | Repositories | Repository | Description | |------------|-------------| | o9c | o9c | | NeuroPilot | An Outer Wilds mod to give ship autopilot control | | BepInEx | Unity / XNA game patcher and plugin framework | | typescript-neuro-game-sdk | A TypeScript/JavaScript SDK for integrating games | | typescript-neuro-game-api | JavaScript/TypeScript package to assist in making | | neuro-sama | Neuro SDK + API for allowing Neuro to play games | | neuro-sdk | Neuro SDK + API for allowing Neuro to play games | | airi | üíñüß∏ Self hosted, you owned Grok Companion, a contai | | the-org | Agents for organizations | | reka-ui | An open-source UI component library for building h | | moeru-ai | No description | | Game-Bots | Ultimate Game Bot Guide (Vol. 1) | | action-send-mail | :gear: A GitHub Action to send an email to multipl | | copilot-cli | GitHub Copilot CLI brings the power of Copilot cod | | graphiql | GraphiQL & the GraphQL LSP Reference Ecosystem for | | daedalOS | Desktop environment in the browser | | socket.io | Realtime application framework (Node.JS server) | | socket.io-client-cpp | C++11 implementation of Socket.IO client | | vcpkg | C++ Library Manager for Windows, Linux, and MacOS | | ecma262 | Status, process, and documents for ECMA-262 | | ecmarkup | An HTML superset/Markdown subset source format for | | re2 | RE2 is a fast, safe, thread-friendly alternative t | | bazelisk | A user-friendly launcher for Bazel. | | bazel-central-registry | The central registry of Bazel modules for the Bzlm | | nvm | Node Version Manager - POSIX-compliant bash script | | node | Node.js JavaScript runtime ‚ú®üê¢üöÄ‚ú® | | gitea | Git with a cup of tea! Painless self-hosted all-in | | 9it | Git with a cup of tea! Painless self-hosted all-in | | dnslib-cpp | C++ library for encoding and decoding of DNS proto | | character-card-spec-v3 | A updated spec for character card used on roleplay | | character-card-spec-v2 | An updated specification for AI character cards. | | agn-ai | No description | | galatea-ui | The official front-end UI. | | aphrodite-engine | Large-scale LLM inference engine | | cli-generator | No description | | aphrodite-loadbalancer | No description | | circles | Scripts and web pages to visualise CMSSW resource | | daelos | Desktop environment in the browser | | fs | No description | | cursdk | Recursal SDK v1 - examples, snippets, and prompt e | | n8n-nodes-featherless | This is an n8n community node for Featherless API | | cline | Autonomous coding agent right in your IDE, capable | | prompts | Library of prompts from the Cline community | | go-lib | General Golang Common Base Reusable Functionality | | dgraph | high-per",https://github.com/o9-ent/o9nn/blob/e327f475cd149a7925223878a40ec1d351f8be07/cline/.clinerules.md
826234730,graph,gravity-ui/graph,https://github.com/gravity-ui/graph,,,0,Unknown,,.clinerules,"@gravity-ui/graph &middot; [](https://www.npmjs.com/package/@gravity-ui/graph) [](https://github.com/gravity-ui/graph/actions/workflows/release.yml?query=branch:main) [](https://preview.gravity-ui.com/graph/) > Migration Guide from 0.x to 1.x ‚Üí A graph visualization library that combines the best of both worlds: - Canvas for high performance when viewing the full graph - HTML/React for rich interactions when zoomed in No more choosing between performance and interactivity. Perfect for large diagrams, flowcharts, and node-based editors. Motivation Modern web applications often require complex visualization and interactivity, but existing solutions typically focus on a single rendering technology: - Canvas offers high performance for complex graphics but is limited in text handling and interactivity. - HTML DOM is convenient for interfaces but less efficient for complex graphics or large numbers of elements. @gravity-ui/graph solves this by automatically switching between Canvas and HTML based on zoom level: - Zoomed Out: Uses Canvas for efficient rendering of the full graph - Medium Zoom: Shows schematic view with basic interactivity - Zoomed In: Switches to HTML/React components for rich interactions How It Works The library uses a smart rendering system that automatically manages the transition between Canvas and React components: 1. At low zoom levels, everything is rendered on Canvas for performance 2. When zooming in to detailed view, the [code] component: - Tracks camera viewport and scale changes - Calculates which blocks are visible in the current viewport (with padding for smooth scrolling) - Renders React components only for visible blocks - Automatically updates the list when scrolling or zooming - Removes React components when zooming out [code] Storybook Install [code] Examples React Example Detailed React Components Documentation [code] Vanilla JavaScript Example [code] Live Examples - Basic example - Large scale example - Custom blocks view - Bezier connection - Connection customization Documentation Table of Contents 1. System - Component Lifecycle - Events - Graph Settings - Public API - Scheduler System 2. Components - Canvas Graph Component - Block Component - Anchors 3. Rendering - Rendering Mechanism - Layers 4. Blocks and Connections - Block Groups - Canvas Connection System",https://github.com/gravity-ui/graph/blob/75229e666461a846afdde77c829a54d498af43d2/.clinerules
933400284,sprout-track,Oak-and-Sprout/sprout-track,https://github.com/Oak-and-Sprout/sprout-track,"A tracker to track baby diapers, feedings, naps, pumping, and other activities.",,0,Unknown,,.clinerules,"Sprout Track > üö® CRITICAL SECURITY UPDATE - IMMEDIATE ACTION REQUIRED > > All users of Sprout Track must upgrade to version 0.96.30 immediately due to a critical React Server Components vulnerability (CVE-2025-66478) that allows remote code execution. This vulnerability affects Next.js applications using React Server Components with the App Router. > > What you need to know: > - Affected versions: All versions prior to 0.96.30 > - Fixed version: Version 0.96.30 (includes Next.js 15.5.7 with security patches) > - Severity: Critical (CVSS 10.0) - Remote Code Execution vulnerability > - Docker users: A new patched image has been deployed to [code] > > Required actions: > - Docker users: Follow the Docker upgrade steps below > - Local installations: Follow the manual upgrade steps below > - All users: Do not delay this update - your application is vulnerable until upgraded > > Docker Upgrade Instructions: > > 1. Backup your database: Navigate to [code] in your browser, log in, and download your database backup from the settings page. > > 2. Pull the latest patched image: [code] > > 3. Restart your container: Stop and start your container to use the new image (e.g., [code] then [code] ). > > 4. Restore your database if prompted: When the new container starts up existing data should automatically migrate if your previous version was after v.0.94.89. If you see the setup wizard use the import feature to restore your database backup file. > > Manual Upgrade Instructions for Local Installations: > > 1. Backup your database and environment file: > - Database: [code] > - Log database (if used): [code] > - Environment file: [code] > > 2. Completely remove your existing project directory and re-clone the repository from GitHub to get the latest code with security patches. > > 3. Follow the standard setup procedure as described in the Getting Started section of this README. > > 4. Restore your backed-up database and [code] file to the new installation. > > Alternative: You can use [code] which automates the backup and rebuild process (without deleting the directory). > > For more details about the vulnerability, see: Next.js Security Advisory CVE-2025-66478 > > --- > ‚ö†Ô∏è IMPORTANT NOTICE - Version 0.94.89 Upgrade > > Admin passwords will be automatically reset to default ""admin"" when upgrading from v0.94.24 or earlier. In attempt to smooth over upgrades for self-hosters that use Docker the /family-manager admin password will be reset to defaults during the import process for new installations. If you manually save/restore your database backup and envirnoment file before the upgrade and do not use the import utility then you will not be affected. Read full details here. A Next.js application for tracking baby activities, milestones, and development. Screenshots Mobile-first app for tracking your child's activities Dark mode for late night feedings Responsive design for larger devices Quick entry for logging activities Comprehensive searchable activity log Calend",https://github.com/Oak-and-Sprout/sprout-track/blob/439b64019f000b4c6d2414574ca8f3c6c535c1b2/.clinerules
903759539,animated_to,chooyan-eng/animated_to,https://github.com/chooyan-eng/animated_to,AnimateTo animates its child to a new position requiring no calculation.,,0,Unknown,,.clinerules,"animated_to animated_to provides a widget named [code] which enables its child widget to change its position with animation when its position is updated for any reason, typically for rebuilding. No calculation is required. Because every calculation is [code] 's business in the Flutter framework, [code] just hires the calculated position and starts animation there. Usage First, place whatever widget you want to animate when its position changes. [code] Then, wrap the widget with [code] or [code] passing [code] . [code] Note that [code] is necessary to keep its [code] alive even when the widget's depth or position changes. And, that's it! All what you need to do is causing rebuilds using whatever state management packages or just [code] and change its position. [code] will automatically leads the [code] to the new position with animation. Spring animation [code] provides [code] which animates its child using [code] . https://api.flutter.dev/flutter/physics/SpringSimulation-class.html This simulates its position transition based on the physical simulation, which make the animations smooth and natural. What you have to do is just switch [code] into [code] to activate spring simulation. You can also configure your own [code] using [code] argument, or you can use pre-defined configuration using @timcreatedit's [code] package. https://pub.dev/packages/motor [code] As [code] is also used inside [code] package(thanks @timcreatedit!), make sure you may have potential risk of dependency conflicts when directly depending on the package on your app side. Some more features [code] lets you specify the start position of the animation in the first frame. By providing an absolute position in the global coordinate system, the widget will appear there and then animate to the original position. [code] lets you specify the start position of the animation in the first frame as well. By providing a relative position to the child's intrinsic position, the widget will slide from the specified position and then animate to the original position. Hit Testing and Coordinate System By default, [code] widgets can only receive gestures (taps, drags, etc.) at their layout position, not at their animated position. This is because Flutter's hit testing system checks widgets at their natural layout position, even though [code] visually paints them at a different location during animation. AnimatedToBoundary [code] serves two important purposes: 1. Enable Hit Testing During Animation To enable gesture detection at the animated position, wrap your widget tree with [code] . This boundary intercepts hit tests and properly forwards them to animating widgets at their current animated positions. [code] [code] is optional. If you don't need to detect gestures on your [code] widgets during animation, you can omit it completely. The animations will work perfectly fine without it. 2. Establish Stable Coordinate Origin [code] can be used to prevent [code] from unexpected behavior by clarifying",https://github.com/chooyan-eng/animated_to/blob/7f4e3e5e846376be5d636271d8fb33289da9487e/.clinerules
275179802,Pilll,bannzai/Pilll,https://github.com/bannzai/Pilll,Pilll x Flutter,,0,Unknown,,.clinerules,Pilll HP https://pilll.wraptas.site/ Blogs - ÂÄã‰∫∫ÈñãÁô∫„ÅÆ„ÅäË©± Download - Google Play - App Store App - Âà©Áî®Ë¶èÁ¥Ñ - „Éó„É©„Ç§„Éê„Ç∑„Éº„Éù„É™„Ç∑„Éº - ÁâπÂÆöÂïÜÂèñÂºïÊ≥ï„Å´Âü∫„Å•„ÅèË°®Á§∫ LICENSE „É©„Ç§„Çª„É≥„Çπ„Å®Êõ∏„ÅÑ„Å¶„Åä„Åç„Å™„Åå„ÇâË¶èÊ†º„Å´Ê≤ø„Å£„Åü„ÇÇ„ÅÆ„ÅÆÊèêÁ§∫„ÅØÁÑ°„ÅÑ„Åß„Åô„ÄÇÂéüÂâáNo LICENSE„Åß„Åô„ÄÇ„Å§„Åæ„ÇäËëó‰ΩúÊ®©„Å®ÂêåÁ≠â„ÅÆÊ®©Âà©„Çí‰∏ªÂºµ„Åó„Åæ„Åô„ÄÇ „Åü„Å†„ÅóPull RequestÁ≠â„ÅØË®±ÂèØ„Åó„Åü„ÅÑ„ÅÆ„ÅßÁã¨Ëá™„ÅßË®±ÂèØ„Åô„Çã„Åì„Å®„ÇíÂÆö„ÇÅ„Å¶ÂàóÊåô„Åó„Åæ„Åô„ÄÇ - „Åì„ÅÆ„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢„Çí‰ΩøÁî®„ÉªË§áÂÜô„Åß„Åç„Çã„Åì„Å®„ÇíÁÑ°ÂÑü„ÅßË®±ÂèØ„Åó„Åæ„Åô - ÂΩì„É™„Éù„Ç∏„Éà„É™„Å´Pull Request„ÇíÈÄÅ„Çã„ÄÅ„Åæ„Åü„ÅØÂÄã‰∫∫Âà©Áî®„ÅÆÁØÑÂõ≤ÂÜÖ„Åß„ÅØ„ÇΩ„Éº„Çπ„Ç≥„Éº„Éâ„ÅÆÂ§âÊõ¥„ÇíË™ç„ÇÅ„Åæ„Åô - Âà©Áî®„Å´‰º¥„ÅÑ‰ΩúÊàêËÄÖ„ÅØ„ÅÑ„Åã„Å™„ÇãË≤¨‰ªª„ÇÇË≤†„ÅÑ„Åæ„Åõ„Çì - ÂΩì„É™„Éù„Ç∏„Éà„É™„Å´Â≠òÂú®„Åô„Çã „ÅÇ„Å™„Åü „ÅåÊîπÂ§â„Åó„Åü„ÇΩ„Éº„Çπ„Ç≥„Éº„Éâ„Å´ÂØæ„Åó„Å¶„ÄÅÁßÅ„ÇíÂê´„ÇÄ‰ªñËÄÖ„ÅåËá™Áî±„Å´ÊîπÂ§â„Åß„Åç„Çã„Åì„Å®„ÇíË™ç„ÇÅ„Å¶„Åè„Å†„Åï„ÅÑ,https://github.com/bannzai/Pilll/blob/35c18c0cb0330151ffe01eed1dbd20d03803ab60/.clinerules
1095103823,n8n-saas-api,aliuygur/n8n-saas-api,https://github.com/aliuygur/n8n-saas-api,,,0,Unknown,,.clinerules,,https://github.com/aliuygur/n8n-saas-api/blob/b3a7386a810d4d73be54020805820ac373717d87/.clinerules.md
967095223,aethr,autifyhq/aethr,https://github.com/autifyhq/aethr,Natural language test scenario runner agent with MCP tools,,0,Unknown,,.clinerules,"Aethr /ÀàiÀêŒ∏…ôr/ Natural language test scenario runner agent with MCP tools. Overview Aethr is a command-line AI agent that runs natural language test scenarios with LLM and MCP, with real-time terminal feedback. It bridges the gap between plain natural language test descriptions and automated testing. Demo Success example Failure example Features - Natural language test file definition - AI agent for test plan and execution - MCP tool calling to automate test execution - CLI-based i.e. CI friendly Getting started Assuming you have Node.js installed and an OpenAI key that can access your [code] model on macOS or Linux: [code] > [!NOTE] > See how to setup for the other LLM providers in Prerequisites section. Prerequisites - Install Node.js 22+ by any method you like - Setup API keys or credentials for one of LLM providers below: - OpenAI, OpenRouter, Anthropic, Amazon Bedrock, Google GenAI, Google VertexAI, Azure OpenAI, Groq, Cohere, Ollama - Put model name and keys/credentials in environment variables (or [code] file) Environment variable setup [code] Usage Create a test scenario file (see below or examples directory) and run it: [code] > [!NOTE] > The default MCP tools is [code] that is a patched version of [code] with a few new features: > > - Assertion tool ( [code] ) > - Environment variable replacement ( [code] , [code] ) > - Trace file output > > You can use any MCP tools for test automation by modifying [code] created by the first execution. Along with the CLI output logs, you can also check Playwright Trace data for debugging: [code] Example Test Scenario Test scenario can be any text format as long as LLM can understand. Here is an example using Markdown: [code] Note: [code] notation is replaced by the environment variables available on the CLI execution (currently it's done by MCP actually). This is useful for sensitive input like password as well as data driven tests. Configuration Aethr uses [code] in the current directory as a configuration file (you can change it by [code] option): [code] You can tweak any configuration here. CI example > [!NOTE] > We're preparing to provide a GitHub Actions to simplify this setup. Stay tuned. If you want to run Aethr in GitHub Actions: [code] Development [code] Author Autify Inc. License Apache-2.0",https://github.com/autifyhq/aethr/blob/868cdd3d3ef7abf44ba7e3a694649604fa89923a/.clinerules
967918082,magento2-mcp,boldcommerce/magento2-mcp,https://github.com/boldcommerce/magento2-mcp,A MCP server for Magento 2,,0,Unknown,,.clinerules,"Magento 2 MCP Server This is a Model Context Protocol (MCP) server that connects to a Magento 2 REST API, allowing Claude and other MCP clients to query product information from a Magento store. Features Product Features - Query product information by SKU or ID - Search for products using various criteria - Get product categories - Get related products - Get product stock information - Get product attributes - Update product attributes by specifying attribute code and value - Advanced product search with filtering and sorting Customer Features - Get all ordered products for a customer by email address Order and Revenue Features - Get order count for specific date ranges - Get revenue for specific date ranges - Get revenue filtered by country for specific date ranges - Get product sales statistics including quantity sold and top-selling products - Support for relative date expressions like ""today"", ""yesterday"", ""last week"", ""this month"", ""YTD"" - Support for country filtering using both country codes and country names Prerequisites - Node.js (v14 or higher) - A Magento 2 instance with REST API access - API token for the Magento 2 instance Installation 1. Clone this repository 2. Install dependencies: [code] Usage Running the server directly [code] Testing with the test client [code] Using with Claude Desktop 1. Check your path node with [code] 2. Go to the Developer settings and click ""Edit config"". This will open a JSON file. 3. Add the following snippet within the [code] : [code] 3. Replace [code] with the path you checked in step 1 4. Replace [code] with the path where you cloned this repo 5. You can get an API token from System > Integrations in the Magento admin 6. Restart Claude Desktop. 7. You should now be able to ask Claude questions about products in your Magento store. Available Tools The server exposes the following tools: Product Tools - [code] : Get detailed information about a product by its SKU - [code] : Search for products using Magento search criteria - [code] : Get categories for a specific product by SKU - [code] : Get products related to a specific product by SKU - [code] : Get stock information for a product by SKU - [code] : Get all attributes for a product by SKU - [code] : Get detailed information about a product by its ID - [code] : Search for products with advanced filtering options - [code] : Update a specific attribute of a product by SKU Customer Tools - [code] : Get all ordered products for a customer by email address Order and Revenue Tools - [code] : Get the number of orders for a given date range - [code] : Get the total revenue for a given date range - [code] : Get revenue filtered by country for a given date range - [code] : Get statistics about the quantity of products sold in a given date range Example Queries for Claude Once the MCP server is connected to Claude Desktop, you can ask questions like: Product Queries - ""What products do you have that are shirts?"" - ""Tell me about product with SKU SKU-xxx"" - ""Wha",https://github.com/boldcommerce/magento2-mcp/blob/5a97766b52797b26fdcd09f00115d79a0748390f/.clinerules
122663163,pyodide,pyodide/pyodide,https://github.com/pyodide/pyodide,Pyodide is a Python distribution for the browser and Node.js based on WebAssembly,,0,Unknown,,AGENTS.md,"[](https://www.npmjs.com/package/pyodide) [](https://pypi.org/project/pyodide-py/) [](https://circleci.com/gh/pyodide/pyodide) [](https://pyodide.readthedocs.io/?badge=stable) Pyodide is a Python distribution for the browser and Node.js based on WebAssembly. What is Pyodide? Pyodide is a port of CPython to WebAssembly/Emscripten. Pyodide makes it possible to install and run Python packages in the browser with micropip. Any pure Python package with a wheel available on PyPi is supported. Many packages with C, C++, and Rust extensions have also been ported for use with Pyodide. These include many general-purpose packages such as regex, PyYAML, and cryptography, and scientific Python packages including NumPy, pandas, SciPy, Matplotlib, and scikit-learn. Pyodide comes with a robust Javascript ‚ü∫ Python foreign function interface so that you can freely mix these two languages in your code with minimal friction. This includes full support for error handling, async/await, and much more. When used inside a browser, Python has full access to the Web APIs. Try Pyodide (no installation needed) Try Pyodide in a REPL directly in your browser. For further information, see the documentation. Getting Started - If you wish to use a hosted distribution of Pyodide: see the Getting Started documentation. - If you wish to host Pyodide yourself, you can download Pyodide from the releases page and serve it with a web server. - If you wish to use Pyodide with a bundler, see the documentation on Working with Bundlers - If you are a Python package maintainer, see the documentation on building and testing Python packages. - If you want to add a package to the Pyodide distribution, see the documentation on adding a package to the Pyodide distribution - If you wish to experiment or contribute back to the Pyodide runtime, see the documentation on building Pyodide from source History Pyodide was created in 2018 by Michael Droettboom at Mozilla as part of the Iodide project. Iodide is an experimental web-based notebook environment for literate scientific computing and communication. Iodide is no longer maintained. If you want to use Pyodide in an interactive client-side notebook, see Pyodide notebook environments. Contributing Please view the contributing guide for tips on filing issues, making changes, and submitting pull requests. Pyodide is an independent and community-driven open-source project. The decision-making process is outlined in the Project governance. Communication - Blog: blog.pyodide.org - Mailing list: mail.python.org/mailman3/lists/pyodide.python.org/ - Twitter: twitter.com/pyodide - Stack Overflow: stackoverflow.com/questions/tagged/pyodide - Discord: Pyodide Discord Sponsors For a full list of current and historical sponsors, please see the Funding section of our About page. Pyodide also has a large number of small donors. If you‚Äôre interested in supporting Pyodide, check out our OpenCollective and GitHub Sponsors pages. Special thanks - BrowserStack: This pr",https://github.com/pyodide/pyodide/blob/97d7568318a3cc64d8bc4914177a3358108a9da9/AGENTS.md
683347556,turso,tursodatabase/turso,https://github.com/tursodatabase/turso,"Turso is an in-process SQL database, compatible with SQLite.",,0,Unknown,,AGENTS.md,"Turso Database An in-process SQL database, compatible with SQLite. --- About Turso Database is an in-process SQL database written in Rust, compatible with SQLite. > ‚ö†Ô∏è Warning: This software is in BETA. It may still contain bugs and unexpected behavior. Use caution with production data and ensure you have backups. Features and Roadmap * SQLite compatibility for SQL dialect, file formats, and the C API see [document for details] * Change data capture (CDC) for real-time tracking of database changes. * Multi-language support for * Go * JavaScript * Java * Python * Rust * WebAssembly * Asynchronous I/O support on Linux with [code] * Cross-platform support for Linux, macOS, Windows and browsers (through WebAssembly) * Vector support support including exact search and vector manipulation * Improved schema management including extended [code] support and faster schema changes. The database has the following experimental features: * [code] for improved write throughput using multi-version concurrency control (MVCC). * Encryption at rest for protecting the data locally. * Incremental computation using DBSP for incremental view maintenance and query subscriptions. * Full-Text-Search powered by the awesome tantivy library The following features are on our current roadmap: * Vector indexing for fast approximate vector search, similar to libSQL vector search. Getting Started Please see the Turso Database Manual for more information. üíª Command Line You can install the latest [code] release with: [code] Then launch the interactive shell: [code] This will start the Turso interactive shell where you can execute SQL statements: [code] You can also build and run the latest development version with: [code] If you like docker, we got you covered. Simply run this in the root folder: [code] ü¶Ä Rust [code] Example usage: [code] ‚ú® JavaScript [code] Example usage: [code] üêç Python [code] Example usage: [code] ü¶´ Go [code] Example usage: [code] ‚òïÔ∏è Java We integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to the README.md under bindings/java. ü§ñ MCP Server Mode The Turso CLI includes a built-in Model Context Protocol (MCP) server that allows AI assistants to interact with your databases. Start the MCP server with: [code] Configuration Add Turso to your MCP client configuration: [code] Available Tools The MCP server provides nine tools for database interaction: 1. [code] - Open a new database 2. [code] - Describe the current database 3. [code] - List all tables in the database 4. [code] - Describe the structure of a specific table 5. [code] - Execute read-only SELECT queries 6. [code] - Insert new data into tables 7. [code] - Update existing data in tables 8. [code] - Delete data from tables 9. [code] - Execute schema modification statements (CREATE TABLE, ALTER TABLE, DROP TABLE) Once connected, you can ask your AI assistant: - ""Show me all tables in the database"" - ""What's the schema for the users table?"" - ""Fi",https://github.com/tursodatabase/turso/blob/caec8a9f55579ec37a135ef3e7b1defbbd8e35fb/AGENTS.md
239517556,rusk,dusk-network/rusk,https://github.com/dusk-network/rusk,The reference Dusk platform implementation and tools,,0,Unknown,,AGENTS.md,"The official Dusk protocol node client and smart contract platform. &nbsp; &nbsp; &nbsp; &nbsp; > _Unstable_ : No guarantees can be made regarding the API stability, the > project is in development. üñß How to run a node This README is for people who want to develop, test nodes locally, and contribute to the Rusk codebase. For more information on running a node for main- or testnet, see our Node operator docs üìÉ Table of Contents - Repo Overview - Prerequisites - Setup script - Rust Installation - Build and Tests - Run a local node for development - Spin up local node - Prepare modules - Run a node - Run an archive node - Run a prover node - Contracts compilation - Docker support üó∫Ô∏è Overview Code projects | Name | Description | | :------------------------------------ | :-------------------------------------------------------------------------- | | üåí rusk | Entrypoint for the blockchain node | | üîó consensus | Implementation of Dusk's succinct attestation consensus | | üìú contracts | Dusk genesis contracts | | üß© data-drivers | Tools to encode/decode contract arguments between RKYV and JS I/O | | üß¨ dusk-core | Core types used for interacting with Dusk and writing smart contracts | | üåê dusk-abi | Dusk application binary interface to develop smart contracts (part of core) | | üìä node-data | Core datatypes for the blockchain node | | ‚öôÔ∏è dusk-vm | The virtual machine to run Dusk smart contracts | | ü™™ rusk-profile | Utility to generate a genesis state based on a set profile | | üì® rusk-prover | Service exposing functionality to remotely prove zero knowledge proofs | | ‚¨áÔ∏è rusk-recovery | Utility to recover the state of a chain | | ‚å®Ô∏è rusk-wallet | Dusk CLI wallet | | üî® w3sper.js | Js SDK to integrate Dusk features into applications | | ‚öôÔ∏è wallet-core | WASM library providing core logic for Dusk wallet implementations | Infrastructure & Testing | Name | Description | | :-------------- | :--------------------------------------------------------- | | üìÇ examples | Example data used for local chain spawning and development | | üìÑ scripts | Utility scripts | | üîß test-wallet | Wallet for testing against the specifications | üìù Prerequisites - Rust 1.82 nightly or higher - GCC 13 or higher - Clang 18 or higher - Deno 2.x Setup script We provide a setup script in the [code] folder that can take care of everything. [code] Rust Installation Rusk makes use of the nightly toolchain, make sure it is installed. Furthermore, to build the WASM contracts, [code] is required. To install and set the nightly toolchain, and install [code] , run: [code] üõ†Ô∏è Build and Tests To build [code] from source, make sure the prerequisites are met. Then you can simply run the following command to compile everything: [code] To run tests: [code] That will also compile all the genesis contracts and its associated circuits. See also [code] for all the available commands üíª Run a local node for development Spin up local node Run a single full-node cluster with example state. Prepare modules: [code] Run ",https://github.com/dusk-network/rusk/blob/d14e81c5b43ff38a18913fd5e953a3447d0afe1f/agents.md
736550812,glimmer-next,lifeart/glimmer-next,https://github.com/lifeart/glimmer-next,"GXT is `glimmer-vm` runtime alternative, only 7kb gzipped",,0,Unknown,,AGENTS.md,"GXT [](https://app.netlify.com/sites/g-next/deploys) [code] is a cutting-edge, compilable runtime environment designed as [code] alternative, showcasing the power and flexibility of modern web component development. This repo includes a live example of how [code] can be used in real-world applications, providing developers with a practical and interactive experience. Explore our sample at netlify. Benefits - üî• Hot Module Replacement (Reloading) - üåë Native shadow-dom support - ‚åõ Async element destructors support - üñ•Ô∏è Server Side Rendering - üíß Rehydration - üîß Ember Developer Tools support - üçÉ Runtime code tree-shaking - üì¶ Small Bundle Size - ‚úçÔ∏è Typed Templates with Glint - ü§ù Ember syntax compatibility - üöÄ 40% performance improvement compared to GlimmerVM - üíæ 2x less memory usage compared to GlimmerVM - üßπ Template linting support via Ember Template Lint - ‚öõÔ∏è Built-in reactivity system Development tools for VS Code - Language Server - Template Syntax - Templates Type checking Quick Links - Related issue: glimmer-vm/issues/1540 - Related PR: glimmer-vm/pull/1541 - Sample App: js-framework-benchmark Documentation - Runtime Compiler - Compile templates at runtime for dynamic content, CMS integration, or development tools Component sample Based on template imports RFC [code] Key Features Simple and Expressive Component Model - Component as Functions: Every component in gNext is a function, executed only once for efficiency and better performance. - Class based components: Class based components are supported as well. - Basic Glint Support: Integration with Glint for improved TypeScript support and developer experience. - Comprehensive Slot Support: Full support for different kinds of slots, including {{yield}}, enhancing the flexibility in component composition. - Modifiers and Helpers APIs: Modifiers for element-specific logic. Helpers for reusable logic across components. - Template Imports: Import templates from other files, enabling better code organization and reusability. - Template Compilation: Compile templates to JavaScript functions for improved performance and efficiency. - Opcodes tree-shaking: Opcodes tree-shaking for smaller bundle size. We don't include unused DOM and component, flow-control opcodes in the bundle. Reactive Primitives - Mutable State with [code] : Use cell for creating reactive, mutable states. Updating and accessing cell values is straightforward and efficient. - Derived State with [code] : Create derived states that automatically update when dependencies change, ensuring reactive and responsive UIs. - Support for destructors: Enables clean-up and resource management, preventing memory leaks. Benefits and Use Cases gNext serves as a powerful tool for web developers looking to harness the capabilities of Glimmer-VM in a real-world setting. Its benefits and use cases include: - Efficient DOM Rendering: Experience fast and efficient DOM updates and rendering, crucial for high-performance web applications. - Reactive State Man",https://github.com/lifeart/glimmer-next/blob/f349895b4460ae3a238604f749da978789689cca/Agents.md
385634291,mimir,grafana/mimir,https://github.com/grafana/mimir,"Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.",,0,Unknown,,AGENTS.md,"Grafana Mimir Grafana Mimir is an open source software project that provides a scalable long-term storage for Prometheus. Some of the core strengths of Grafana Mimir include: - Easy to install and maintain: Grafana Mimir‚Äôs extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system. - Massive scalability: You can run Grafana Mimir's horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series. - Global view of metrics: Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed. - Cheap, durable metric storage: Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage. - High availability: Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying. - Natively multi-tenant: Grafana Mimir‚Äôs multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants. Migrating to Grafana Mimir If you're migrating to Grafana Mimir, refer to the following documents: - Migrating from Thanos or Prometheus to Grafana Mimir. - Migrating from Cortex to Grafana Mimir Deploying Grafana Mimir For information about how to deploy Grafana Mimir, refer to Deploy Grafana Mimir. Getting started If you‚Äôre new to Grafana Mimir, read the Get started guide. Before deploying Grafana Mimir in a production environment, read: 1. An overview of Grafana Mimir‚Äôs architecture 1. Configure Grafana Mimir 1. Run Grafana Mimir in production Documentation Refer to the following links to access Grafana Mimir documentation: - Latest release - Upcoming release, at the tip of the [code] branch Contributing To contribute to Grafana Mimir, refer to Contributing to Grafana Mimir. Join the Grafana Mimir discussion",https://github.com/grafana/mimir/blob/efbaac3097bf22709c9c5dbfb263ee51ce635196/AGENTS.md
365319834,surajfale,surajfale/surajfale,https://github.com/surajfale/surajfale,,,0,Unknown,,AGENTS.md,"üëã Hi, I'm Suraj Fale Principal Engineer | System Design & Architecture | Scala & Kafka | Generative AI & Prompt Engineering [](https://www.linkedin.com/in/surajfale) [](https://github.com/surajfale) [](https://stackoverflow.com/users/585398/suraj-fale) [](https://surajfale.netlify.app) [](https://dev.to/surajfale) [](https://medium.com/@surajfale) --- üöÄ About Me I'm a Principal Engineer focused on driving technical strategy, designing large-scale distributed systems, and leading multiple software projects from architecture through delivery. I enjoy solving complex systems problems and mentoring engineers to build maintainable, scalable solutions. - üî≠ Currently driving technical strategy and delivery of Scala and Apache Kafka projects - ü§ñ Exploring Generative AI, Prompt Engineering, and LLM integration - üå± Learning AI/ML, containerization (Docker/Kubernetes), and orchestration architectures - üíº Leading cross-team delivery and technical vision for enterprise-scale distributed systems - üéì Java Certified by HackerRank (2020) - üí° Passionate about clean code, system design, and performance optimization - üåê Portfolio: surajfale.com --- üõ†Ô∏è Tech Stack Languages Core Strengths: Also Proficient: Frameworks & Technologies Tools & Platforms --- üíº Professional Experience Principal Engineer | Current - Driving technical strategy and high-level architecture across multiple projects - Overseeing enterprise-scale real-time data processing pipelines with Apache Kafka - Designing microservices and platform components with Scala and modern architectural patterns - Mentoring engineering leads and aligning long-term technical vision with business goals --- üéØ Featured Projects üé§ Voice Enabled Grocery App A smart grocery list application with voice recognition capabilities, making shopping lists more accessible and efficient. Tech Stack: React, Voice API, JavaScript [](https://voice-grocery-list.netlify.app/) [](https://github.com/surajfale/voice-grocery-list_app) üîß Developer Tools Collection A curated collection of essential developer tools and utilities to boost productivity and streamline development workflows. Tech Stack: React, TypeScript, Material-UI [](https://devs-tools.netlify.app/) [](https://github.com/surajfale/dev-tools) ü§ñ Git Commit MCP Server A lightweight Model Context Protocol (MCP) server that automates Conventional Commit message generation, changelog updates, and optional git pushes. Ideal for teams and individuals who want AI-assisted, well-formed commit messages and automated changelog management. Tech Stack: Python 3.10+, MCP Protocol, Git [](https://test.pypi.org/project/git-commit-mcp-server/) [](https://github.com/surajfale/git-mcp-server) üìù Notes & Tasks Web Application A modern, production-ready web app for managing notes and tasks with full offline support, list organization, and a responsive Material Design 3 UI. Features rich text notes, task tracking, JWT authentication, and seamless sync. Tech Stack: SvelteKit, Node.js, Express, MongoDB A",https://github.com/surajfale/surajfale/blob/7081ee118db4d28a28bfb22cf3c72569b75c5225/AGENTS.MD
899097441,hass_lmair,kmifka/hass_lmair,https://github.com/kmifka/hass_lmair,"Home Assistant custom integration for the Light Manager Air by jb media. Control lights, blinds and other actuators, receive radio signals , and manage scenes through HASS.",,0,Unknown,,AGENTS.md,"[](https://github.com/kmifka/hass_lmair/releases/latest) [](https://buymeacoffee.com/kmifka) Light Manager Air Integration for Home Assistant A Home Assistant custom integration for the jbmedia's Light Manager Air. Key Features - Automatic device discovery on your local network - Full control of: - Lights (including dimming) - Blinds/Covers - Markers - Scenes - Radio reception: Receive 433 MHz and 868 MHz radio signals - Marker status updates: Read an control markers as a switch in Home Assistant - Weather data: Integration of connected weather channels - Cover Positioning: Configure covers to display and set their current position based on opening and closing times. - Marker mapping: Use markers as state proxies for stateless devices. - Ignore Zones: Configure zones to be ignored in Home Assistant - Entity Type Conversion: Convert entities to different types (e.g., light to switch) This integration bridges jb media's Light Manager Air with Home Assistant, unlocking advanced home automation capabilities. --- Installation Option 1: Manual Installation 1. Copy the [code] folder to the [code] directory in your Home Assistant configuration folder. 2. Restart Home Assistant. 3. Add the integration via the UI: Go to Settings ‚Üí Devices & Services ‚Üí Add Integration and search for ""Light Manager Air"". Option 2: Installation via HACS (Home Assistant Community Store) 1. Ensure HACS is Installed If you don‚Äôt have HACS installed, follow the HACS installation guide. 2. Add the Custom Repository - Open Home Assistant and navigate to HACS ‚Üí Integrations. - Click the three dots menu in the top-right corner and select Custom repositories. - Add the following repository URL: [code] - Select Integration as the category. - Click Add. 3. Install the Integration - Search for ""Light Manager Air"" in the HACS integrations list. - Click Install to download and install the integration. 4. Restart Home Assistant to apply changes. 5. Add the integration via the UI: Go to Settings ‚Üí Devices & Services ‚Üí Add Integration and search for ""Light Manager Air"". --- Important Notes on Unique Zone and Actuator Names It is crucial that each combination of zone and actuator name in the Light Manager is unique, as these are used to generate entities in Home Assistant. If the names are not unique, only the first occurrence will be added to Home Assistant, and all subsequent entities will be skipped. Changes to zones or actuators in the Light Manager will result in duplicate or new entries in Home Assistant. --- Reloading devices and scenes after changes When you add or rename zones, actuators, or scenes in the Light Manager Air, Home Assistant needs a reload to pick them up. The integration now exposes a service for this: - Call service [code] (optional data: [code] if you have multiple instances) to refresh devices and entities from the Light Manager. - Alternatively, go to Settings ‚Üí Devices & Services ‚Üí Light Manager Air ‚Üí Reload in the UI. The service performs a full config-entry reloa",https://github.com/kmifka/hass_lmair/blob/480b1d24d06586ff36f42726749c46487f3fbfd8/Agents.md
1092853338,pbt,koaning/pbt,https://github.com/koaning/pbt,,,0,Unknown,,AGENTS.md,"PBT A DBT-like data transformation tool built on Polars/Narwhals with lazy evaluation and incremental processing. Quick Start [code] Model Types [code] - Always recomputed on each run - Use for reading raw data files - Should return a LazyFrame [code] - Lazy views - not materialized - Useful for intermediate transformations - Passed as parameters to downstream models [code] - Materialized to parquet files in [code] - Supports full refresh mode [code] - Sets up append-only incremental tables - Automatically filters to new records using [code] - Still materializes to [code] Incremental Processing Incremental tables track the maximum value of a time column and only process new records: [code] For advanced use cases you can still call [code] manually (e.g. to place the filter earlier in your pipeline or combine with other predicates). The helper just saves you from repeating the time column in both places. Rerunning specific windows Incremental tables expose [code] so you can reprocess historical ranges without doing a full refresh. PBT removes the old rows for that window from the materialized parquet and rebuilds them using the current logic‚Äîhandy for backfills or bug fixes. [code] The helper accepts Python [code] objects or ISO-8601 strings and is only available on incremental tables with a configured [code] . Dependency Resolution PBT builds a DAG by inspecting function parameters: [code] Execution order is automatically determined via topological sort. Implementation Details Metadata Injection PBT monkeypatches [code] to add [code] : [code] The [code] method reads this metadata to: - Know which table is being built - Access the state manager - Get the last max value (or rerun bounds) for filtering State Tracking Every table write updates [code] with a [code] timestamp, and incremental tables also track their [code] . This makes it easy to audit when each table was materialized and where incremental processing will resume. Running [code] Future Enhancements - [ ] CLI interface with model selection ( [code] ) - [ ] Full refresh flag ( [code] ) - [ ] Merge/upsert strategies (not just append) - [ ] Partition-based incremental (delete+insert) - [ ] Better date/datetime type handling in state - [ ] Schema validation and testing hooks - [ ] Parallel execution of independent models - [ ] Support for multiple backends via Narwhals",https://github.com/koaning/pbt/blob/a20d3182ce745b64b2f73059b5c0772f34939478/agents.md
605728251,ax,ax-llm/ax,https://github.com/ax-llm/ax,"The pretty much ""official"" DSPy framework for Typescript",,0,Unknown,,AGENTS.md,"Ax - Build Reliable AI Apps in TypeScript with DSPy Ax brings DSPy's approach to TypeScript ‚Äì describe what you want, and let the framework handle the rest. Production-ready, type-safe, works with all major LLMs. [](https://www.npmjs.com/package/@ax-llm/ax) [](https://twitter.com/dosco) [](https://discord.gg/DSHg3dU7dW) The Problem Building with LLMs is painful. You write prompts, test them, they break. You switch providers, everything needs rewriting. You add validation, error handling, retries ‚Äì suddenly you're maintaining infrastructure instead of shipping features. The Solution Define what goes in and what comes out. Ax handles the rest. [code] No prompt engineering. No trial and error. Works with GPT-4, Claude, Gemini, or any LLM. Why Ax Write once, run anywhere. Switch between OpenAI, Anthropic, Google, or 15+ providers with one line. No rewrites. Ship faster. Stop tweaking prompts. Define inputs and outputs. The framework generates optimal prompts automatically. Production-ready. Built-in streaming, validation, error handling, observability. Used in production handling millions of requests. Gets smarter. Train your programs with examples. Watch accuracy improve automatically. No ML expertise needed. Examples Extract structured data [code] Complex nested objects [code] Validation and constraints [code] Available constraints: [code] , [code] , [code] , [code] , [code] , [code] , [code] , [code] Validation runs on both input and output. Automatic retry with corrections on validation errors. Agents with tools (ReAct pattern) [code] Multi-modal (images, audio) [code] Install [code] Additional packages: [code] Features - 15+ LLM Providers ‚Äì OpenAI, Anthropic, Google, Mistral, Ollama, and more - Type-safe ‚Äì Full TypeScript support with auto-completion - Streaming ‚Äì Real-time responses with validation - Multi-modal ‚Äì Images, audio, text in the same signature - Optimization ‚Äì Automatic prompt tuning with MiPRO, ACE, GEPA - Observability ‚Äì OpenTelemetry tracing built-in - Workflows ‚Äì Compose complex pipelines with AxFlow - RAG ‚Äì Multi-hop retrieval with quality loops - Agents ‚Äì Tools and multi-agent collaboration - Zero dependencies ‚Äì Lightweight, fast, reliable Documentation Get Started - Quick Start Guide ‚Äì Set up in 5 minutes - Examples Guide ‚Äì Comprehensive examples - DSPy Concepts ‚Äì Understanding the approach - Signatures Guide ‚Äì Type-safe signature design Deep Dives - AI Providers ‚Äì All providers, AWS Bedrock, Vercel AI SDK - AxFlow Workflows ‚Äì Build complex AI systems - Optimization (MiPRO, ACE, GEPA) ‚Äì Make programs smarter - AxAgent & RLM ‚Äì Agents, child agents, tools, and RLM for long contexts - Advanced RAG ‚Äì Production search and retrieval Run Examples [code] Core examples: [code] , [code] , [code] , [code] , [code] Production patterns: [code] , [code] , [code] , [code] , [code] View all 70+ examples Community - Twitter ‚Äì Updates - Discord ‚Äì Help and discussion - GitHub ‚Äì Star the project - DeepWiki ‚Äì AI-powered docs Production Ready - B",https://github.com/ax-llm/ax/blob/e06a158726ba90c801c7befee739d342e79e3f02/AGENTS.md
1043568442,yourfine,Jimuelzxc/yourfine,https://github.com/Jimuelzxc/yourfine,Prompt Refining & Saving Tool,,0,Unknown,,AGENTS.md,"yourfine A smart prompt library and refinement tool that helps you turn messy ideas into polished prompts. Why your fine? yourfine is an open-source web app designed for anyone who works with AI prompts. It solves a simple but common problem: great prompt ideas often start messy, and it's easy to lose track of your best versions. With yourfine, you can: - Clean up rough prompt drafts using AI-powered refinement - Save both original and refined versions for comparison - Organize prompts into sessions for different projects - Access everything from any device (data stays in your browser) Key Features üß† AI-Powered Refinement Turn rough ideas into polished prompts (especially helpful for non-English speakers) with a single click. yourfine integrates with leading AI models to help you refine your prompts automatically. üåç Multilingual Support Write prompts in your native language and use AI to translate and refine them into English. Perfect for non-English speakers who want to leverage AI tools that work best in English. üìö Smart Organization - Save unlimited prompts with timestamps - Toggle between original and refined versions - Bookmark your favorite prompts - Search through your entire prompt history üóÇÔ∏è Session Management - Create separate sessions for different projects - Export/import sessions as JSON files - Rename sessions for better organization üîí Privacy First - Your API key stays on your machine - All data stored locally in your browser - No servers, no accounts, no data sharing How It Works 1. Type your messy prompt idea (in any language) 2. Refine it with AI assistance (translate and polish) 3. Save both versions for future reference 4. Organize prompts into project-specific sessions 5. Reuse your best prompts anytime Getting Started Prerequisites - Node.js (version 18 or higher) - npm or yarn Installation [code] Development [code] Open http://localhost:3000 in your browser. Production Build [code] Built With - Next.js - React framework - Google Generative AI - AI model integration - React Icons - UI icons - Tailwind CSS - Styling Contributing We welcome contributions! Here's how you can help: 1. Fork the repository 2. Create a feature branch 3. Commit your changes 4. Push to the branch 5. Open a pull request Areas for Improvement - Additional AI model integrations - Advanced prompt organization (tags, categories) - Prompt chaining and workflows - Collaboration features Check out our Issues page for ideas or submit your own! License This project is licensed under the MIT License. --- *yourfine: Because your best prompts shouldn't get lost in translation.*",https://github.com/Jimuelzxc/yourfine/blob/2e942cedba47e586b03942e9fb40ee95c9f77a88/AGENTS.MD
344243953,lading,DataDog/lading,https://github.com/DataDog/lading,A suite of data generation and load testing tools,,0,Unknown,,AGENTS.md,"[code] - A tool for measuring the performance of long-running programs. The [code] project is a tool for measuring the performance behavior of long-running programs -- daemons, often -- using synthetic, repeatable load generation across a variety of protocols. The ambition is to be a worry-free component of a larger performance testing strategy for complex programs. The [Datadog Agent][agent] project uses lading in their 'Regression Detector' tests. Operating Model [code] operates on three conceptual components: * generators, * target and * blackholes A ""generator"" in [code] is responsible for creating load and ""pushing"" it into the target. The ""target"" in is the program that [code] runs as a sub-process, collecting resource consumption data about the target from the operating system but also self-telemetry regarding generation. The ""blackhole"" exists for targets to push load into, when necessary, allowing for a target to be run and examined by [code] without including external programs or APIs into the setup. As much as possible [code] pre-computes any generator and blackhole payloads, intending to minimize runtime overhead compared to the target program. Users must provide a seed to [code] -- see below -- ensuring that payloads are generated in a repeatable manner across [code] runs. While pre-computation does mean that [code] is capable of outpacing many targets with minimal runtime interference it does also mean higher memory use compared to other load generation tools. Configuration The configuration of [code] is split between a configuration file in YAML format and command-line options. Generators and blackholes are configured in the config file, targets on the command line. This is, at first glance, awkward but does allow for [code] to be used in dynamic environments like CI without foreknowledge of the target. That ""push"" can be as direct as network IO into the target or as indirect as doing file operations for a target who's tracing with BPF. Consider the following [code] : [code] In this setup [code] is configured to run one generator and one blackhole. In general, at least one generator is required and zero or more blackholes are. The generator here, named ""http"", uses a fixed seed to repeatably produce [fluent's forward protocol][fluent] instances at 100 MiB per second into the target, with a pre-built size of 256 MiB. That is, [code] will _attempt_ to push at a fixed throughput, although the target might not be able to cope with that load and [code] will consume 256 MiB of RAM to accommodate pre-build payloads. The blackhole in this configuration responds with an empty body 200 OK. [code] supports three types of targets, binary launch mode, PID watch mode, and container watch mode. In binary launch mode, [code] acts like a wrapper around the target. To use this mode, one specifies where on disk the configuration is, the path to the target and its arguments. [code] and [code] allow the target's stdout, stderr to be forwarded into file",https://github.com/DataDog/lading/blob/b968631298733d373f535ae4db5901df368f06e6/AGENTS.md
632947911,wordpress-plugin-boilerplate,WPBoilerplate/wordpress-plugin-boilerplate,https://github.com/WPBoilerplate/wordpress-plugin-boilerplate,,,0,Unknown,,AGENTS.md,"WordPress Plugin Boilerplate A comprehensive, modern WordPress plugin boilerplate that follows WordPress coding standards and incorporates the latest development tools and best practices. [](https://wordpress.org) [](https://php.net) [](http://www.gnu.org/licenses/gpl-2.0.html) üöÄ Features - **Modern PHP Development*‚îú‚îÄ‚îÄ üìÅ vendor/ # Composer dependencies ‚îú‚îÄ‚îÄ üìÑ composer.json # Composer configuration (includes Mozart) ‚îú‚îÄ‚îÄ üìÑ package.json # npm configuration ‚îú‚îÄ‚îÄ üìÑ webpack.config.js # Build configuration ‚îú‚îÄ‚îÄ üìÑ init-plugin.sh # Initialization script ‚îî‚îÄ‚îÄ üìÑ your-plugin.php # Main plugin file-4 autoloading, namespace organization - WordPress Standards: Follows WordPress Coding Standards (WPCS) - Build System: @wordpress/scripts with Webpack, Babel, and SCSS support - Block Development: Integrated Gutenberg block creation and registration - Automated Deployment: GitHub Actions for WordPress.org deployment - Internationalization: Built-in i18n support with POT file generation - Composer Integration: Dependency management with custom WPBoilerplate packages - Security: Built-in security best practices and sanitization üìã Requirements - WordPress: 4.9.1 or higher - PHP: 7.4 or higher (8.0+ recommended) - ‚ö†Ô∏è Critical: PHP 7.4 is the minimum required version enforced by [code] - üöÄ Recommended: PHP 8.0+ for better performance and modern language features - üîí Enforcement: Composer will prevent installation on older PHP versions - Node.js: 14.0 or higher - Composer: 2.0 or higher üîç PHP Version Verification Before installation, verify your PHP version meets the requirements: [code] Why PHP 7.4+? - ‚úÖ Modern Features: Arrow functions, typed properties, null coalescing assignment - ‚úÖ Performance: Significant performance improvements over PHP 7.3 and earlier - ‚úÖ Security: Better security features and ongoing support - ‚úÖ WordPress Compatibility: Full compatibility with modern WordPress features - ‚úÖ Ecosystem: Required by modern WordPress development tools and packages üõ†Ô∏è Quick Start Method 1: Using the Initialization Script (Recommended) 1. Clone the boilerplate: [code] 2. Run the initialization script: [code] 3. Follow the interactive prompts: - Enter your plugin name (e.g., ""My Awesome Plugin"") - Enter your GitHub organization name (e.g., ""MyCompany"") - Optional: Select WPBoilerplate packages for WordPress integrations: - [code] - Auto-register Gutenberg blocks - [code] - GitHub-based auto-updates - [code] - BuddyPress/BuddyBoss compatibility - [code] - WooCommerce integration support - And more specialized packages for common WordPress needs - The script will automatically: - Create a new plugin with your details - Install selected packages via Composer - Add integration code to [code] - Set up the complete development environment Method 2: Manual Setup 1. Clone and rename: [code] 2. Install dependencies: [code] 3. Build assets: [code] üèóÔ∏è Build System (@wordpress/scripts) The plugin uses WordPress's official build tools for modern development workflows: Available Command",https://github.com/WPBoilerplate/wordpress-plugin-boilerplate/blob/a134ef1228ce059e1ae08bd6656a9498fa0c69eb/agents.md
749418211,sx_training_fetch,gordonwatts/sx_training_fetch,https://github.com/gordonwatts/sx_training_fetch,,,0,Unknown,,AGENTS.md,"sx_training_fetch Code to fetch training datasets from ATLAS derivations for the Run 3 per-jet CalRatio NN. While designed to run against LLP1, really, it will work on anything that has the data. Contributing The main home for this repo is on GitHub. Over there please feel free to: * Open an issue * Submit a PR * Examine the roadmap Any other mirrors are for archival purposes only and their issues and MR's aren't frequently checked! Installation What you'll need on your system: 1. To run against a local file: a. [code] should be installed 1. To run against a web dataset or a RUCIO dataset a. [code] file to a ServiceX instance. Usage Fetching Data This command fetches the data from a sample and formats it as regular training input. [code] Some notes: * Output data will be written in files called [code] by default. The [code] is to keep files to the 2 GB size. * Default running means you need to run nothing but the data type and the DID dataset. * If no jets are written out, rerun with [code] to see if there are any messages that give you a hint. * The [code] files are not deleted at the start of a run. Take care not to get confused by subsequent runs! The dataset type: * [code] - Expect to find LLP's and only emits jets that are aligned with the LLPs * [code] - Will extract all good jets * [code] - Will extract all good jets from events that have fired a signal trigger * [code] - Will extract jets that match a BIB trigger, but not the tighter signal triggers. As of this writing only [code] and [code] are implemented. Where can the data be located? In all cases we are expecting a LLP1-type derivation. The data can be in a number of locations: 1. Local File You can either specify the path, or use the standard [code] url: [code] . If you just specify the path, the file must exist or the system might guess you are trying to do another file source. NOTE this only works in a branch of this code (removed functionality because it wasn't robust). 1. URL The file should be accessible by anyone anywhere (e.g. public). The dataset can be processed locally or remotely in this case (see the [code] option). a. If the URL is a CERNBox URL, it can be converted to a [code] address and accessed more efficiently that way - if you are running on a remote [code] instance. To correctly use a cernbox url, go to the file in CERNBOX, click on the details option from the drop down, and select the 'Direct Link' option. 1. Rucio Dataset You can specify just the dataset name, or prefix it with [code] . The rucio DID scope must be present. Note that this will use a remote ServiceX executable if it can - it will only use the local service if you are running on a local machine.",https://github.com/gordonwatts/sx_training_fetch/blob/d9dbad96595c8e8a3521c3930bdc8fca467315bf/Agents.md
1019207615,the-artist-hub,liondragon/the-artist-hub,https://github.com/liondragon/the-artist-hub,,,0,Unknown,,AGENTS.md,"The Artist Hub Theme INTERNAL USE ONLY Architectural Decisions & Constraints ATTENTION FUTURE AGENTS & DEVELOPERS: 1. NO BLOCK EDITOR (GUTENBERG): This theme is designed to be lightweight and purely PHP-based. The WordPress Block Editor is intentionally disabled and unsupported. * Do NOT add [code] . * Do NOT add block support. * Keep the clean, classic editor experience. 2. NO BUILD PIPELINE: There is no [code] , generic build scripts, or pre-processing. The theme serves raw CSS and JS for simplicity and ease of maintenance in this specific environment. 3. NO EXTERNAL DEPENDENCIES: The theme should remain self-contained. Theme Structure * [code] : Source of truth for design tokens. * [code] : Functional logic separated by concern. * [code] : Custom layouts. Maintenance * Strict types ( [code] ) are enforced. * All output must be escaped ( [code] , [code] , etc.).",https://github.com/liondragon/the-artist-hub/blob/76cdf88dbbdad167216a6572c9ddf49bcf803a50/agents.md
1022870846,anml-exp,mattsq/anml-exp,https://github.com/mattsq/anml-exp,A unified interface to prototype and test anomaly detection methods.,,0,Unknown,,AGENTS.md,"anml-exp A unified interface to prototype and test anomaly detection methods. Project Structure [code] Installation Create a reproducible environment with [code] and install optional extras as needed: [code] Benchmarking Run the [code] command to execute a benchmark and produce a JSON result conforming to [code] . [code] Leaderboard Run the [code] command to benchmark all built-in tabular datasets and generate a Markdown leaderboard. Results are stored under [code] . [code] Hardware descriptor Use the [code] flag to record the execution environment. It accepts a short string or JSON object with keys [code] , [code] , [code] , [code] , [code] and [code] . Artefact registry Models may be saved and loaded using [code] , which stores pickled artefacts under a semantic version and verifies their SHA-256 digest.",https://github.com/mattsq/anml-exp/blob/124bba0488c8092a5bc23e3ed567a9268951bbac/Agents.md
764049913,neo4j-graphrag-python,neo4j/neo4j-graphrag-python,https://github.com/neo4j/neo4j-graphrag-python,Neo4j GraphRAG for Python,,0,Unknown,,AGENTS.md,"Neo4j GraphRAG Package for Python The official Neo4j GraphRAG package for Python enables developers to build graph retrieval augmented generation (GraphRAG) applications using the power of Neo4j and Python. As a first-party library, it offers a robust, feature-rich, and high-performance solution, with the added assurance of long-term support and maintenance directly from Neo4j. üìÑ Documentation Documentation can be found here Resources A series of blog posts demonstrating how to use this package: - Build a Knowledge Graph and use GenAI to answer questions: - GraphRAG Python Package: Accelerating GenAI With Knowledge Graphs - Retrievers: when the Neo4j graph is already populated: - Getting Started With the Neo4j GraphRAG Python Package - Enriching Vector Search With Graph Traversal Using the GraphRAG Python Package - Hybrid Retrieval for GraphRAG Applications Using the GraphRAG Python Package - Enhancing Hybrid Retrieval With Graph Traversal Using the GraphRAG Python Package - Effortless RAG With Text2CypherRetriever A list of Neo4j GenAI-related features can also be found at Neo4j GenAI Ecosystem. üêç Python Version Support | Version | Supported? | |---------|-----------:| | 3.14 | &check; | | 3.13 | &check; | | 3.12 | &check; | | 3.11 | &check; | | 3.10 | &check; | üì¶ Installation To install the latest stable version, run: [code] Optional Dependencies This package has some optional features that can be enabled using the extra dependencies described below: - LLM providers (at least one is required for RAG and KG Builder Pipeline): - ollama: LLMs from Ollama - openai: LLMs from OpenAI (including AzureOpenAI) - google: LLMs from Vertex AI - cohere: LLMs from Cohere - anthropic: LLMs from Anthropic - mistralai: LLMs from MistralAI - sentence-transformers : to use embeddings from the [code] Python package - Vector database (to use :ref: [code] ): - weaviate: store vectors in Weaviate - pinecone: store vectors in Pinecone - qdrant: store vectors in Qdrant - experimental: experimental features mainly related to the Knowledge Graph creation pipelines. - nlp: installs spaCy for NLP pipelines, used by [code] in the experimental KG builder components. - fuzzy-matching: installs RapidFuzz, used by [code] in the experimental KG builder components. > Note: The [code] extra is currently not supported on Python 3.14 due to an upstream spaCy import-time issue (spaCy #13895). Use Python 3.13 or earlier for spaCy-based features until that is resolved upstream. Install package with optional dependencies with (for instance): [code] üíª Example Usage The scripts below demonstrate how to get started with the package and make use of its key features. To run these examples, ensure that you have a Neo4j instance up and running and update the [code] , [code] , and [code] variables in each script with the details of your Neo4j instance. For the examples, make sure to export your OpenAI key as an environment variable named [code] . Additional examples are available in the [code] ",https://github.com/neo4j/neo4j-graphrag-python/blob/8bc6a622773a9770a39a821a3fd4ccd776f4811e/AGENTS.md
1016079214,agent-context-seed-files,KazanderDad/agent-context-seed-files,https://github.com/KazanderDad/agent-context-seed-files,A set of files for AI agents to leverage,,0,Unknown,,AGENTS.md,"Agent Context & Agent Seed Files This repo contains seed files available to developers and agents to pull from into their own repos. - seed files, e.g. ci.yml - agent-context file templates - agent-instruction files with specific instructions if needed These files area opinionated towards nextjs projects with supabase using pnpm. They work well with projects build on Vercel's v0.dev and OpenAI's Codex The seeed AGENTS.md file is a boilerplate seed file to be copied and updated for your context (it is not an agent.md file for this repo)",https://github.com/KazanderDad/agent-context-seed-files/blob/2dc106daef3a66e6f0b203476b46a6b4c4be8cd9/seed.AGENTS.md
1111456180,onecoach-ui,g97iulio1609/onecoach-ui,https://github.com/g97iulio1609/onecoach-ui,"UI packages for CoachOne (ui, lib-design-system, design-system)",,0,Unknown,,AGENTS.md,,https://github.com/g97iulio1609/onecoach-ui/blob/fe03e604b8b309126a94fdeb9123cc79240cc479/AGENTS.MD
1124821520,archdesigner,Krosebrook/archdesigner,https://github.com/Krosebrook/archdesigner,Base44 App: ArchDesigner,,0,Unknown,,AGENTS.md,"ArchDesigner - Microservices Architecture Design Platform > AI-powered microservices architecture design and management platform [](./CHANGELOG.md) [](./COMPREHENSIVE_AUDIT_REPORT.md) [](./LICENSE) [](https://base44.com) --- üìö Table of Contents - Overview - Key Features - Documentation - Quick Start - Architecture - Technology Stack - Development - Testing - Deployment - Contributing - Project Status - Roadmap - Support --- Overview ArchDesigner is a comprehensive, AI-powered platform for designing, validating, deploying, and maintaining microservices architectures. Built on the Base44 platform with a React/Vite frontend and TypeScript/Deno serverless backend, it provides intelligent assistance through advanced Chain-of-Thought (CoT) reasoning agents. What Makes ArchDesigner Unique? - ü§ñ AI-First Architecture: 10 specialized agents with 5-stage CoT reasoning - üîí Security-First Design: Built-in OWASP Top 10 auditing and multi-standard compliance - üé® Visual Architecture Editor: Drag-and-drop microservices design - ‚ö° End-to-End Workflow: Design ‚Üí Code ‚Üí Deploy ‚Üí Monitor - üåê Multi-Cloud Support: AWS, Azure, GCP deployment generation - üìä Real-Time Analytics: Architecture health scoring and insights --- üöÄ Key Features Real-Time Collaboration üÜï - Live Presence Tracking: See who's online and actively editing - Real-Time Updates: Changes sync instantly across all connected users (80%) - Framework: None currently configured - Roadmap: Q1 2025 - Comprehensive testing infrastructure Planned Testing Stack [code] Frameworks: - Jest: Unit testing - React Testing Library: Component testing - Playwright: E2E testing - MSW: API mocking --- üöÄ Deployment Base44 Platform (Recommended) [code] Manual Deployment Frontend (Vercel/Netlify): [code] Backend (Deno Deploy): [code] Docker [code] --- ü§ù Contributing We welcome contributions! Please read our Contributing Guidelines for details on our code of conduct, development workflow, and how to submit pull requests. Quick Start for Contributors 1. Fork the repository 2. Create a feature branch ( [code] ) 3. Make your changes 4. Commit with conventional commits ( [code] ) 5. Push to your fork ( [code] ) 6. Open a Pull Request Development Workflow [code] Commit Convention We follow Conventional Commits: - [code] New feature - [code] Bug fix - [code] Documentation changes - [code] Code style changes (formatting, etc.) - [code] Code refactoring - [code] Adding or updating tests - [code] Maintenance tasks --- üìä Project Status - Version: 0.0.0 (Active Development) - Health Score: 82/100 - Features: 10+ major features implemented - Backend Functions: 10 serverless functions - Frontend Components: 216+ components - Lines of Code: ~15,000+ Health Metrics | Metric | Score | Target | Status | |--------|-------|--------|--------| | Overall Health | 82/100 | 90/100 | üü° Good | | Code Organization | 9/10 | 10/10 | üü¢ Excellent | | Security | 8/10 | 10/10 | üü¢ Strong | | Type Safety | 5/10 | 10/10 | üî¥ Needs Improvement | | Test Coverage | 2/10",https://github.com/Krosebrook/archdesigner/blob/b80a39bea11753476d877ba728246a5843ffc585/agents.md
1073989180,nextjs-boilerplate,renktt/nextjs-boilerplate,https://github.com/renktt/nextjs-boilerplate,new nextjs project,,0,Unknown,,AGENTS.md,"This is a Next.js project bootstrapped with [ [code] ](https://nextjs.org/docs/app/api-reference/cli/create-next-app). Getting Started First, run the development server: [code] Open http://localhost:3000 with your browser to see the result. You can start editing the page by modifying [code] . The page auto-updates as you edit the file. This project uses [ [code] ](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load Geist, a new font family for Vercel. Learn More To learn more about Next.js, take a look at the following resources: - Next.js Documentation - learn about Next.js features and API. - Learn Next.js - an interactive Next.js tutorial. You can check out the Next.js GitHub repository - your feedback and contributions are welcome! Deploy on Vercel The easiest way to deploy your Next.js app is to use the Vercel Platform from the creators of Next.js. Check out our Next.js deployment documentation for more details.",https://github.com/renktt/nextjs-boilerplate/blob/6dd62c4c4024829d8ad7154a97a1bd5f3207d0ff/Agents.md
88383294,qrcode.vue,scopewu/qrcode.vue,https://github.com/scopewu/qrcode.vue,A Vue component to generate qrcode. Supports both Vue 2 and Vue 3. ‰∏ÄÊ¨æÂêåÊó∂ÊîØÊè¥ Vue 2 Âíå Vue 3 ÁöÑ‰∫åÁª¥Á†ÅÁªÑ‰ª∂„ÄÇ,,0,Unknown,,AGENTS.md,"qrcode.vue ‚ö†Ô∏è Now when you are using Vue 3.x, please upgrade [code] to [code] üîí if you are using Vue 2.x, please keep using version [code] ; A Vue.js component to generate QRCode. Both support Vue 2 and Vue 3. ‰∏≠Êñá | Êó•Êú¨Ë™û install the [code] component can use in you Vue.js app. [code] [code] Usage e.g. [code] Or single-file components with a [code] extension: [code] When you use the component with Vue 3 with [code] : [code] Component props [code] - Type: [code] - Default: [code] The value content of qrcode. [code] - Type: [code] - Default: [code] The size of qrcode element. [code] - Type: [code] - Default: [code] Generate QRcode as [code] or [code] . The prop [code] can work on SSR. [code] - Type: [code] - Default: [code] Define how much wide the quiet zone should be. [code] - Type: [code] - Default: [code] qrcode Error correction level (one of 'L', 'M', 'Q', 'H'). Know more, wikipedia: QR_code. [code] - Type: [code] - Default: [code] The background color of qrcode. [code] - Type: [code] - Default: [code] The foreground color of qrcode. [code] - Type: [code] - Default: [code] [code] The settings to support qrcode image logo. [code] - Type: [code] - Default: [code] Enable gradient fill for the QR code. [code] - Type: [code] - Default: [code] Specify the type of gradient. [code] - Type: [code] - Default: [code] The start color of the gradient. [code] - Type: [code] - Default: [code] The end color of the gradient. [code] - Type: [code] - Default: [code] The class name of qrcode element. [code] 3.5+ [code] 3.5+ exports separate [code] and [code] components, for which the rollup configuration has been modified: [code] Direct references to [code] in common.js and cdn now require the [code] field: [code] [code] License copyright &copy; 2021 @scopewu, license by MIT",https://github.com/scopewu/qrcode.vue/blob/667ffe747975ea18bc20cba5de0d2e4277ebd980/AGENTS.md
23633128,generalized-kmeans-clustering,derrickburns/generalized-kmeans-clustering,https://github.com/derrickburns/generalized-kmeans-clustering,"Production-ready K-Means clustering for Apache Spark with pluggable Bregman divergences (KL, Itakura-Saito, L1, etc). 6 algorithms, 740      tests, cross-version persistence. Drop-in replacement for M",,0,Unknown,,AGENTS.md,"Generalized K-Means Clustering [](https://github.com/derrickburns/generalized-kmeans-clustering/actions/workflows/ci.yml) [](https://github.com/derrickburns/generalized-kmeans-clustering/actions/workflows/codeql.yml) [](https://opensource.org/licenses/Apache-2.0) [](https://www.scala-lang.org/) [](https://www.scala-lang.org/) [](https://spark.apache.org/) [](https://spark.apache.org/) > Security: This project follows security best practices. See SECURITY.md for vulnerability reporting and dependabot.yml for automated dependency updates. DataFrame-only API ‚Äî Version 0.7.0 removes the legacy RDD API entirely. The library is now 100% DataFrame/Spark ML native with a clean, modern architecture. This project generalizes K-Means to multiple Bregman divergences and advanced variants (Bisecting, X-Means, Soft/Fuzzy, Streaming, K-Medians, K-Medoids). It provides a pure DataFrame/ML API following Spark's Estimator/Model pattern. What's in here - Multiple divergences: Squared Euclidean, KL, Itakura‚ÄìSaito, L1/Manhattan (K-Medians), Generalized-I, Logistic-loss, Spherical/Cosine - Variants: Bisecting, X-Means (BIC/AIC), Soft K-Means, Structured-Streaming K-Means, K-Medoids (PAM/CLARA) - Scale: Tested on tens of millions of points in 700+ dimensions - Tooling: Scala 2.13 (primary) / 2.12, Spark 4.0.x / 3.5.x / 3.4.x - Spark 4.0.x: Scala 2.13 only (Scala 2.12 support dropped in Spark 4.0) - Spark 3.x: Both Scala 2.13 and 2.12 supported --- Quick Start (DataFrame API) Recommended for all new projects. The DataFrame API follows the Spark ML Estimator/Model pattern. [code] More recipes: see DataFrame API Examples. --- What CI Validates Our comprehensive CI pipeline ensures quality across multiple dimensions: | Validation | What It Checks | Badge | |----------------|-------------------|-----------| | Lint & Style | Scalastyle compliance, code formatting | Part of main CI | | Build Matrix | Scala 2.12.18 & 2.13.14 √ó Spark 3.4.3 / 3.5.1 / 4.0.1 | [](https://github.com/derrickburns/generalized-kmeans-clustering/actions/workflows/ci.yml) | | Test Matrix | 576 tests across all Scala/Spark combinations‚Ä¢ 62 kernel accuracy tests (divergence formulas, gradients, inverse gradients)‚Ä¢ 19 Lloyd's iterator tests (core k-means loop)‚Ä¢ Determinism, edge cases, numerical stability | Part of main CI | | Executable Documentation | All examples run with assertions that verify correctness (ExamplesSuite):‚Ä¢ BisectingExample - validates cluster count‚Ä¢ SoftKMeansExample - validates probability columns‚Ä¢ XMeansExample - validates automatic k selection‚Ä¢ SphericalKMeansExample - validates cosine similarity clustering‚Ä¢ PersistenceRoundTrip - validates save/load with center accuracy‚Ä¢ PersistenceRoundTripKMedoids - validates medoid preservation | Part of main CI | | Cross-version Persistence | Models save/load across Scala 2.12‚Üî2.13 and Spark 3.4‚Üî3.5‚Üî4.0 | Part of main CI | | Performance Sanity | Basic performance regression check (30s budget) | Part of main CI | | Python Smoke Test | PySpark wr",https://github.com/derrickburns/generalized-kmeans-clustering/blob/4bb21d58f00f60d3f80e58e3592b74276f2b5566/AGENTS.md
498766488,electric,electric-sql/electric,https://github.com/electric-sql/electric,"Read-path sync engine for Postgres that handles partial replication, data delivery and fan-out.",,0,Unknown,,AGENTS.md,"Electric Real-time sync for Postgres. Table of Contents: - Quick links - What is Electric? - Getting Started - HTTP API Docs - Developing Electric - Mac setup - Contributing - Support Quick links - Quickstart - Website - About - Docs - Demos (also see the [ [code] folder](./examples)) What is Electric? Sync is the magic ingredient behind fast, modern software. From apps like Figma and Linear to AI agents running on live local data. Electric is a Postgres sync engine. It solves the hard problems of sync for you, including partial replication, fan-out, and data delivery. So you can build awesome software, without rolling your own sync. Specifically, Electric is a read-path sync engine for Postgres. It syncs data out of Postgres into ... anything you like. The core sync protocol is based on a low-level HTTP API. This integrates with CDNs for highly-scalable data delivery. Partial replication is managed using Shapes. Sync can be consumed directly or via client libraries and framework integrations. Getting Started See the Quickstart guide to get up and running. In short, you need to: 1. have a Postgres database with logical replication enabled; and then to 2. run Electric in front of it, connected via [code] For example, using Docker Compose from the root of this repo: [code] You can then use the HTTP API to sync data from your Postgres. For example, to start syncing the whole [code] table: [code] Or use one of the clients or integrations, such as the [ [code] ](https://electric-sql.com/docs/api/integrations/react) React hook: [code] Again, see the Quickstart and the Docs for more details. HTTP API Docs The HTTP API is defined in an OpenAPI spec in website/electric-api.yaml. Developing Electric We use asdf to install Elixir, Erlang, and Node.js. Versions are defined in .tool-versions. Mac setup [code] You'll probably need to fiddle with your bash/zsh/etc rc file to load the right tool into your environment. Running Tests Electric has comprehensive test suites for both Elixir and TypeScript components. Prerequisites Install dependencies (if not already done): [code] Then start the test Postgres database: [code] This starts a Docker Compose setup with Postgres configured for logical replication on port 54321. To stop the database: [code] Elixir Tests Sync Service: [code] For coverage reports: [code] Elixir Client: [code] TypeScript Tests TypeScript tests require both the database and a running sync service. In a separate terminal, start the sync service: [code] Then run the tests: Individual Package: [code] All TypeScript Packages: From the root directory: [code] For coverage: [code] Contributing See the: - Guide to Contributing - Contributor License Agreement - Community Guidelines Support We have an open community Discord. Come and say hello and let us know if you have any questions or need any help getting things running. It's also super helpful if you leave the project a star here at the top of the page‚òùÔ∏è",https://github.com/electric-sql/electric/blob/7ba32193cc9f970835acdcb2de48101f1a812ae9/AGENTS.md
230863067,apartment,rails-on-services/apartment,https://github.com/rails-on-services/apartment,Database multi-tenancy for Rack (and Rails) applications,,0,Unknown,,AGENTS.md,"Apartment [](https://badge.fury.io/rb/ros-apartment) [](https://codecov.io/gh/rails-on-services/apartment) *Multitenancy for Rails and ActiveRecord* Apartment provides tools to help you deal with multiple tenants in your Rails application. If you need to have certain data sequestered based on account or company, but still allow some data to exist in a common tenant, Apartment can help. Apartment Fork: ros-apartment This gem is a fork of the original Apartment gem, which is no longer maintained. We have continued development under the name [code] to keep the gem up-to-date and compatible with the latest versions of Rails. [code] is designed as a drop-in replacement for the original, allowing you to seamlessly transition your application without code changes. Community Support This project thrives on community support. Whether you have an idea for a new feature, find a bug, or need help with [code] , we encourage you to participate! For questions and troubleshooting, check out our Discussions board to connect with the community. You can also open issues or submit pull requests directly. We are committed to maintaining [code] and ensuring it remains a valuable tool for Rails developers. Maintainer Update As of May 2024, Apartment is maintained with the support of CampusESP. We continue to keep Apartment open-source under the MIT license. We also want to recognize and thank the previous maintainers for their valuable contributions to this project. Installation Requirements - Ruby 3.1+ - Rails 7.0+ (Rails 6.1 support was dropped in v3.4.0) - PostgreSQL, MySQL, or SQLite3 Rails Add the following to your Gemfile: [code] Then generate your [code] config file using [code] This will create a [code] initializer file. Configure as needed using the docs below. That's all you need to set up the Apartment libraries. If you want to switch tenants on a per-user basis, look under ""Usage - Switching tenants per request"", below. Usage Video Tutorial How to separate your application data into different accounts or companies. GoRails #47 Creating new Tenants Before you can switch to a new apartment tenant, you will need to create it. Whenever you need to create a new tenant, you can run the following command: [code] If you're using the prepend environment config option or you AREN'T using Postgresql Schemas, this will create a tenant in the following format: ""#{environment}\_tenant_name"". In the case of a sqlite database, this will be created in your 'db/' folder. With other databases, the tenant will be created as a new DB within the system. When you create a new tenant, all migrations will be run against that tenant, so it will be up to date when create returns. Notes on PostgreSQL PostgreSQL works slightly differently than other databases when creating a new tenant. If you are using PostgreSQL, Apartment by default will set up a new schema and migrate into there. This provides better performance, and allows Apartment to work on systems like Heroku, which would not ",https://github.com/rails-on-services/apartment/blob/d1e6c75c59bfb882a6ff4f9c8e8a7791ae3d7a73/AGENTS.md
337513916,condo,open-condo-software/condo,https://github.com/open-condo-software/condo,"Condo is an Open Source property management SaaS that allows users to manage tickets, resident contacts, properties, payment tracking, create invoices, and oversee a service marketplace, all while off",,0,Unknown,,AGENTS.md,"CONDO Condo is an Open Source property management SaaS that allows users to manage tickets, resident contacts, properties, payment tracking, create invoices, and oversee a service marketplace, all while offering an extension system for mini-apps, making it an ideal platform for property management companies and those servicing shared properties. Table of contents - Getting started 1. Databases setup 2. Environment setup 3. Installing dependencies 4. [Building [code] dependencies](#4-building-open-condo-dependencies) 5. Preparing the local app environment 6. Starting app in dev / prod mode 7. Starting the worker - Developing - Contributing - Migration guides - Deploying Getting started 1. Databases setup We use Postgres 16.4 to store most of the information, and Redis 6.2 to store session information, asynchronous tasks, and various caches. In addition to them, we use s3 to store files, but it is optional to get started. You can start the databases using docker compose with this command: [code] Or you can bring up the databases directly on the host machine, using the corresponding tutorials 2. Environment setup Node.js 22.x All of our applications are written in Node.js, so you should also install it before you run the project. > We run our applications on the current LTS version of node, which is 22.x. > You can check node version using [code] command in your terminal. We recommend using nvm for local development, and for deploying the application there is Dockerfile ready to use at the root of the repository. Python 3.x We also use Python with packages for database migrations. So make sure you have one installed. 3. Installing dependencies To install Node.js dependencies simply type the following command: [code] > If you get errors related to missing yarn, > use these instructions to install it. > We also use turborepo to orchestrate npm modules in this monorepo. > Even though it is specified in the global [code] , in some environments you may get the error > [code] in further steps... > > In such cases, we recommend installing it globally using: > [code] To install python packages type the command: [code] 4. Building [code] dependencies Condo depends on several packages located in [code] directory, so it is required to build them before launching the main application. You can do it using this command: [code] 5. Preparing the local app environment We have a mechanism in place to get applications ready for launch, specifically: 1. Copy the global and local .env.example to .env 2. Create a database for each application and perform the necessary migrations in it 3. Assign dedicated ports to the applications 4. Run the local prepare of each application > During the ""local prepare"" step each app prepares itself by filling extra environment variables, > creating test users and other entities, needed for the first launch. To launch prepare script, run the following command: [code] > This step is only used in local development, > so consider manually se",https://github.com/open-condo-software/condo/blob/2a3ee915cff7fbb41db51376dd570193f94f14d4/AGENTS.md
198995767,macaw-ui,saleor/macaw-ui,https://github.com/saleor/macaw-ui,MacawUI: an official UI design kit for Saleor,,0,Unknown,,AGENTS.md,"[](https://www.npmjs.com/package/@saleor/macaw-ui) [](https://www.npmjs.com/package/@saleor/macaw-ui) [](https://bundlephobia.com/package/@saleor/macaw-ui@latest) MacawUI Official React UI components kit for Saleor ‚Äî an open-source GraphQL-first and Next.js ready e-commerce platform. You can find most of the elements used in the creation of Saleor's dashboard interface and use it to create Saleor Apps. Have a great time working on your projects and empowering your users. If you have any questions, feel free to let us know on GitHub Discussions. Installation [code] Usage You need to import the styles into your app. You can do it in your main entry point, for example [code] tsx [code] ThemeProvider [code] getCSSVariables [code] _document.tsx [code] Controller [code] Sentry.Integrations.Breadcrumbs`: [code] Right now sentry will display MacawUI components names in breadcrumbs. Development To begin, you need to install dependencies: [code] Then, you can run the Storybook: [code] You can run build in watch mode (useful for real-time development with e.g Dashboard): [code] When you finish woking, you can add new changeset [code] Useful tooling - Chrome browser extension - Atomic CSS Devtools License Distributed under the Creative Common Attribution 4.0 International License https://creativecommons.org/licenses/by/4.0/ Thanks Thanks to Chromatic for providing the visual testing platform that helps us review UI changes and catch visual regressions.",https://github.com/saleor/macaw-ui/blob/ca418151d8db3f07bd98831ac6f655b1a8830654/AGENTS.md
946671328,miro,vincent-uden/miro,https://github.com/vincent-uden/miro,A native pdf viewer for Windows and Linux (Wayland/X11) with configurable keybindings.,,0,Unknown,,AGENTS.md,"miro A native pdf viewer for Windows, macOS and Linux (Wayland/X11) with configurable keybindings. Features - Dark mode (both for the interface and the pdf) - Vim-like keybindings (by default) - Configuration file for key bindings (in case you don't like Vim bindings) - Mouse controls - Multiple pdfs in tabs - Cli arg for opening pdfs from the terminal - Automatic hot-reloading of any viewed pdf (especially useful when writing anything that compiles into pdfs like Latex/Typst/etc.) - Text copying in documents - Internal links (such as a table of contents) - External links (email, websites, etc. copies on click) - Bookmarks - Jumplist - Optional RPC server to control the viewer from another program - Print via the default web browser - Open links using keyboard controls Configuration The configuration file is located at [code] (or [code] in the home directory of your operating system). An example configuration file is located at [code] which contains all the default bindings for the program. Every binding that is possible is bound at least once in the default configuration file. Configuration File Format The configuration file uses a simple text format with three types of commands and comments: Key Bindings [code] Key sequences can be: - Single keys: [code] , [code] , [code] , [code] - Modified keys: [code] , [code] - Key chords (multiple keys): [code] (quotes required for sequences with spaces) All available actions are bound in the example config file. If you need a more exact view of the syntax it is documented in the keybinds-rs crate. Mouse Bindings [code] Mouse inputs can be: - Basic buttons: [code] , [code] , [code] , [code] , [code] - With modifiers: [code] , [code] All available actions are bound in the example config file. Settings [code] Available settings: - [code] - Enable/disable RPC server - [code] - Set RPC server port - [code] - Set a multiplier on panning with a trackpad Default Settings [code] Default settings apply only at application startup. They can later be toggled with key bindings. Available default settings: - [code] - Enable/disable dark mode rendering of the PDF - [code] - Enable/disable dark mode for the UI - [code] - Open sidebar - [code] - Enable/disable page borders Comments and Empty Lines [code] Error Handling The configuration parser provides detailed error messages with line numbers when parsing fails. Errors on one line don't prevent parsing of other lines Example error output: [code] Installation Pre-compiled binary Head over to releases and download the latest binary for your platform, then place it somewhere in your path. Nix Cachix Binary Cache [code] Crates.io This is pretty much the same as the following option, but doesn't require cloning the repo. See building from source for possible complications when compiling for Windows. I've had no problems compiling on Linux thus far. [code] Building from source On linux, the commands below would clone the repository, compile the project and copy the resulting b",https://github.com/vincent-uden/miro/blob/a606030a627b185e829ae283bdb9463ded438139/AGENTS.md
570557896,ESPresense-companion,ESPresense/ESPresense-companion,https://github.com/ESPresense/ESPresense-companion,HA Add-on / Docker container that solves indoor positions with mqtt data received from multiple ESPresense nodes,,0,Unknown,,AGENTS.md,ESPresense-companion A Home Assistant Add-on / Docker container that solves indoor positions using MQTT data received from multiple ESPresense nodes. The companion is the central brain of your ESPresense system. It: - Processes distance readings from all nodes using trilateration to determine device locations - Reports device room presence to Home Assistant via MQTT - Visualizes BLE device locations on your floorplan - Manages and configures ESPresense nodes - Updates node firmware - Adjusts device-specific settings - Monitors and controls automatic node optimization Documentation 1. Installation Guide 2. Configuration Guide 3. Node Setup 4. Optimization Guide Need Help? - Join our Discord Community - Check the Troubleshooting Guide - Report issues on GitHub Contributing - Submit pull requests - Improve our documentation,https://github.com/ESPresense/ESPresense-companion/blob/8abe104ed4c79bcdb57f835d4a53ebb28f18f327/AGENTS.md
1077871556,Droid-CLI-Orchestrator,aeitroc/Droid-CLI-Orchestrator,https://github.com/aeitroc/Droid-CLI-Orchestrator,ü§ñ Droid CLI Orchestrator - An intelligent AI orchestration system for coordinating specialized droids to accomplish complex development tasks,,0,Unknown,,AGENTS.md,"Droid Factory CLI ‚Äì Intelligent Orchestration System Complete orchestration system with intelligent planning, adaptive execution, and AI-powered specialist coordination. Features smart project analysis, learning capabilities, and proactive problem solving for complex multi-domain projects. Factory AI coding agents are intelligent AI assistants that work directly in your projects via the [code] command. --- üéØ Quick Start 1. Setup Your Project [code] 2. Use the Smart Orchestrator [code] The orchestrator will: - Auto-detect your tech stack and project structure - Intelligently plan the execution strategy - Select the best specialist droids for each task - Coordinate parallel execution with Factory - Learn from the project and improve future performance --- üöÄ Smart Orchestrator Features Intelligent Project Analysis - Auto-detects project type (React, Next.js, Python, Django, etc.) - Scans for tech stack patterns and dependencies - Assesses complexity and risk factors automatically - Predicts potential issues before they occur Smart Droid Selection - Ranks specialists based on expertise and success history - Adapts selection based on project characteristics - Learns from previous projects to improve choices - Provides fallback strategies when needed Adaptive Execution Strategies - Optimizes between sequential, parallel, and hybrid approaches - Auto-detects dependencies and optimizes task ordering - Real-time bottleneck detection and resolution - Dynamic scheduling based on progress monitoring Proactive Problem Solving - Predicts common issues and provides preemptive solutions - Applies learned patterns from successful projects - Implements security-first approaches for sensitive features - Suggests performance optimizations early Continuous Learning - Tracks success patterns and learns from failures - Updates knowledge base with each project - Improves prompt generation and strategy over time - Applies cross-project insights to new challenges Factory Coordination - Requests Factory parallel execution with smart prompt engineering - Provides comprehensive context and dependencies - Monitors progress and handles bottlenecks - Integrates results from all specialists Real-time Monitoring - Progress tracking with milestone detection - Performance metrics tracking and optimization - Quality assurance with automatic validation - Adaptive scheduling for optimal execution Error Recovery - Auto-diagnoses execution failures with detailed analysis - Provides alternative strategies and fallback approaches - Implements graceful degradation when needed - Learns from failures to prevent future issues Knowledge Management - Stores successful patterns for reuse - Documents failure scenarios to avoid - Creates templates for common project types - Improves strategy based on historical data - Scans for tech stack patterns and dependencies - Assesses complexity and risk factors automatically - Predicts potential issues before they occur Smart Droid Selection - Ranks specia",https://github.com/aeitroc/Droid-CLI-Orchestrator/blob/26828bc8354a382e07bc8808492589a6d5a9d48c/AGENTS.md
902155585,gac,cellwebb/gac,https://github.com/cellwebb/gac,Intelligent LLM-powered git commit message generator that understands your code!,,0,Unknown,,AGENTS.md,"üöÄ Git Auto Commit (gac) [](https://pypi.org/project/gac/) [](https://www.python.org/downloads/) [](https://github.com/cellwebb/gac/actions) [](https://app.codecov.io/gh/cellwebb/gac) [](https://github.com/astral-sh/ruff) [](https://mypy-lang.org/) [](docs/en/CONTRIBUTING.md) [](LICENSE) English | ÁÆÄ‰Ωì‰∏≠Êñá | ÁπÅÈ´î‰∏≠Êñá | Êó•Êú¨Ë™û | ÌïúÍµ≠Ïñ¥ | ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä | Ti·∫øng Vi·ªát | Fran√ßais | –†—É—Å—Å–∫–∏–π | Espa√±ol | Portugu√™s | Norsk | Svenska | Deutsch | Nederlands | Italiano LLM-powered commit messages that understand your code! Automate your commits! Replace [code] with [code] for contextual, well-formatted commit messages generated by large language models! --- What You Get Intelligent, contextual messages that explain the why behind your changes: --- Quick Start Use gac without installing [code] That's it! Review the generated message and confirm with [code] . Install and use gac [code] Upgrade installed gac [code] --- Key Features üåê 25+ Supported Providers - Anthropic ‚Ä¢ Azure OpenAI ‚Ä¢ Cerebras ‚Ä¢ Chutes.ai ‚Ä¢ Claude Code (OAuth) - DeepSeek ‚Ä¢ Fireworks ‚Ä¢ Gemini ‚Ä¢ Groq ‚Ä¢ Kimi for Coding ‚Ä¢ LM Studio - MiniMax.io ‚Ä¢ Mistral AI ‚Ä¢ Moonshot AI ‚Ä¢ Ollama ‚Ä¢ OpenAI ‚Ä¢ OpenRouter - Qwen.ai (OAuth) ‚Ä¢ Replicate ‚Ä¢ Streamlake ‚Ä¢ Synthetic.new ‚Ä¢ Together AI - Z.AI ‚Ä¢ Z.AI Coding ‚Ä¢ Custom Endpoints (Anthropic/OpenAI) üß† Smart LLM Analysis - Understands intent: Analyzes code structure, logic, and patterns to understand the ""why"" behind your changes, not just what changed - Semantic awareness: Recognizes refactoring, bug fixes, features, and breaking changes to generate contextually appropriate messages - Intelligent filtering: Prioritizes meaningful changes while ignoring generated files, dependencies, and artifacts - Intelligent commit grouping - Automatically group related changes into multiple logical commits with [code] üìù Multiple Message Formats - One-liner (-o flag): Single-line commit message following conventional commit format - Standard (default): Summary with bullet points explaining implementation details - Verbose (-v flag): Comprehensive explanations including motivation, technical approach, and impact analysis üåç Multilingual Support - 25+ languages: Generate commit messages in English, Chinese, Japanese, Korean, Spanish, French, German, and 20+ more languages - Flexible translation: Choose to keep conventional commit prefixes in English for tool compatibility, or fully translate them - Multiple workflows: Set a default language with [code] , or use [code] flag for one-time overrides - Native script support: Full support for non-Latin scripts including CJK, Cyrillic, Thai, and more üíª Developer Experience - Interactive feedback: Type [code] to reroll, [code] to edit in-place with vi/emacs keybindings, or directly type your feedback like [code] or [code] - Interactive questioning: Use [code] ( [code] ) to answer targeted questions about your changes for more contextual commit messages - One-command workflows: Complete workflows with flags like [code] (stage all, auto-confirm, push) - Git integrat",https://github.com/cellwebb/gac/blob/2447a824eb987c8d1299673bb3963b4bd8388925/AGENTS.md
