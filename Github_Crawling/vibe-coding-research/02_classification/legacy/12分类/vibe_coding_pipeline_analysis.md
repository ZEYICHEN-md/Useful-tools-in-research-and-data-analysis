# Vibe Coding 数据处理流程分析报告

> **核心理念**：找到 vibe coding 火热的当下，个人开发者们到底在用 vibe coding 做什么事情。

---

## 📊 一句话总结每个环节

| 环节 | 一句话总结 |
|------|-----------|
| **爬虫搜索** | 按天扫描 GitHub 最近创建的新仓库，用"负向过滤"排除噪音（作业/教程/配置库等），分层抽样保留个人真实项目。 |
| **数据筛选** | 只保留有 README 的仓库（证明项目有描述价值），排除机构/公司项目，聚焦个人开发者。 |
| **抽样逻辑** | 把仓库分成"沉默大多数"(≤20星)和"高价值信号"(>20星)两层，前者保留 20%，后者全保留。 |
| **AI 分析** | 用 DeepSeek API 给每个仓库打 6 个标签：AI 参与度、核心意图、宏观类别、微观场景、复杂度、行业洞察。 |

---

## 🔍 详细方法说明与合理性论证

### 第一步：爬虫搜索（vibe_coding_crawler.py）

#### 搜索口径

```
created:{当天日期} size:50..80000 pushed:>{次日} stars:0..3000
```

#### 关键设计

| 设计 | 说明 | 合理性 |
|------|------|--------|
| **按天切片** | 从 2026-01-28 开始，每天单独搜索 | GitHub 搜索限制最多 1000 条/请求，按天分片确保不遗漏，时间分布均匀 |
| **size:50..80000** | 代码库大小 50KB-80MB | 过滤空仓库(<50KB)和超大企业项目(>80MB) |
| **stars:0..3000** | 0 到 3000 星 | 排除超大型机构项目(>3000 星基本是大公司产品) |
| **pushed>次日** | 创建后还有更新 | 证明项目是"活"的，不是一次性 Demo |

#### 负向过滤清单（9 大类噪音）

| 类别 | 关键词示例 |
|------|-----------|
| 1. 教育类 | homework, tutorial, assignment, course, student |
| 2. 算法刷题 | leetcode, algorithm, solutions, coding challenge |
| 3. 配置备份 | dotfiles, config, backup, personal settings |
| 4. Awesome List | awesome list, curated list, resources |
| 5. 教程示例 | example code, starter template, boilerplate, 101 |
| 6. 大公司黑名单 | microsoft, google, meta, openai, apple, amazon |
| 7. 库/框架命名 | lib-, -lib, sdk-, framework, plugin- |
| 8. 描述排除词 | official, enterprise, deprecated, archived |
| 9. Topics 黑名单 | awesome-list, tutorial, homework, deprecated |

#### 合理性论证

**为什么要负向过滤？**

因为 GitHub 上 80% 的新仓库是**无效噪音**（学生作业、配置备份、教程示例）。如果不过滤，数据会被噪音淹没。

**为什么不直接用"vibe coding"关键词搜索？**

因为这个概念太新，很多人不会打标签；我们要找的是**实际的 AI 辅助开发行为**，而不是自称的。

---

### 第二步：分层抽样

#### 核心逻辑

```
Tier 1 (沉默大多数): stars ≤ 20 → 随机保留 20%
Tier 2 (高价值信号): stars > 20 → 100%保留
```

#### 合理性论证

| 问题 | 解答 |
|------|------|
| 为什么低星只抽 20%？ | GitHub 上绝大多数仓库(>80%)是 0-20 星的个人实验项目，全部保留会导致数据极度不平衡 |
| 为什么高星全保留？ | >20 星的仓库代表了经过社区验证的"有价值信号"，数量少但信息密度高 |
| 这样会不会丢失信息？ | 会丢失一些，但随机抽样保证了代表性；我们关注的是**趋势分布**，而非绝对数量 |

---

### 第三步：AI 分析分类（deepseek_analyzer.py）

#### 输入

仓库元数据 + README 内容（截断前 10000 字符）

#### 输出 6 个维度

| 维度 | 选项/范围 | 说明 |
|------|----------|------|
| **ai_generation_score** | 1-5 分 | 评估 AI 参与程度：找 AGENTS.md/.cursorrules/CLAUDE.md 等 AI 工作流特征文件 |
| **core_intent** | ≤15 字 | 一句话概括核心痛点，如"抓取网页推送到飞书" |
| **macro_category** | 三选一 | 个人效能工具 / 基础设施组件 / 产品系统原型 |
| **micro_scenario** | 十二选一 | productivity/content_creation/business_automation/education/social/fintech/health/entertainment/research/personal/ecommerce/other |
| **complexity_level** | 1-5 分 | 1=单文件脚本，5=多 API 复杂系统 |
| **analytical_insight** | 1-2 句话 | 行业分析师视角的趋势洞察 |

#### 合理性论证

| 设计 | 为什么合理 |
|------|-----------|
| 为什么看 README？ | README 是开发者与世界的"第一次对话"，最能体现**真实意图**；代码只能告诉你"做了什么"，README 告诉你"想做什么" |
| AI 生成分数怎么打？ | 不只看复杂度（AI 也能写复杂代码），而是找**AI 工作流特征**：AGENTS.md/.cursorrules/CLAUDE.md 等配置文件的存在 |
| 为什么要人工定义 12 个场景？ | 基于投资人视角的行业分类，覆盖软件商业化的主要赛道；LLM 在这个封闭集合里分类准确率高 |
| 宏观三分类的意义？ | 区分"自用的工具"、"给别人用的组件"、"完整的商业产品"——这是软件价值递增的三个层级 |

---

### 第四步：核心理念验证

#### 核心问题

**Vibe Coding 火热的当下，个人开发者们在用 AI 做什么？**

#### 数据链条如何回答这个问题

```
爬虫（找仓库） → 过滤（去噪音） → 抽样（保代表） → AI分析（打标签） → 聚合（出洞察）
     ↓              ↓            ↓           ↓            ↓
   全量扫描    排除作业/教程   保留真实项目  识别AI参与度  看清趋势分布
```

#### 关键洞察产出

1. **AI 参与度分布**：多少项目是高 AI 生成(5 分) vs 传统手工(1 分)？
2. **场景热度图**：12 个微观场景中哪些最热门？
3. **复杂度演进**：AI 时代个人项目的复杂度是否在提升？
4. **产品化路径**：从"个人工具"到"基础设施"到"产品原型"的分布变化

---

## 📈 数据规模参考

| 指标 | 数值 |
|------|------|
| 原始扫描仓库 | ~2100 个 |
| 通过过滤+抽样后 | ~1500 个 |
| 有 README 可分析 | ~1500 个 |
| 分析成本 | ~¥46 (DeepSeek API) |
| 时间跨度 | 2026-01-28 至 2026-02-10 (约 2 周) |

---

## ✅ 方法论总结

这个设计确保了我们捕捉的是**最新鲜**、**最真实**、**最具代表性**的个人开发者 AI 实践样本，为投资人提供了观察 "Vibe Coding" 趋势的窗口。

### 核心设计原则

1. **负向过滤优于正向关键词**：不依赖 self-reported 标签，通过排除法找真实项目
2. **分层抽样保证代表性**：既关注"沉默大多数"的实验性项目，也重视"高价值信号"的验证项目
3. **AI 辅助分析规模化**：用 LLM 统一标准分析大量仓库，提取结构化洞察
4. **投资人视角的分类**：从商业价值落地角度定义场景，而非技术栈角度

---

*文档生成时间：2026-02-11*
*数据来源：Vibe Coding 研究项目*
