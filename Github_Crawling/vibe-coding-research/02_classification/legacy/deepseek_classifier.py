#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ DeepSeek API å¯¹ Vibe Coding é¡¹ç›®è¿›è¡Œæ™ºèƒ½åˆ†ç±»

åˆ†ç±»ç»´åº¦:
1. é¡¹ç›®ç±»å‹ (project_type) - è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„é¡¹ç›®?
2. åº”ç”¨é¢†åŸŸ (application_domain) - ç”¨äºä»€ä¹ˆåœºæ™¯/é¢†åŸŸ?
3. æŠ€æœ¯æ ˆ (tech_stack) - ä¸»è¦ä½¿ç”¨äº†å“ªäº›æŠ€æœ¯?
4. å®Œæˆåº¦ (maturity) - é¡¹ç›®æˆç†Ÿåº¦è¯„ä¼°
5.  vibe_coding_score - Vibe Coding ç‰¹å¾è¯„åˆ† (1-10)
"""

import os
import csv
import json
import time
from datetime import datetime
from dotenv import load_dotenv
import requests

load_dotenv()

# DeepSeek API é…ç½®
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

# åˆ†ç±»æç¤ºè¯æ¨¡æ¿
CLASSIFICATION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¡¹ç›®åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«å’Œåˆ†ç±»è½¯ä»¶å¼€å‘é¡¹ç›®ã€‚

è¯·åˆ†æä»¥ä¸‹ GitHub ä»“åº“ä¿¡æ¯ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯èƒ½é€šè¿‡ AI Coding Agent (Vibe Coding) æ–¹å¼åˆ›å»ºçš„é¡¹ç›®ã€‚

ã€ä»“åº“ä¿¡æ¯ã€‘
åç§°: {name}
æè¿°: {description}
è¯­è¨€: {language}
Topics: {topics}
æ¥æºä¿¡å·: {source}
é…ç½®æ–‡ä»¶: {config_file}
ç½®ä¿¡åº¦: {confidence}

è¯·è¾“å‡ºä»¥ä¸‹åˆ†ç±»ç»“æœï¼ˆJSONæ ¼å¼ï¼‰:
{{
  "project_type": "é¡¹ç›®ç±»å‹",
  "project_type_reason": "åˆ¤æ–­ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰",
  "application_domain": "åº”ç”¨é¢†åŸŸ",
  "application_domain_reason": "åˆ¤æ–­ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰",
  "tech_stack": ["æŠ€æœ¯1", "æŠ€æœ¯2", "æŠ€æœ¯3"],
  "maturity": "mature|prototype|experimental|unknown",
  "maturity_reason": "æˆç†Ÿåº¦åˆ¤æ–­ç†ç”±",
  "vibe_coding_score": 8,
  "vibe_coding_signals": ["ä¿¡å·1", "ä¿¡å·2"],
  "key_features": ["åŠŸèƒ½1", "åŠŸèƒ½2"],
  "target_users": "ç›®æ ‡ç”¨æˆ·ç¾¤ä½“"
}}

åˆ†ç±»æ ‡å‡†:

ã€é¡¹ç›®ç±»å‹ project_typeã€‘
- web_app: Web åº”ç”¨/SaaS/å¹³å°
- web_service: Web API/åç«¯æœåŠ¡
- mobile_app: ç§»åŠ¨åº”ç”¨
- desktop_app: æ¡Œé¢åº”ç”¨
- browser_extension: æµè§ˆå™¨æ’ä»¶
- cli_tool: å‘½ä»¤è¡Œå·¥å…·
- ai_agent: AI Agent/æ™ºèƒ½æœºå™¨äºº
- ai_tool: AI/ML å·¥å…·æˆ–å¹³å°
- automation: è‡ªåŠ¨åŒ–/çˆ¬è™«/å·¥ä½œæµå·¥å…·
- dev_tool: å¼€å‘è€…å·¥å…·/IDEæ’ä»¶
- data_tool: æ•°æ®å¤„ç†/åˆ†æ/å¯è§†åŒ–å·¥å…·
- game: æ¸¸æˆ
- content_platform: å†…å®¹å¹³å°/CMS/ç¤¾åŒº
- ecommerce: ç”µå•†/æ”¯ä»˜ç³»ç»Ÿ
- infra_tool: åŸºç¡€è®¾æ–½/DevOpså·¥å…·
- personal_tool: ä¸ªäººå·¥å…·/è„šæœ¬
- library: å¼€æºåº“/æ¡†æ¶/SDK
- template: æ¨¡æ¿/è„šæ‰‹æ¶/Boilerplate
- other: å…¶ä»–

ã€åº”ç”¨é¢†åŸŸ application_domainã€‘
- productivity: ç”Ÿäº§åŠ›/æ•ˆç‡å·¥å…·
- content_creation: å†…å®¹åˆ›ä½œ/åª’ä½“
- business_automation: ä¸šåŠ¡è‡ªåŠ¨åŒ–/ä¼ä¸š
- education: æ•™è‚²/å­¦ä¹ 
- social: ç¤¾äº¤/é€šè®¯
- fintech: é‡‘è/æ”¯ä»˜/åŠ å¯†
- health: å¥åº·/åŒ»ç–—/wellness
- entertainment: å¨±ä¹/æ¸¸æˆ
- research: ç ”ç©¶/å®éªŒ/åŸå‹
- personal: ä¸ªäººç”Ÿæ´»ç®¡ç†
- ecommerce: ç”µå•†/é›¶å”®
- other: å…¶ä»–

ã€æˆç†Ÿåº¦ maturityã€‘
- mature: åŠŸèƒ½å®Œæ•´ï¼Œå¯ç”Ÿäº§ä½¿ç”¨
- prototype: åŸå‹/MVPé˜¶æ®µ
- experimental: å®éªŒæ€§/æ¦‚å¿µéªŒè¯
- unknown: æ— æ³•åˆ¤æ–­

ã€Vibe Coding è¯„åˆ† 1-10ã€‘
åŸºäºä»¥ä¸‹ä¿¡å·è¯„åˆ†:
- åŒ…å« AI é…ç½®æ–‡ä»¶ (+2)
- é¡¹ç›®æè¿°æåŠ AI/Agent (+1)
- ä»£ç ç”Ÿæˆç—•è¿¹æ˜æ˜¾ (+1)
- å•æ–‡ä»¶/å¿«é€ŸåŸå‹ç‰¹å¾ (+1)
- é¡¹ç›®è¾ƒæ–°ä½†åŠŸèƒ½è¾ƒå®Œæ•´ (+2)
- README æœ‰ AI ç”Ÿæˆç‰¹å¾ (+1)
- é¡¹ç›®å/æè¿°æœ‰ vibe coding ç›¸å…³ (+2)

è¯·åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""


class DeepSeekClassifier:
    def __init__(self, api_key: str = ""):
        self.api_key = api_key
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        self.results = []
        
    def classify_project(self, repo: dict) -> dict:
        """ä½¿ç”¨ DeepSeek API åˆ†ç±»å•ä¸ªé¡¹ç›®"""
        if not self.api_key:
            print("âŒ é”™è¯¯: æœªè®¾ç½® DEEPSEEK_API_KEY")
            return None
        
        prompt = CLASSIFICATION_PROMPT.format(
            name=repo.get("name", ""),
            description=repo.get("description", "") or "æ— æè¿°",
            language=repo.get("language", "Unknown"),
            topics=repo.get("topics", ""),
            source=repo.get("source", ""),
            config_file=repo.get("config_file", "æ— "),
            confidence=repo.get("confidence", "medium")
        )
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¡¹ç›®åˆ†æå¸ˆã€‚è¯·åªè¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 800
        }
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    DEEPSEEK_API_URL,
                    headers=self.headers,
                    json=payload,
                    timeout=60
                )
                response.raise_for_status()
                
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—
                content = content.strip()
                if content.startswith("```json"):
                    content = content[7:]
                if content.startswith("```"):
                    content = content[3:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()
                
                # è§£æ JSON
                classification = json.loads(content)
                
                # æ·»åŠ åŸå§‹æ•°æ®
                classification.update({
                    "repo_id": repo.get("repo_id"),
                    "full_name": repo.get("full_name"),
                    "html_url": repo.get("html_url"),
                    "stars": repo.get("stars", 0),
                    "language": repo.get("language"),
                    "original_description": repo.get("description"),
                    "confidence": repo.get("confidence"),
                    "classified_at": datetime.now().isoformat(),
                })
                
                return classification
                
            except json.JSONDecodeError as e:
                print(f"    âš ï¸ JSONè§£æå¤±è´¥: {e}")
                print(f"    å†…å®¹: {content[:200]}")
                if attempt == max_retries - 1:
                    return self._fallback_classification(repo)
                    
            except Exception as e:
                print(f"    âš ï¸ APIè¯·æ±‚å¤±è´¥ ({attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return self._fallback_classification(repo)
        
        return None
    
    def _fallback_classification(self, repo: dict) -> dict:
        """å¤±è´¥æ—¶çš„é»˜è®¤åˆ†ç±»"""
        return {
            "repo_id": repo.get("repo_id"),
            "full_name": repo.get("full_name"),
            "html_url": repo.get("html_url"),
            "project_type": "unknown",
            "project_type_reason": "APIè°ƒç”¨å¤±è´¥",
            "application_domain": "unknown",
            "application_domain_reason": "APIè°ƒç”¨å¤±è´¥",
            "tech_stack": [repo.get("language", "Unknown")],
            "maturity": "unknown",
            "maturity_reason": "åˆ†ç±»å¤±è´¥",
            "vibe_coding_score": 0,
            "vibe_coding_signals": [],
            "key_features": [],
            "target_users": "unknown",
            "error": True,
        }
    
    def process_csv(self, input_file: str, output_file: str = None, limit: int = None):
        """å¤„ç† CSV æ–‡ä»¶"""
        if not output_file:
            base = input_file.replace(".csv", "")
            output_file = f"{base}_classified_{datetime.now().strftime('%Y%m%d')}.csv"
        
        # è¯»å– CSV
        repos = []
        with open(input_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            repos = list(reader)
        
        if limit:
            repos = repos[:limit]
        
        total = len(repos)
        print(f"\nğŸ“Š å¼€å§‹åˆ†ç±» {total} ä¸ªé¡¹ç›®...")
        print("="*70)
        
        classified = []
        for idx, repo in enumerate(repos, 1):
            print(f"\n[{idx}/{total}] {repo.get('full_name', 'Unknown')}")
            
            result = self.classify_project(repo)
            if result:
                classified.append(result)
                score = result.get('vibe_coding_score', 0)
                ptype = result.get('project_type', 'unknown')
                domain = result.get('application_domain', 'unknown')
                print(f"  âœ“ ç±»å‹: {ptype} | é¢†åŸŸ: {domain} | Vibeè¯„åˆ†: {score}/10")
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            if idx % 10 == 0:
                self._save_intermediate(classified, output_file)
                print(f"  ğŸ’¾ å·²ä¿å­˜ä¸­é—´ç»“æœ ({len(classified)} æ¡)")
            
            # é¿å…é€Ÿç‡é™åˆ¶
            time.sleep(1)
        
        # æœ€ç»ˆç»“æœ
        self._save_final(classified, output_file)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_report(classified, output_file.replace(".csv", "_report.json"))
        
        return classified
    
    def _save_intermediate(self, results: list, filename: str):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        self._save_to_csv(results, filename.replace(".csv", "_temp.csv"))
    
    def _save_final(self, results: list, filename: str):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        self._save_to_csv(results, filename)
        print(f"\nâœ… åˆ†ç±»å®Œæˆï¼ç»“æœä¿å­˜è‡³: {filename}")
    
    def _save_to_csv(self, results: list, filename: str):
        """ä¿å­˜ä¸º CSV"""
        if not results:
            return
        
        # æ‰å¹³åŒ– tech_stack å’Œ key_features
        for r in results:
            if isinstance(r.get("tech_stack"), list):
                r["tech_stack"] = "|".join(r["tech_stack"])
            if isinstance(r.get("key_features"), list):
                r["key_features"] = "|".join(r["key_features"])
            if isinstance(r.get("vibe_coding_signals"), list):
                r["vibe_coding_signals"] = "|".join(r["vibe_coding_signals"])
        
        fieldnames = [
            "repo_id", "full_name", "html_url", "stars", "language",
            "project_type", "project_type_reason",
            "application_domain", "application_domain_reason",
            "tech_stack", "maturity", "maturity_reason",
            "vibe_coding_score", "vibe_coding_signals",
            "key_features", "target_users",
            "confidence", "original_description",
        ]
        
        with open(filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(results)
    
    def generate_report(self, results: list, filename: str):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        from collections import Counter
        
        # ç»Ÿè®¡
        types = Counter([r.get("project_type", "unknown") for r in results])
        domains = Counter([r.get("application_domain", "unknown") for r in results])
        maturities = Counter([r.get("maturity", "unknown") for r in results])
        
        # å¹³å‡ vibe coding score
        scores = [r.get("vibe_coding_score", 0) for r in results if r.get("vibe_coding_score")]
        avg_score = sum(scores) / len(scores) if scores else 0
        
        # é«˜è¯„åˆ†é¡¹ç›®
        high_score_projects = [
            {
                "name": r["full_name"],
                "score": r["vibe_coding_score"],
                "type": r["project_type"],
                "domain": r["application_domain"],
                "url": r["html_url"]
            }
            for r in results
            if r.get("vibe_coding_score", 0) >= 7
        ]
        high_score_projects.sort(key=lambda x: x["score"], reverse=True)
        
        report = {
            "generated_at": datetime.now().isoformat(),
            "total_classified": len(results),
            "vibe_coding_score": {
                "average": round(avg_score, 2),
                "distribution": dict(Counter(scores))
            },
            "project_type_distribution": dict(types.most_common()),
            "application_domain_distribution": dict(domains.most_common()),
            "maturity_distribution": dict(maturities.most_common()),
            "high_vibe_score_projects": high_score_projects[:20],
        }
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ˆ ç»Ÿè®¡æŠ¥å‘Š: {filename}")
        
        # æ§åˆ¶å°æ‘˜è¦
        print("\n" + "="*70)
        print("ğŸ“Š åˆ†ç±»ç»“æœæ‘˜è¦")
        print("="*70)
        print(f"\n  æ€»é¡¹ç›®æ•°: {len(results)}")
        print(f"  å¹³å‡ Vibe Score: {avg_score:.1f}/10")
        
        print(f"\n  ğŸ“‚ é¡¹ç›®ç±»å‹ Top 5:")
        for t, c in types.most_common(5):
            print(f"     {t}: {c}")
        
        print(f"\n  ğŸ¯ åº”ç”¨é¢†åŸŸ Top 5:")
        for d, c in domains.most_common(5):
            print(f"     {d}: {c}")
        
        print(f"\n  ğŸ† Vibe Score æœ€é«˜çš„é¡¹ç›®:")
        for p in high_score_projects[:5]:
            print(f"     â€¢ {p['name']} (Score: {p['score']}/10)")
            print(f"       {p['type']} | {p['domain']}")


def main():
    print("="*70)
    print("ğŸ¤– DeepSeek Vibe Coding é¡¹ç›®æ™ºèƒ½åˆ†ç±»")
    print("="*70)
    
    # æ£€æŸ¥ API Key
    if not DEEPSEEK_API_KEY:
        print("\nâŒ é”™è¯¯: æœªè®¾ç½® DEEPSEEK_API_KEY")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : DEEPSEEK_API_KEY=your_key")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„ vibe coding CSV æ–‡ä»¶
    import glob
    csv_files = glob.glob("vibe_coding_*.csv")
    
    if not csv_files:
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ° vibe coding CSV æ–‡ä»¶")
        print("   è¯·å…ˆè¿è¡Œ: python vibe_coding_crawler.py")
        return
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    print("\nğŸ“ æ‰¾åˆ°ä»¥ä¸‹æ•°æ®æ–‡ä»¶:")
    for i, f in enumerate(csv_files, 1):
        print(f"   {i}. {f}")
    
    # é€‰æ‹©æ–‡ä»¶
    choice = input("\nè¯·é€‰æ‹©è¦åˆ†ç±»çš„æ–‡ä»¶ç¼–å· (é»˜è®¤ 1): ").strip()
    if not choice:
        choice = "1"
    
    try:
        input_file = csv_files[int(choice) - 1]
    except (ValueError, IndexError):
        input_file = csv_files[0]
    
    print(f"\nğŸ“‚ é€‰æ‹©æ–‡ä»¶: {input_file}")
    
    # è¯¢é—®æ˜¯å¦é™åˆ¶æ•°é‡
    limit_input = input("\né™åˆ¶å¤„ç†æ•°é‡? (ç›´æ¥å›è½¦å¤„ç†å…¨éƒ¨, æˆ–è¾“å…¥æ•°å­—): ").strip()
    limit = int(limit_input) if limit_input.isdigit() else None
    
    # å¼€å§‹åˆ†ç±»
    classifier = DeepSeekClassifier(DEEPSEEK_API_KEY)
    classifier.process_csv(input_file, limit=limit)


if __name__ == "__main__":
    main()
