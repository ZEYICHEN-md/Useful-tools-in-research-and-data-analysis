#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨æ–°çš„8åˆ†ç±»ä½“ç³»é‡æ–°åˆ†æ Vibe Coding é¡¹ç›®

æ–°åˆ†ç±»ä½“ç³»:
1. enterprise_business - ä¼ä¸šå•†ä¸šåº”ç”¨
2. productivity_tools - æ•ˆç‡å·¥å…·  
3. tech_infrastructure - æŠ€æœ¯åŸºç¡€è®¾æ–½
4. entertainment_media - å¨±ä¹åª’ä½“
5. education_learning - æ•™è‚²å­¦ä¹ 
6. social_community - ç¤¾äº¤ç¤¾åŒº
7. health_wellness - å¥åº·åŒ»ç–—
8. personal_life - ä¸ªäººç”Ÿæ´»

ä½œè€…: AI Assistant
æ—¥æœŸ: 2026-02-11
"""

import os
import json
import time
import sys
from datetime import datetime
from typing import Optional, Dict, Any, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
from dotenv import load_dotenv
import requests

load_dotenv()
sys.stdout.reconfigure(encoding='utf-8')

# ========== é…ç½®å¸¸é‡ ==========
INPUT_FILE = "vibe_coding_dataset_2w.jsonl"
OUTPUT_JSON = "vibe_coding_analysis_8categories.jsonl"
OUTPUT_CSV = "vibe_coding_analysis_8categories.csv"
PROGRESS_FILE = "analyzer_progress_8cat.json"
FAILED_FILE = "analyzer_failed_8cat.jsonl"

# DeepSeek API é…ç½®
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
DEEPSEEK_MODEL = "deepseek-chat"

# å¹¶å‘å’Œé€Ÿç‡æ§åˆ¶
MAX_WORKERS = 5
REQUEST_DELAY = 0.5
MAX_RETRIES = 3
RETRY_DELAY_BASE = 2

# æˆæœ¬æ§åˆ¶
MAX_BUDGET_CNY = 50

# æ–°çš„ç³»ç»Ÿæç¤ºè¯
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½æ·±è°™ç§‘æŠ€è¡Œä¸šä¸é£é™©æŠ•èµ„è¶‹åŠ¿çš„æ•°æ®åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æ GitHub ä»“åº“çš„å…ƒæ•°æ®å’Œ README å†…å®¹ï¼Œä»ä¸­æç‚¼å‡ºå¼€å‘è€…çš„çœŸå®æ„å»ºæ„å›¾ã€è¡Œä¸šè½åœ°åœºæ™¯ä»¥åŠ AI å‚ä¸ç¼–ç¨‹çš„æµ“åº¦ã€‚

è¯·é˜…è¯»æä¾›çš„å•ä¸ª GitHub é¡¹ç›®æ•°æ®ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºä½ çš„åˆ†æç»“æœã€‚å¿…é¡»è¾“å‡ºåˆæ³•çš„ JSON æ ¼å¼ï¼Œç¦æ­¢åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæ€§æ–‡æœ¬ã€‚

åˆ†æç»´åº¦ä¸è¾“å‡ºå­—æ®µè¯´æ˜ï¼š

1. ai_generation_score (æ•´æ•° 1 åˆ° 5)
è¯„ä¼°è¯¥é¡¹ç›®å€ŸåŠ© AI è¾…åŠ©ç”Ÿæˆï¼ˆVibe Codingï¼‰çš„ç¨‹åº¦ã€‚
- 1: æä½ã€‚æ˜ç¡®çš„ä¼ ç»Ÿäººå·¥æ‰‹å†™ç—•è¿¹ï¼Œç¼ºä¹ä»»ä½• AI é…ç½®æ–‡ä»¶ã€‚
- 3: ä¸­ç­‰ã€‚æ··åˆå¼€å‘ï¼Œå¯èƒ½ä½¿ç”¨äº† AI è¾…åŠ©è¡¥å…¨ä»£ç ã€‚
- 5: æé«˜ã€‚å…·å¤‡æ˜æ˜¾çš„ AI åŸç”Ÿç‰¹å¾ï¼Œå¦‚ AGENTS.md, .cursorrules æ–‡ä»¶ï¼Œæˆ–å®˜æ–¹ AI æ¨¡æ¿ç”Ÿæˆçš„é¡¹ç›®ã€‚

2. core_intent (å­—ç¬¦ä¸²)
ç”¨ä¸€å¥è¯ï¼ˆä¸è¶…è¿‡ 15 ä¸ªå­—ï¼‰æå…¶ç²¾ç‚¼åœ°æ¦‚æ‹¬è¯¥é¡¹ç›®è§£å†³çš„æ ¸å¿ƒç—›ç‚¹æˆ–ä¸šåŠ¡é€»è¾‘ã€‚

3. macro_category (å­—ç¬¦ä¸²)
å¿…é¡»ä»ä»¥ä¸‹ 3 ä¸ªé€‰é¡¹ä¸­ç²¾ç¡®é€‰æ‹©å…¶ä¸€ï¼š
- ä¸ªäººæ•ˆèƒ½ä¸è¾…åŠ©å·¥å…·
- åŸºç¡€è®¾æ–½ä¸åº•å±‚ç»„ä»¶  
- äº§å“ä¸ç³»ç»ŸåŸå‹

4. micro_scenario (å­—ç¬¦ä¸²)
å¿…é¡»ä»ä»¥ä¸‹ 8 ä¸ªé€‰é¡¹ä¸­ç²¾ç¡®é€‰æ‹©å…¶ä¸€ï¼š

- enterprise_business: ä¼ä¸šå•†ä¸šåº”ç”¨ã€‚å•†ä¸šæµç¨‹è‡ªåŠ¨åŒ–ã€ç”µå•†ã€é‡‘èç§‘æŠ€ã€CRMã€ERPã€ä¼ä¸šç®¡ç†ç³»ç»Ÿã€‚
  ç¤ºä¾‹ï¼šæ´—è½¦åº—ç®¡ç†ã€æœºåœºèˆªç­ç³»ç»Ÿã€é¤å…å¤–å–ã€æˆ¿äº§ç§Ÿèµã€æŠ•èµ„å¯è§†åŒ–ã€æ”¯ä»˜ç½‘å…³

- productivity_tools: æ•ˆç‡å·¥å…·ã€‚ä¸ªäºº/å›¢é˜Ÿæ•ˆç‡ã€å¼€å‘è€…å·¥å…·ã€å†…å®¹åˆ›ä½œå·¥å…·ã€æ¨¡æ¿/è„šæ‰‹æ¶ã€‚
  ç¤ºä¾‹ï¼šåœ¨çº¿ç¼–è¯‘å™¨ã€ç”µå­è¡¨æ ¼ã€AIå·¥ä½œç©ºé—´ã€è§†é¢‘ç‰¹æ•ˆã€CMSã€Next.jsæ¨¡æ¿

- tech_infrastructure: æŠ€æœ¯åŸºç¡€è®¾æ–½ã€‚æŠ€æœ¯ç ”ç©¶ã€åŸå‹éªŒè¯ã€ç³»ç»Ÿå·¥å…·ã€ç¡¬ä»¶/IoTã€æ“ä½œç³»ç»Ÿã€ç½‘ç»œåè®®ã€‚
  ç¤ºä¾‹ï¼šCRUDç”Ÿæˆå™¨ã€åŸºå› åˆ†æã€å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€WebåŸå‹ã€å›ºä»¶ã€åµŒå…¥å¼ç³»ç»Ÿ

- entertainment_media: å¨±ä¹åª’ä½“ã€‚æ¸¸æˆã€å¨±ä¹æ¶ˆè´¹ã€åª’ä½“æ’­æ”¾ã€å†…å®¹æ¶ˆè´¹ã€‚
  ç¤ºä¾‹ï¼šç¬¦å·åŒ¹é…æ¸¸æˆã€VRå¯è§†åŒ–ã€IPTVæ’­æ”¾å™¨ã€æ¼«ç”»é˜…è¯»å™¨

- education_learning: æ•™è‚²å­¦ä¹ ã€‚æ•™è‚²å¹³å°ã€å­¦ä¹ å·¥å…·ã€çŸ¥è¯†ä¼ æˆã€æŠ€èƒ½æå‡ã€‚
  ç¤ºä¾‹ï¼šåœ¨çº¿æ•™è‚²å¹³å°ã€é—ªå¡åº”ç”¨ã€è¯¾ç¨‹ææ–™ã€ç¼–ç¨‹å­¦ä¹ å·¥å…·

- social_community: ç¤¾äº¤ç¤¾åŒºã€‚ç¤¾äº¤åº”ç”¨ã€ç¤¾åŒºå¹³å°ã€é€šè®¯å·¥å…·ã€çº¦ä¼šåŒ¹é…ã€è®ºå›ã€‚
  ç¤ºä¾‹ï¼šèŠå¤©æœºå™¨äººã€æ–°é—»ç¤¾äº¤APIã€ç¤¾å›¢ç½‘ç«™ã€çº¦ä¼šåŒ¹é…

- health_wellness: å¥åº·åŒ»ç–—ã€‚åŒ»ç–—åº”ç”¨ã€å¥åº·è¿½è¸ªã€wellnessã€å¿ƒç†å¥åº·ã€å¥èº«ç®¡ç†ã€‚
  ç¤ºä¾‹ï¼šAIå…½åŒ»å¹³å°ã€æ‚£è€…è¯æˆ¿è¿æ¥ã€AIå¿ƒç†æ—¥è®°ã€åŒ»ç–—ç—…å†

- personal_life: ä¸ªäººç”Ÿæ´»ã€‚ä¸ªäººç”Ÿæ´»ç®¡ç†ã€ä½œå“é›†å±•ç¤ºã€å®¶åº­ç®¡ç†ã€ä¸ªäººå“ç‰Œã€ç”Ÿæ´»åŠ©æ‰‹ã€‚
  ç¤ºä¾‹ï¼šç”µå½±æ¸…å•ã€ä½œå“é›†ç½‘ç«™ã€å®¶åº­å®¶åŠ¡ç®¡ç†ã€ä¸ªäººé£Ÿè°±

5. complexity_level (æ•´æ•° 1 åˆ° 5)
1 ä»£è¡¨æå…¶ç®€å•çš„å•æ–‡ä»¶è„šæœ¬ï¼Œ5 ä»£è¡¨æ¶‰åŠå¤šæ–¹ API å’Œå®Œæ•´çŠ¶æ€ç®¡ç†çš„å¤æ‚ç³»ç»Ÿã€‚

6. analytical_insight (å­—ç¬¦ä¸²)
ç”¨ç®€çŸ­çš„ä¸€ä¸¤å¥è¯è¯„ä»·è¿™ä¸ªé¡¹ç›®åæ˜ äº†å½“ä¸‹è½¯ä»¶å¼€å‘ç”Ÿæ€ä¸­çš„å“ªç§å¾®è§‚è¶‹åŠ¿ã€‚

å¿…é¡»è¾“å‡ºåˆæ³•çš„ JSON æ ¼å¼ï¼Œç¦æ­¢åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæ€§æ–‡æœ¬ã€‚"""


class VibeCodingAnalyzer8Cat:
    """Vibe Coding 8åˆ†ç±»åˆ†æå™¨"""
    
    def __init__(self):
        self.api_key = DEEPSEEK_API_KEY
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        self.stats = {
            "total": 0,
            "readme_ok": 0,
            "processed": 0,
            "success": 0,
            "failed": 0,
            "skipped": 0,
            "tokens_input": 0,
            "tokens_output": 0,
            "total_cost_cny": 0.0,
            "start_time": None,
            "end_time": None,
        }
        
        self.category_stats = {
            "micro_scenario": {},
            "ai_generation_score": {i: 0 for i in range(1, 6)},
        }
        
        self.processed_ids: Set[int] = set()
        self.failed_ids: Set[int] = set()
        self.lock = Lock()
        self.running = True
    
    def load_progress(self) -> None:
        """åŠ è½½è¿›åº¦"""
        if os.path.exists(PROGRESS_FILE):
            try:
                with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.processed_ids = set(data.get("processed_ids", []))
                    self.failed_ids = set(data.get("failed_ids", []))
                    self.stats["tokens_input"] = data.get("tokens_input", 0)
                    self.stats["tokens_output"] = data.get("tokens_output", 0)
                    self.stats["total_cost_cny"] = data.get("total_cost_cny", 0.0)
                    print(f"ğŸ“‚ å·²åŠ è½½è¿›åº¦: {len(self.processed_ids)} å·²å¤„ç†, {len(self.failed_ids)} å¤±è´¥")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½è¿›åº¦å¤±è´¥: {e}")
    
    def save_progress(self) -> None:
        """ä¿å­˜è¿›åº¦"""
        data = {
            "processed_ids": list(self.processed_ids),
            "failed_ids": list(self.failed_ids),
            "tokens_input": self.stats["tokens_input"],
            "tokens_output": self.stats["tokens_output"],
            "total_cost_cny": self.stats["total_cost_cny"],
            "last_update": datetime.now().isoformat()
        }
        try:
            with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def analyze_project(self, repo: dict) -> Optional[dict]:
        """ä½¿ç”¨ DeepSeek API åˆ†æå•ä¸ªé¡¹ç›®"""
        if not self.api_key:
            print("âŒ é”™è¯¯: æœªè®¾ç½® DEEPSEEK_API_KEY")
            return None
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(repo)
        
        payload = {
            "model": DEEPSEEK_MODEL,
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 800
        }
        
        for attempt in range(MAX_RETRIES):
            try:
                response = requests.post(
                    DEEPSEEK_API_URL,
                    headers=self.headers,
                    json=payload,
                    timeout=60
                )
                response.raise_for_status()
                result = response.json()
                
                # è§£æç»“æœ
                content = result["choices"][0]["message"]["content"]
                analysis = json.loads(content)
                
                # ç»Ÿè®¡ token
                tokens_in = result.get("usage", {}).get("prompt_tokens", 0)
                tokens_out = result.get("usage", {}).get("completion_tokens", 0)
                cost = (tokens_in * 1 + tokens_out * 2) / 1000000  # å…ƒ
                
                return {
                    "analysis": analysis,
                    "tokens_input": tokens_in,
                    "tokens_output": tokens_out,
                    "cost": cost
                }
                
            except requests.exceptions.RequestException as e:
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY_BASE * (2 ** attempt)
                    print(f"  è¯·æ±‚å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... ({e})")
                    time.sleep(wait_time)
                else:
                    print(f"  è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    return None
            except json.JSONDecodeError as e:
                print(f"  JSONè§£æå¤±è´¥: {e}")
                return None
            except Exception as e:
                print(f"  æœªçŸ¥é”™è¯¯: {e}")
                return None
        
        return None
    
    def _build_prompt(self, repo: dict) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        readme_content = repo.get("readme_content", "")
        if readme_content:
            readme_preview = readme_content[:3000] + "..." if len(readme_content) > 3000 else readme_content
        else:
            readme_preview = "æ—  README å†…å®¹"
        
        return f"""è¯·åˆ†æä»¥ä¸‹ GitHub ä»“åº“ï¼š

ã€åŸºæœ¬ä¿¡æ¯ã€‘
ä»“åº“åç§°: {repo.get("name", "N/A")}
æè¿°: {repo.get("description", "N/A")}
è¯­è¨€: {repo.get("language", "N/A")}
Topics: {', '.join(repo.get("topics", []))}
Stars: {repo.get("stars", 0)}

ã€README å†…å®¹é¢„è§ˆã€‘
{readme_preview}

è¯·è¾“å‡º JSON æ ¼å¼çš„åˆ†æç»“æœã€‚"""
    
    def process_single_repo(self, repo: dict) -> Optional[dict]:
        """å¤„ç†å•ä¸ªä»“åº“"""
        repo_id = repo.get("id")
        
        with self.lock:
            if repo_id in self.processed_ids:
                return None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰README
        if not repo.get("readme_content"):
            with self.lock:
                self.stats["readme_ok"] += 1
                self.processed_ids.add(repo_id)
            return None
        
        # è°ƒç”¨APIåˆ†æ
        result = self.analyze_project(repo)
        
        with self.lock:
            self.stats["processed"] += 1
            
            if result:
                self.stats["success"] += 1
                self.stats["tokens_input"] += result["tokens_input"]
                self.stats["tokens_output"] += result["tokens_output"]
                self.stats["total_cost_cny"] += result["cost"]
                self.processed_ids.add(repo_id)
                
                # æ›´æ–°åˆ†ç±»ç»Ÿè®¡
                micro = result["analysis"].get("micro_scenario", "unknown")
                self.category_stats["micro_scenario"][micro] = self.category_stats["micro_scenario"].get(micro, 0) + 1
                
                score = result["analysis"].get("ai_generation_score", 3)
                self.category_stats["ai_generation_score"][score] = self.category_stats["ai_generation_score"].get(score, 0) + 1
                
                return result
            else:
                self.stats["failed"] += 1
                self.failed_ids.add(repo_id)
                return None
    
    def save_result(self, repo: dict, analysis: dict) -> None:
        """ä¿å­˜åˆ†æç»“æœ"""
        result = {
            "repo_id": repo.get("id"),
            "repo_name": repo.get("name"),
            "repo_url": repo.get("url"),
            "stars": repo.get("stars"),
            "description": repo.get("description"),
            "language": repo.get("language"),
            "topics": repo.get("topics", []),
            "ai_generation_score": analysis.get("ai_generation_score"),
            "core_intent": analysis.get("core_intent"),
            "macro_category": analysis.get("macro_category"),
            "micro_scenario": analysis.get("micro_scenario"),
            "complexity_level": analysis.get("complexity_level"),
            "analytical_insight": analysis.get("analytical_insight"),
            "analyzed_at": datetime.now().isoformat(),
        }
        
        with open(OUTPUT_JSON, 'a', encoding='utf-8') as f:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    def run(self) -> None:
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("=" * 70)
        print("Vibe Coding 8åˆ†ç±»åˆ†æå™¨")
        print("=" * 70)
        
        # æ£€æŸ¥APIå¯†é’¥
        if not self.api_key:
            print("âŒ é”™è¯¯: æœªè®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
            return
        
        # åŠ è½½è¿›åº¦
        self.load_progress()
        
        # åŠ è½½å¾…å¤„ç†æ•°æ®
        print(f"\nğŸ“‚ åŠ è½½æ•°æ®: {INPUT_FILE}")
        repos = []
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    repo = json.loads(line)
                    repos.append(repo)
                except:
                    pass
        
        self.stats["total"] = len(repos)
        print(f"   æ€»å…± {len(repos)} ä¸ªä»“åº“")
        
        # è¿‡æ»¤å·²å¤„ç†çš„
        pending_repos = [r for r in repos if r.get("id") not in self.processed_ids]
        print(f"   å¾…å¤„ç†: {len(pending_repos)} ä¸ª")
        
        if not pending_repos:
            print("\nâœ… æ‰€æœ‰é¡¹ç›®å·²å¤„ç†å®Œæˆ")
            return
        
        # é¢„ä¼°æˆæœ¬
        estimated_cost = len(pending_repos) * 0.03
        print(f"\nğŸ’° é¢„ä¼°æˆæœ¬: Â¥{estimated_cost:.2f} (çº¦ {len(pending_repos) * 2500} tokens)")
        
        if estimated_cost > MAX_BUDGET_CNY:
            print(f"âš ï¸ è­¦å‘Š: é¢„ä¼°æˆæœ¬ Â¥{estimated_cost:.2f} è¶…è¿‡é¢„ç®—ä¸Šé™ Â¥{MAX_BUDGET_CNY}")
            return
        
        input("\næŒ‰ Enter é”®å¼€å§‹åˆ†æï¼Œæˆ–æŒ‰ Ctrl+C å–æ¶ˆ...")
        
        self.stats["start_time"] = datetime.now()
        
        # å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = {executor.submit(self.process_single_repo, repo): repo for repo in pending_repos}
            
            for future in as_completed(futures):
                repo = futures[future]
                try:
                    result = future.result()
                    if result:
                        self.save_result(repo, result["analysis"])
                        
                        # æ‰“å°è¿›åº¦
                        if self.stats["success"] % 10 == 0:
                            self.print_progress()
                            self.save_progress()
                            
                except Exception as e:
                    print(f"âŒ å¤„ç† {repo.get('name')} æ—¶å‡ºé”™: {e}")
                
                time.sleep(REQUEST_DELAY)
        
        self.stats["end_time"] = datetime.now()
        self.save_progress()
        
        print("\n" + "=" * 70)
        print("åˆ†æå®Œæˆ!")
        print("=" * 70)
        self.print_final_stats()
    
    def print_progress(self) -> None:
        """æ‰“å°è¿›åº¦"""
        processed = self.stats["success"]
        total = self.stats["total"]
        pct = processed / total * 100 if total > 0 else 0
        cost = self.stats["total_cost_cny"]
        
        print(f"\nğŸ“Š è¿›åº¦: {processed}/{total} ({pct:.1f}%) | ğŸ’° æˆæœ¬: Â¥{cost:.2f}")
        print(f"   åˆ†ç±»åˆ†å¸ƒ: {dict(sorted(self.category_stats['micro_scenario'].items(), key=lambda x: -x[1])[:5])}")
    
    def print_final_stats(self) -> None:
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds() / 60
        
        print(f"\næ€»å¤„ç†: {self.stats['total']} ä¸ªä»“åº“")
        print(f"æˆåŠŸ: {self.stats['success']} | å¤±è´¥: {self.stats['failed']} | è·³è¿‡: {self.stats['skipped']}")
        print(f"è€—æ—¶: {duration:.1f} åˆ†é’Ÿ")
        print(f"æ€»æˆæœ¬: Â¥{self.stats['total_cost_cny']:.2f}")
        print(f"\n8åˆ†ç±»åˆ†å¸ƒ:")
        for cat, count in sorted(self.category_stats["micro_scenario"].items(), key=lambda x: -x[1]):
            pct = count / self.stats["success"] * 100 if self.stats["success"] > 0 else 0
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        print(f"\nè¾“å‡ºæ–‡ä»¶:")
        print(f"  JSON: {OUTPUT_JSON}")
        print(f"  è¿›åº¦: {PROGRESS_FILE}")


if __name__ == "__main__":
    analyzer = VibeCodingAnalyzer8Cat()
    analyzer.run()
